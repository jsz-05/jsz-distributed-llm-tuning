Distributed Algorithms

Dining Philosophers
This module describes algorithms for The
Distributed Dining Philosophers Problem a problem
that exemplifies mutual exclusion of critical
operations among agents in a distributed setting
This and following modules describe algorithms by which agents
manage conflicts among themselves This module describes an
algorithm for a distributed mutual exclusion problem called The

Distributed Dining Philosophers Problem 

Key Concepts
1 Mutual Exclusion
The distributed dining philosophers is a generalization of the mutual
exclusion problem to distributed systems A mutual exclusion or
mutex problem is one in which only one agent can carry out some
activity such as executing a critical section of a program Mutex
algorithms ensure that all agents that want to carry out such
activities do so eventually

2 Priorities among Agents
Distributed conflictresolution algorithms ensure that when multiple
agents are in a conflict that only one of them can win every agent
wins eventually A standard way of managing conflicts is to have
agents agree on relative priorities among themselves the agent with
higher priority wins
Distributed algorithms often use a goodneighbor policy to ensure
that all agents win conflicts eventually An agent that wins a conflict

makes its priority lower than the priorities of all the agents with which
it competes

3 Tokens and What Agents Know
An agent can resolve a conflict with other agents only if it knows
something about the states of other agents For example what
agents want to enter a critical section and what are their priorities
httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

117

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

What agents know is defined in this module We used the concept of

Distributed Algorithms

Contents

Index

tokens to illustrate what agents know A system has a fixed number
of indivisible tokens which are neither created nor destroyed An



agent that holds a token knows that no other agent holds that token
This knowledge is at the core of many conflict resolution algorithms

The Problem
Agent States in a Mutual Exclusion Problem

Fig2 States in Mutual Exclusion
An agent in a mutual exclusion problem is in one of three states
1 Outside critical section The agent is executing outside its
critical section An agent can remain in this state for ever or it
may transit after finite time to the next state waiting to enter its
critical section
2 Waiting to enter critical section The agent waits to enter critical
section until it is given permission to do so by the operating
system
3 In critical section The agent executes in its critical section An
agent does not remain in its critical section forever It does so
for only finite time after which it transits to the state outside
critical section
Clients determine transitions from outside critical section to waiting
to enter critical section and from in critical section to outside critical

section The operating system determines transitions from waiting to
enter critical section to outside critical section

Agent States in the Dining PhilosophersProblem
httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

217

71124 600 PM

Distributed Algorithms

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

Contents

Index



Fig3 States in Dining Philosophers
The name Dining Philosophers is an example of CS humor an
oxymoron Philosophers may think for ever but eat for only finite
time The algorithm must ensure that hungry philosophers dont
starve  they get to eat eventually The problem and its name were
proposed by Edsger W Dijkstra a CS pioneer
The states Thinking Hungry and Eating correspond exactly to
Outside critical section Waiting to enter critical section and In critical

section respectively

Agent Communication Structure

Fig4 Communication among Agents
The commununication structure among agents is represented by an
undirected graph in which the nodes are agents and each edge
represents two channels one in each direction The agents are either
httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

317

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

OS or client agents There is one client agent associated with each

Distributed Algorithms

Contents

Index

OS agent Clients are shown as squares and OS agents as circles For
example client agent w is associated with OS agent w The diagram



does not show all clients so as not to make the diagram too crowded
A pair of OS agents are neighbors when there is an edge between
them A pair of client agents are neighbors when the OS agents with
which they are associated are neighbors For example in the figure w
and y are neighbors

Specification
Safety Neighbors do not eat at the same
time
Let safe be the predicate Neighboring clients are not eating and let

init be a predicate that holds initially
The safety part of the specification is that safe holds in every state
in every path from every initial state

init  Asafe

Progress Hungry agents eat eventually
The progress part of the specification is that every hungry agent
transits to eating state eventually
For every agent v

v state  hungry



v state  eating

Example of Safety

httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

417

71124 600 PM

Distributed Algorithms

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

Contents

Index



Fig5 Diagrams illustrating Safety
Figure 5 shows a client eating as a red node depicting the client and
its OS agent An uncolored node represents a client that is thinking or
hungry The diagram on the left shows the system in a safe state
there are no edges between red vertices The diagram on the right
shows an unsafe state because there are edges between red vertices

The Clients Program
We use two tokens that move between a client and its OS agent The
tokens are called the resource token and the request token The
clients states are represented by which tokens the client holds
1 Thinking State A thinking client holds the request token but not
the resource token
2 Transition Thinking to Hungry Send the request token to the
OS
3 Hungry State The client holds neither the request nor the
resource token
4 Transition Hungry to Eating The client transits to eating when it
receives both the request and resource token
5 Eating The client holds both the request and resource tokens
6 Transition from Eating to Thinking The client holds sends the
resource token to the OS and continues to hold the request
token
The figure below illustrates the states of the client The request token
is shown as a square and the resource token as a circle

httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

517

71124 600 PM

Distributed Algorithms

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

Contents

Index



Fig6 Clients Program
Initially all clients are thinking all resource tokens are with OS agents
and all request tokens are with clients

What the OS Knows
While the OS agent holds the request token it knows that its client is
hungry While the OS agent holds the resource token it knows that its
client is not eating

Fig7 OS Agents Program
When a client transits from thinking to hungry it sends its request
token to the agent When the OS receives the request token the OS
also has the resource token so the OS knows that its client is hungry
There is an interval after the client sends the request token and
before the OS receives it during which the client is hungry but the OS
doesnt know that An OS agent does not need to know what state its
httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

617

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

client is in at every point Likewise a client does not need to know its

Distributed Algorithms

OS agents state at every point

Contents

Index



A client is hungry leadsto its OS agent knowing that its client is
hungry The leadsto captures the fact that the OS doesnt know the
clients state at the instant that the client transitions from thinking to
hungry

Introduction of Tokens
We introduce a token on each edge of the agent communication
graph see figure 4 The token on an edge v w is in one of four states
held by v in the channel from v to w held by w or in the channel
from w to v Therefore while v holds this token it knows that w
doesnt hold it Likewise while w holds this token it knows that v
doesnt

Fig7 Fork on each edge of the agent communication
graph
These tokens are called forks They are called chopsticks in some
papers An agent eats only if it holds forks for all the edges incident
on it Therefore while an agent eats none of its neighbors do and so
the safety specification is satisfied

Key Question When does a hungry agent
yield forks
An eating philosopher holds on to all its forks until it finishes eating
A thinking philosopher can give a fork to a neighbor that requests it

httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

717

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

So the key question is Under what conditions should a hungry

Distributed Algorithms

Contents

Index

neighbor give a fork that it holds to a neighbor that requests it



Suppose every hungry agent gives a fork to a neighbor that requests
it Then we can get the scenario shown in the figure below

Fig8 Scenario when hungry agents yield forks
The figure shows a system with 3 agents indexed 0 1 2 The forks
are shown as small colored circles The state on the left shows agent
j holding the fork that it shares with agent j  1 mod 3 If each
agent yields the fork to its neighbor we get the state on the right in
which agent j holds the fork that it shares with agent j  1 mod 3
So if all hungry agents yield forks the states can alternate for ever
between the one on the left and the one on the right In this case
hungry agents starve they remain hungry forever
If hungry agents dont yield forks then the state on the left persists for
ever In this case too hungry agents starve

Creating a Partial Order of Priorities
Lets assign priorities to agents so that a hungry agent v releases a
fork to a neighbor w only if v has lower priority than w If there is a
cycle of agents all with the same priority then we get the situation
shown in figure 8 So we will ensure that priorities form a partial
order in all states in all transitions Priorities form a partial order
exactly when the priority graph is acyclic The graph has an edge from
v to w exactly when v has higher priority over w
In the figure below the diagram on the left shows an acyclic priority
graph while the one on the right shows a graph with a cycle
httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

817

71124 600 PM

Distributed Algorithms

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

Contents

Index



Fig9 Priority Graph must be Acyclic

How should Priorities Change

Fig10 How should priorities change when v eats
How should priorities change when an agent eats so that the priority
graph remains acyclic For example consider the priority graph
shown in figure 10 Assume agent v has all its forks and is about to
eat Should the directions of edges incident on v be flipped Or
should v have lower priority than all its neighbors ie all edges
incident on v point towards v
What happens if we flip the directions of the edges incident on v
After the flip the edges are directed from w x and y towards v and
from v to u But now we have a cycle y to v to u to w to y So
flipping edge directions doesnt work

httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

917

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

What happens if agents adopt the good neighbor policy The winner

Distributed Algorithms

Contents

Index

of a conflict gives itself lower priority than all the agents with which it
competes So an agent that starts eating gives itself lower priority



than all its neighbors All edges point towards an eating agent

Fig11 Winner gets lower priority than its neighbors
When all edges incident on a vertex point towards the vertex then
there is no cycle through that vertex So directing all edges incident
on an eating vertex towards the eating vertex maintains acyclicity of
the graph
For example in the figure directing all edges incident on vertex v
towards v ensures that no new cycle is created

Agents priority does not decrease until the agent
eats

How an Agent knows its Priority
We assign an attribute clean  dirty to forks A fork is either dirty or

clean The forks held by an eating agent are dirty When an agent
receives a fork from another agent the receiving agent cleans the
fork So the receiver holds a clean fork and the fork remains clean
until an agent next eats with it This is the hygenic solution Another
 sad  attempt at CS humor
An agent holding a dirty fork knows that it has lower priority than the
agent with which it shares the fork Likewise an agent holding a clean
fork knows that it has higher priority than the agent with which it
shares the fork

httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

1017

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

If an agent does not hold the fork that it shares with a neighbor then

Distributed Algorithms

Contents

Index

the agent does not know its priority with respect to that neighbor



Example of a Forks Lifecycle
The diagram below shows states of a fork shared by agents u and v
The red arrow shows priority and the black arrows show channels
The blue dot represents the fork
In the figure on the top left agent u is hungry and holds a clean fork
So u knows that it has priority over v At this point v does not know
whether v has priority over u or not
The next figure at the top right shows that when u transits from
hungry to eating the fork becomes dirty and u has lower priority than
v Agent u continues to hold the fork while it eats
The next figure bottom right shows the situation after u gets a
request for the fork from v Because u got the request from v and u
hasnt sent the fork to v agent u knows that v is hungry Since the
fork is dirty u sends the fork to v The figure shows the fork in the
channel from u to v While the fork is in the channel it doesnt matter
whether the fork is clean or dirty however merely for convenience
lets assume that u being hygenic cleans the fork before sending it
to its partner While the fork is in a channel the priority doesnt change
but neither u nor v knows what the priority is
The next figure bottom left shows the situation when v receives the
fork Receiving the fork doesnt change the priority At this point v is
hungry and the fork is clean and so v knows that it has higher priority

v holds on to the fork until it next eats

httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

1117

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

Fig12 How an Agent knows its Priority

Distributed Algorithms

Contents

Index



Algorithm
Properties of Reachable States
Here is a list of some of the properties of states in all trajectories
1 The priority graph is acyclic u has priority over a neighbor v
exactly when u holds the fork that it shares with v and the fork
is clean or the fork is in the channel from v to u or v holds the
fork and the fork is dirty
2 Eating philosophers hold the forks for all edges incident on
them and these forks are dirty
3 All forks held by thinking philosphers are dirty
4 Thinking philosophers never send requests and never receive
forks Thinking philosophers respond to request for forks by
sending the requested forks

Initial States
Initially all philosophers are thinking all forks are dirty and all
channels are empty The forks are placed so that the priority graph is
acyclic The initial assignment of forks is as follows Given an
arbitrary acyclic graph for any edge directed from v to w the fork
shared by v and w is initially at w and the fork is dirty

Algorithm Commands
The algorithm is specified by the following commands
1 When a thinking philosophers gets a request for a fork that it
holds it sends the fork A fork held by a thinking philosopher is
dirty
2 When a thinking philosopher transits to hungry it sends
requests for all forks that it does not hold
3 When a hungry philosopher receives a fork it records the fork
as being clean If the hungry philosopher holds all its forks and
if it has no request for any dirty fork that it holds then it transits
to eating and records all the forks that it holds in the eating
state as dirty
4 When a hungry philosopher receives a request for a fork that it
holds it sends the fork if the fork is dirty and holds on to the
fork if it is clean
httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

1217

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

5 When an eating philosopher receives a request for a fork it

Distributed Algorithms

Contents

Index

registers the request in memory and continues eating while
holding the fork When an eating philosopher transits to



thinking it sends forks for all requests that it received

What could go wrong
The proof of safety is straightforward Neighbors arent eating
because neighbors cant hold the same fork at the same time
Before we look at the proof of progress lets see what may go wrong
Could a group of philosophers exchange forks with each other so that
members of the group eat repeatedly and starve a philosopher who is
not in the group For example in the figure below could philosophers
u v w exchange forks so that they each eat in turn and starve y

Fig13 Potential Problems What could go wrong
Could the system enter a deadlock state in which each hungry
philosopher in a group holds only some  but not all  of the forks
that it needs to eat while other members of the group hold the
remaining forks

Proof of Correctness
The algorithm is correct We are required to prove that every hungery
philosopher eats eventually

v 

v h  v e

where for a philosopher v v h holds exactly when v is hungry and
v e holds exactly when v is eating
httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

1317

71124 600 PM

Variant
DistributedFunction
Algorithms

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

Contents

Index



To prove this progress property we find a variant function that
satisfies the following two conditions
1 Safety The variant function does not increase while v remains
hungry
2 progress The following predicate does not hold forever The
variant function remains unchanged and v remains hungry
We propose a variant function which is a pair of integers nT  nH 
which are the number of thinking and hungry philosophers
respectively of higher priority than v In terms of the priority graph

nT  nH are the numbers of thinking and hungry philosophers ie
vertices with paths to v

Example of Variant Function
The figure below shows a portion of the priority graph in a state of the
system The figure only shows philosophers with higher priority than
philosopher v ie it only shows vertices in the graph with paths to v
Since eating philosophers have lower priority than their neighbors
eating philosophers dont appear in this graph
A hungry philosopher is marked with an H and a thinking
philosopher with a T In the diagram philosophers v w x y are
hungry and u is thinking Forks are located at philosophers and are
shown as small colored circles A dirty fork is colored red and clean
one is blue For example the fork shared by v and y is at y and is
clean

httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

1417

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

Fig15 A Variant Function Numbers of higher priority

Distributed Algorithms

thinking hungry agents

Contents

Index



Example of Changes to Variant Function
The next figure is an example of changes to the variant function The
diagram on the top left shows the higher priority vertices in the state
of the previous figure If agent x eats next the priority graph transits
to the diagram on the top right and the variant function nT  nH
changes from 1 3 to 1 2

Fig16 Example of Values of the Variant Function
If agent y eats next the priority graph transits to the diagram on the
bottom right and the variant function nT  nH changes from 1 2
to 1 1 If agent w eats next the priority graph transits to the
diagram on the bottom left and the variant function nT  nH
changes from 1 1 to 0 0

Proof that the variant function does not increase
while v remains hungry
If a philosopher of higher priority than v transits from thinking to
hungry then nT decreases Though nH increases the variant
function nT  nH decreases because ordering of function values is
done lexicographically
If a philosopher of higher priority than v transits from hungry to
eating then nH decreases and so the variant function nT  nH
decreases

httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

1517

71124 600 PM

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

Proof
that Algorithms
the following Contents
predicate does
not hold
Distributed
Index



forever The variant function remains unchanged
and v remains hungry
Let w be a highestpriority hungry philosopher ie a philosopher with
no hungry philosopher with priority higher than w Note w may be
the same as v All philosophers with priority higher than w are
thinking In the next paragraph we show that either w gets all its forks
and then transits from hungry to eating or the variant function
decreases
From the algorithm a hungry philosopher w requests forks from its
neighbors From the algorithm w eventually gets forks from all its
lower priority neighbors A higher priority neighbor x of w is thinking
So when x gets a request for a fork from w either 1 x sends the
requested fork to w or 2 x transits from thinking to hungry in which
case the variant function nT  nH decreases

Summary Key Ideas of this
Module
This module introduced the problem of distributed mutual exclusion
showed how the good neighbor policy  a winning agent reduces its
priority to be lower than all the agents that it competes with  solves
this conflict resolution problem introduced tokens and what agents
know about other agents holding tokens and showed a proof pattern
that is one of the most common patterns for proving progress

Review
1 What is the meaning of mutual exclusion among neighboring
philosophers
2 An invariant of the algorithm is that each token is in exactly one
place an agent or a channel How does this invariant help in
designing the algorithm
3 An invariant of the algorithm is that the relative priorities
among agents forms a partial order  the priority graph is
acyclic What can go wrong if the priority graph has cycles
4 An agent that has a request for a fork releases the fork if the
fork is dirty and holds on to the fork if the fork is clean What
could go wrong if an agent releases a fork when it gets a
request regardless of whether the fork is clean or dirty
httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

1617

71124 600 PM

Distributed Algorithms

DistributedCollaborationDiningPhilosophersDiningPhilosophershtml

Contents

Index

K Mani Chandy Emeritus Simon Ramo Professor California Institute



of Technology

httpskmchandygithubioDistributedCollaborationDiningPhilosophersDiningPhilosophershtml

1717

71124 329 PM

ChannelSnapshotsChannelSnapshotsDetailshtml

Distributed Algorithms

Contents

Index



A Global Snapshot Algorithm
A global snapshot algorithm records a state of the system that can
occur during a computation The state obtained by the algorithm is
called a global snapshot Systems are monitored by taking repeated
global snapshots When a transient error is detected a rollback and
recovery algorithm restarts the computation from the most recent
snapshot instead of starting it from the initial state

Global Snapshot Details
This webpage gives a code outline for the global snapshot algorithm
and gives examples of steps in the algorithm

Code Structure
The code outline is given below in Python channels_recorded is a
dict dictionary where channels_recordedsender becomes True
when the snapshot for the channel from this sender has finished
being recorded channel_snapshots is a dict where
channel_snapshotssender is the ongoing recording of the snapshot
of the channel from the sender
taken_local_snapshot  False
channel_snapshots  key  for key in predecessors
channels_recorded  key False for key in predecessors
start
def receivemessage sender
if isinstancemessage Marker and not taken_local_snapshot
local_snapshot  record_state
taken_local_snapshot  True
channels_recordedsender  True
output_message  Marker
for receiver in successors
sendoutput_message receiver
elif isinstancemessage Marker and taken_local_snapshot
channels_recordedsender  True
else
if taken_local_snapshot and not channels_recordedsender
httpskmchandygithubioChannelSnapshotsChannelSnapshotsDetailshtml

15

71124 329 PM

ChannelSnapshotsChannelSnapshotsDetailshtml

channel_snapshotssender  

Distributed Algorithms

Contents

Index

channel_snapshotssenderappendmessage



The remainder of this webpage consists of examples

Examples
Example Snapshots may change a Clients
Computation
This example shows that the OS algorithm may change a clients
computation though it does not change the clients dataflow
Figure 2 is a representation of a computation with event sequence
0 1 2    and agents X Y  Z without a concurrent OS
algorithm and figure 3 shows how the OS changes this computation
Events later in the computation are placed to the right of earlier
events

Fig2 Representation of a Computation without
Snapshots
Figure 3 shows how a clients computation is changed when the OS
takes snapshots The local snapshots taken by agents are shown as
a yellow circle on the agents timelines The OS delays event 3 so that
it occurs after events 4 5 6 and 7 as shown in the figure The OS
changes the computation but it does not change the dataflow

httpskmchandygithubioChannelSnapshotsChannelSnapshotsDetailshtml

25

71124 329 PM

Distributed Algorithms

ChannelSnapshotsChannelSnapshotsDetailshtml

Contents

Index



Fig3 The OS changes a Clients Computation
In figure 3 the presnapshot events are 0 1 2 4 6 There is only one
message received in a presnapshot event namely the message
represented by the edge 0 2 So every message received in a presnapshot event is sent in a presnapshot event The figure shows that
the set of presnapshot events is closed

Example Steps in a Global Snapshot Algorithm
Initiation
Figure 4 illustrates the first step of the algorithm

Fig4 Agent Sends Markers when it Takes its Local
Snapshot
Agent Y takes its local snapshot shown as a yellow vertex on Ys
timeline When Y takes its snapshot it sends markers on its output
channels The markers are shown as green edges in the figure
When agents X and Z each receive the markers they take their local
snapshots because they havent taken snapshots earlier
httpskmchandygithubioChannelSnapshotsChannelSnapshotsDetailshtml

35

71124 329 PM

Distributed Algorithms

ChannelSnapshotsChannelSnapshotsDetailshtml

Contents

Index



Fig5 Agents Take Local Snapshots when they Receive
Markers
The actions by X and Z of taking their snapshots are shown as yellow
vertices on their timelines in figure 5

Example Agents take Snapshots upon Receiving
Markers
When X and Z take their snapshots they send markers out on their
output channels The markers sent by X are shown in figure 7 The
markers sent by Z are not shown in the figure

Fig6 When an Agent takes its Snapshot it sends
Markers

Example Snapshot of a Channel

httpskmchandygithubioChannelSnapshotsChannelSnapshotsDetailshtml

45

71124 329 PM

ChannelSnapshotsChannelSnapshotsDetailshtml

Figure 8 shows how agent Y determines the state of the channel from

Distributed Algorithms

Contents

Index

X to Y in the global snapshot Y starts recording the messages it
receives along this channel after Y takes its snapshot and stops the



recording when it receives a marker on this channel The only
message in this interval is the message corresponding to edge 6 7

Fig7 Example Recording a Channel State
The message corresponding to edge 0 2 is from X to Y but is not in
the snapshot of the channel because both 0 and 2 are presnapshot
events Likewise the message corresponding to edge 12 13 is
from X to Y but is not in the snapshot of the channel because both 12
and 13 are postsnapshot events The message corresponding to
edge 6 7 was sent in a presnapshot event and received in a postsnapshot event and so it is in the snapshot of the channel

Next
Next logical clocks

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioChannelSnapshotsChannelSnapshotsDetailshtml

55

71124 347 PM

Distributed Algorithms

ByzantineByzantineOralhtml

Contents

Index



Byzantine Consensus Oral
Messages
This module describes a Byzantine consensus algorithm in which
messages are not encrypted An agent x that receives a message
signed by an agent y cannot tell whether y signed the message or
whether some other agent forged ys signature and corrupted the
message
This module describes solutions to the Byzantine problem with oral
messages whereas the previous module studied the problem with
written messages For convenience we repeat the problem
specification next
An agent is a general or a lieutenant An agent may be loyal or
disloyal Let N be the number of agents and t the number of disloyal
agents The general sends a command to each lieutenant where the
command is either attack or retreat A loyal general sends the same
command to all lieutenants whereas a disloyal general may send
different commands to different lieutenants Each lieutenant decides
to attack or retreat at the end of the algorithm
If all loyal lieutenants get the same command then each loyal
lieutenant obeys the commands that it received if the command is
attack then each loyal lieutenant attacks and if the command is
retreat then each loyal lieutenant retreats
Even if loyal lieutenants receive different commands all loyal
lieutenants make the same the decision either all loyal lieutenants
attack or all loyal lieutenants retreat

Notation
We use indices i j k for loyal agents x y for generic agents who
may be loyal or disloyal and e for disloyal agents Nothing in an
agents id or data identifies the agent as loyal or disloyal Moreover
the algorithm does not have to discover which agents act disloyally
For a nonempty list L we use the Python notation L to refer the last
element of the list For example if L  5 6 then L  6
httpskmchandygithubioByzantineByzantineOralhtml

19

71124 347 PM

ByzantineByzantineOralhtml

For a list L and an element x the notation L x represents a list

Distributed Algorithms
Contents
Index
consisting of x appended to the tail of L For example if L is the list
1 2 then L 3 is the list 1 2 3 and L 3 4 is the list 1 2 3 4



The general is the agent with index 0 and the lieutenants have
indices 1   N  1
Let mx be the message that the general sends lieutenant x and let
ax be the decision the lieutenant x makes

Specification
The specification has two parts validity and consensus

Validity Loyal lieutenants obey a loyal general
If all loyal lieutenants get the same message then each loyal
lieutenant obeys the message that it receives

i j  mi  mj



i  ai  mi

Consensus Loyal lieutenants make the same
decision
i j  ai  aj

Assumptions
The oral Byzantine version makes fewer assumptions than the written
version The assumptions made are as follows
1 Synchrony The algorithm operates in a synchronous fashion in
a sequence of rounds or synchronous steps If an agent x does
not send a message to an agent y in a given round then y can
detect that x did not send a message to it in that round
2 Reliability If an agent y sends a message m to an agent y in a
given round then z receives m in that round
3 Receiver knows sender An agent that receives a message
knows which agent sent it If an agent z receives a message m
from an agent y in a round then z knows that y sent m in that
round

Why oral messages are harder
In the written version of the problem if an agent z receives a
message m from any agent where m is signed by the general then z
knows that the general did send m An agent cannot forge the
httpskmchandygithubioByzantineByzantineOralhtml

29

71124 347 PM

ByzantineByzantineOralhtml

generals signature and send a false message By contrast in the oral

Distributed Algorithms

Contents

Index

or unencrypted version any agent can forge any agents signature
and send corrupted messages



Byzantine Generals Algorithm
Messages in the algorithm are either attack or retreat messages If
an agent x does not receive a message from an agent y on a round
then x treats the absence of the message from y in the same way as
if x received a retreat message from y So the algorithm only deals
with attack and retreat messages and does not deal with steps that
an agent takes if it does not receive a message
First we describe the flow of message in the algorithm and then
describe the algorithm

Message Flow
Messages flow along a tree of height t  1 The root node is m0
which represents the generals command Each node of the tree is of
the form mL where L0  0 and L1    is a list of lieutenants
where each lieutenant appears at most once
The next figure illustrates a part of the messaging tree for
N  7 t  2 There is insufficient space to show the complete
tree

Fig1 A Part of the Message Tree for General and 6
Lieutenants
Each nonleaf node mL in the tree has a child mL x for each
lieutenant x that is not in L For example m0 has children
httpskmchandygithubioByzantineByzantineOralhtml

39

71124 347 PM

ByzantineByzantineOralhtml

m0 1 m0 2   m0 N  1
Distributed Algorithms
Contents
Index
m0 x is the message that lieutenant x receives from the general
m0 x0   xk is the message that lieutenant x0 receives from the
general and forwards to lieutenant x1  which in turn forwards the
message to lieutenant xn1 which in turn forwards the message to
lieutenant xn



If the general is loyal then it sends the same message to all
lieutenants m0 x  m0 for all x Loyal lieutenants forward the
messages that they receive however disloyal lieutenants may send
arbitrary messages

Example
The diagram below shows a situation in which the general is loyal
and sends attack messages to all lieutenants Lieutenant 1 is disloyal
shown as a dashed circle Lieutenant 1 sends retreat messages to
some lieutenants and attack messages to others Lieutenant 2 is
loyal and so it broadcasts the message that it receives

Fig2 Edges Aggregation Dataflow Trees

Aggregating Phase
Messages received by a lieutenant are processed by the lieutenant in
steps that are also represented by a tree called the aggregation tree
The aggregation tree has a node aL for each node mL of the
message tree
The diagram below shows a part of the aggregation tree for
N  7 t  2 these are the processing steps of lieutenant 1

httpskmchandygithubioByzantineByzantineOralhtml

49

71124 347 PM

Distributed Algorithms

ByzantineByzantineOralhtml

Contents

Index



Fig3 Aggregation Tree Steps for Lieutenant 1
Each node aL i of the tree has a child aL x i for each x that is
not in L i For example a0 1 has children
a0 2 1 a0 3 1  a0 6 1
Connections from Messaging to Aggregating Nodes
There is an edge directed from each message node mL to the
aggregation node aL For example there are edges from
m2 3 1 to a2 3 1 and from m2 1 to a2 1 and from m1 to

a1
Output of Aggregating Nodes
The output of an aggregation node is the majority of its inputs For
example

a2 1  majoritym2 1 a2 3 1 a2 4 1   a2 6 1
If there are an equal number of attack and retreat inputs then the
majority value is defined to be any default value

Example
The next diagram shows the data flow  messaging and aggregation
trees and the connections between them  for a system where

N  4 t  1

httpskmchandygithubioByzantineByzantineOralhtml

59

71124 347 PM

Distributed Algorithms

ByzantineByzantineOralhtml

Contents

Index



Fig4 Dataflow for 4 agents 1 of which is disloyal

Inductive Generation of the Data Flow
The basic unit of data flow which is replicated many times is shown
in the top diagram of the figure below The input to the unit is a node
mL of the message tree this unit is specified by Land the
message mL The output of the unit are nodes aL x of the
aggregation tree for all lieutenants x not in L
The base case of the induction is a node at depth t The input for the
base case is mL where L is a list starting with 0 and followed by t
lieutenants For the base case aL x  mL x for all x The base
case is illustrated in the lower diagram

Fig5 Structure of Dataflow
The data flow connecting a message node mL at depth d  t to
aggregation nodes aL x is shown below
httpskmchandygithubioByzantineByzantineOralhtml

69

71124 347 PM

Distributed Algorithms

ByzantineByzantineOralhtml

Contents

Index



Fig6 Structure of Dataflow
Message node mL feeds message nodes mL x The
connections between mL x and aggregation nodes aL x y are
specified by the data flow connecting nodes of depth d  1 shown in
the diagram by blue dotted lines
The value of an aggregation node is the majority of its inputs

aL i  majoritymL i x  L i  aL x i
For example

a0 1 2  majoritym0 1 2 a0 1 3 2 a0 1 4 2 a0 1 5 2 

Proof of Validity
We prove that for all nodes mL of the message tree if L is loyal
then for all i not in L

aL i  mL
The proof is by induction The base case is for message nodes at
depth t We prove that if validity holds for message nodes at depth
d  0 then it holds for message nodes at depth d  1

Base Case
See the lower diagram of figure 5 For a message node mL at depth
t

aL i  mL i
If L is loyal then mL i  mL and the result follows
httpskmchandygithubioByzantineByzantineOralhtml

79

71124 347 PM

Inductive
DistributedStep
Algorithms

ByzantineByzantineOralhtml

Contents

Index



See figure 6
A node L at depth d consists of d  1 agents Therefore there are at
least 3t  1  d  1 lieutenants that are not in L Because d  t
there are at least 2t not in L So at least t lieutenants not in L are
loyal and at most t of them are disloyal
Because L is loyal mL i  mL
By the induction assumption for each loyal lieutenant j not in L and
for each loyal lieutenant i not in L j aL j i  mL i  mL

aL i  majoritymL i j  L i  aL j i
The majority is taken over at least t  1 values equal to mL and at
most t values that are different from it And therefore

aL i  mL

Example
The next illustrates the proof of validity Message mL is shown in
red and the flow of correct messages is shown in red edges and red
nodes For example nodes mL i mL j mL i j mL j i
are red because agents i j are loyal
A disloyal agent is represented by the symbol e The output of a
disloyal agent is unknown and is shown in black Node al i gets
more than 2t red inputs and at most t black inputs and hence the
majority of its inputs is red

Fig7 Illustration of Validity
httpskmchandygithubioByzantineByzantineOralhtml

89

71124 347 PM

Proof
of Algorithms
ConsensusContents
Distributed

ByzantineByzantineOralhtml

Index



We will prove consensus for nodes at depth d if the number of faulty
nodes is at most t  d

Base Case d  t
In this case there are no disloyal lieutenants For each i j mL i
and mL j are arbitrary however mL i  mL j

aL i j  mL i and aL j i  mL j Therefore the inputs
to aL i and to aL j are identical and the result follows

Inductive Step d  t
If the general is loyal then consensus follows from validity
There are at most t  d faulty nodes If the general is disloyal then
there at most t  d  1  t  d  1 disloyal lieutenants
Therefore the induction assumption holds for mL x Therefore

aL i k  aL i j

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioByzantineByzantineOralhtml

99

71124 350 PM

Distributed Algorithms

CryptoBitCoinhtml

Contents

Index



Introduction to Bitcoin
This module introduces the algorithm underlying
BitCoin
Bitcoin is based on cryptography and distributed consensus We
discussed aspects of cryptography required for Bitcoin in an earlier
module Next we study the distributed consensus algorithm used by
BitCoin This Princeton University book has a superb and longer
description of consensus in Bitcoin
We discussed distributed consensus in the modules on Paxos and
Byzantine Generals with written and oral messages The specification
of consensus is weaker in Bitcoin and the algorithm used to obtain
consensus is different from those used in Paxos and Byzantine
Generals written and oral algorithms The Byzantine Generals
algorithms assumes that the algorithm operates in rounds whereas
the Bitcoin algorithm doesnt require synchronous rounds in which all
agents participate The Paxos algorithm does not guarantee progress
whereas Bitcoin requires progress with high probability you wouldnt
want to use coins if you had to wait a long time to buy anything

No trusted agent
In an earlier module we described an algorithm that had many of the
features that we expect from a cryptocurrency That algorithm had
however a characteristic which is problematic to some It relies on a
trusted agent The trusted agent could be the Federal Reserve in the
US or a central bank that manages a currency Two of many reasons
given for mistrusting banks are that 1 people may want to execute
transactions in secret giving only their public keys and 2 central
banks may be able to print money whereas some cryptocurrencies
such as Bitcoin limit the total amount of coins that can ever exist
The Bitcoin algorithm is a modification that eliminates the trusted
agent from the algorithm given in the previous module

No assumptions about numbers of agents
The Byzantine Generals algorithm uses an upper bound on the
number of faulty agents Paxos assumes that the total number of
httpskmchandygithubioCryptoBitCoinhtml

114

71124 350 PM

CryptoBitCoinhtml

agents is known The Bitcoin algorithm makes no assumptions about

Distributed Algorithms

Contents

Index

numbers of faulty and nonfaulty agents other than that there are a
large number of agents



Incentives and transaction fees
When a currency is managed by a single trusted agent such as a
bank we assume that the bank gets some reward for its service or is
paid by a government to carry out this service The Bitcoin algorithm
pays agents with Bitcoins for checking the validity of transactions
This payment consists of new coins that are mined More about
mining later

A First Proposal for an Algorithm
How can we modify the algorithm we described earlier so that it
works without a trusted agent Lets try this modification Select
random agents to play the role of the trusted manager
A step of the algorithm is as follows A single agent is chosen
randomly to play the role of the trusted manager This agent receives
and validates transactions gathers some of the transactions into a
block appends the block to the block chain and broadcasts the
updated block chain The other agents update their copies of the
block chain when they receive this value The system waits for all
agents to update their copies and then executes the next step

Challenges of the Proposed Algorithm
This algorithm has several challenges
1 Selecting a single agent How can the collection of agents
select a single agent to add a block to the block chain The
selection of a single agent requires all agents to reach a
consensus about which agent to select So solving the problem
this way would require solving another consensus problem The
Bitcoin algorithm does not select a unique agent to add a block
to the block chain however it uses an ingenious mechanism to
ensure that multiple agents dont attempt to add blocks at
about the same time
2 Synchronization How can the collection of agents wait long
enough to ensure that all agents have updated their copies of
the ledger to the most recent version before the ledger is
modified again

httpskmchandygithubioCryptoBitCoinhtml

214

71124 350 PM

CryptoBitCoinhtml

Consider the following example scenario All agents have the

Distributed Algorithms

Contents

Index

same copy x of the ledger at some point t Agent B selected
randomly to act as the trusted agent appends transaction y to



the ledger at a later point t at which point Bs copy is x y
Then agent C selected randomly to act as the trusted agent
appends transaction z to the ledger at a later point t If Cs
copy is still x because it has not as yet been updated to x y
then after C appends z to the ledger Cs copy becomes x z

A key property of the algorithm with the trusted
agent is that two copies of the ledger are either
identical or the longer copy consists of additional
transactions appended to the shorter copy

With this property two copies of the ledger are either identical
or the shorter copy can eventually catch up to the longer copy
by merely by appending more values
In the example B may receive information about transaction z
after receiving information about transaction y whereas C may
receive this information in the reverse order which leaves Bs
copy as x y z and Cs copy as x z y In this case the copies
remain different forever
The Bitcoin algorithm does not guarantee synchronization
however its mechanism helps to make many agents append
blocks in the same order
3 Incentives Why should an agent chosen to play the role of
trusted agent agree to play that role Whats the incentive Why
wouldnt the trusted agent do nothing at all execute its step
slowly
4 Untrustworthy Agents The randomlychosen trusted manager
may not be trustworthy You can imagine what may go wrong in
the previous algorithm if the bank was dishonest
Next lets look at how the Bitcoin algorithm addresses challenges 1
and 2 Well look at challenges 3 and 4 later

Selecting a Single Random Agent
How can an arbitrary set of agents some of whom may be malicious
and where the size of the set is unknown pick a random agent
httpskmchandygithubioCryptoBitCoinhtml

314

71124 350 PM

CryptoBitCoinhtml

Using
Puzzles
to Select Contents
a Single Agent
Distributed
Algorithms
Index



Lets look at a simple situation several people solve puzzles in the
same room When a person solves her puzzle she yells I won
When a person hears that somebody else has won she stops solving
her puzzle
If everybody starts at the same instant and take the same time then
there will be collisions  many will claim to win at the same time If
however the time to solve a puzzle is a random variable with a flat
distribution then collisions are unlikely Bitcoin uses the puzzlefriendly property of cryptographic hash functions discussed in the
previous module
Now instead of people being all in the same room assume that they
are competing across a network When a person solves a puzzle she
broadcasts a I won message When a person working on a puzzle
gets a I won message from somebody else she stops working on
her puzzle
Collisions are likely if the expected time to solve the puzzle is small
say a millisecond compared with the expected time say a minute
for a message broadcast by one person to reach others Message
delays may cause multiple people to solve their puzzles before
receiving I won messages Collisions are unlikely when times to
solve puzzles are much greater than message delays
We could attempt to use timestamps When a person solves her
puzzle she broadcasts a I won message and the time at which she
finished solving the puzzle If a person gets a I won message with
an earlier timestamp then she concedes This approach is
problematic because a devious agent may not solve the puzzle or
may set her timestamp to an earlier value

Puzzles in Bitcoin
Next lets look at the puzzles used in Bitcoin Each agent has its own
copy of the block chain An agent A collects a set trans of
transactions that havent as yet been added to As copy of the block
chain Agent A proposes to append a block to the chain where the
block consists of the set trans in the following way
Let ptr be the pointer to agent As copy of the block chain Agent A
can add a block containing trans to the chain only if it proves that it
has solved the following problem  the puzzle
httpskmchandygithubioCryptoBitCoinhtml

414

71124 350 PM

Find a number called nonce such that

Distributed Algorithms
Contents
Hnonce  ptr  trans  target

CryptoBitCoinhtml

Index



where  is the concatenation operator  and target is a given value
For the time being assume that target is a constant later well see
that it decreases very slowly over time The smaller the value of

target the greater the expected time to solve the puzzle
The time to solve a Bitcoin puzzle is a random variable with a flat
distribution Each proposer of a block is probably solving a different
puzzle because the block of transactions that it is aggregating is
likely to be different from that of other proposers Agents have
different amounts of computing capacity and the time to solve a
puzzle decreases with capacity Agents are unlikely to start solving
their puzzles at the same instant For these reasons it is possible but
unlikely that many agents will solve their puzzles at the same time
Using puzzles to identify a single random agent leaves us with at
least three challenges 1 Collisions will occur 2 agents may be
devious  they may claim to have solved puzzles when they havent
and 3 agents with computing power that far exceeds those of
others will solve their puzzles faster than others do  and so though
agents are selected randomly those with large computing power are
likely to be selected more often

Attempts at Synchronization
When an agent A appends a new block B to a block chain L it
broadcasts the new chain L  B This is analogous to a person
shouting I won in the example given earlier
When a nondevious agent A which proposes to extend chain L
gets a message saying that L has already been extended to L  B
then A stops attempting to append a block to L Instead A starts
again with a new set of transactions that it proposes to append to the
extended chain L  B
If the message delay between agents A and A is small compared to
the time to solve puzzles then a collision between A and A is
unlikely but still possible So it is possible that A broadcasts L  B
while A broadcasts L  B at about the same time So different
agents may have different copies of the block chain What is the
equivalent of the true systemwide block chain when different
agents have different copies
httpskmchandygithubioCryptoBitCoinhtml

514

71124 350 PM

CryptoBitCoinhtml

The Bitcoin algorithm does not use synchrony to deal with this issue

Distributed Algorithms

Contents

Index

The problem of different copies of the block chain extant at the same
time is handled in an ingenious asynchronous way that we describe



later

Managing Concurrent Updates
A key step of the Bitcoin algorithm that updates local copies of block
chains is as follows After an agent creates a block and appends the
newly created block to its local copy it broadcasts its copy of the
block chain

When an agent A gets a message containing a copy of
another agents block chain agent A sets its local copy to
the block chain in the message if and only if the length of
the block chain in the message exceeds the length of As
local copy

Lets look at a scenario For this scenario X and Y are single blocks
Assume that agent As copy of the block chain is L when A receives
a message containing the block chain L  X Because the length of
the block chain L  X is bigger than As copy A sets its copy to
L  X
Now suppose agent A gets a message containing the block chain
L  Y  what does A do Agent A ignores the message because the
length of L  Y does not exceed that of As current copy L  X

Continuing Collisions
Lets continue the above scenario Can block Y become part of As
chain or will it remain forever an orphan block as far as A is
concerned
Heres a possible scenario An agent with a block chain copy L  X
solves its puzzle and appends a block X1 to get a new copy

L  X  X1 of the block chain which the agent broadcasts At the
same time another agent with a block chain copy L  Y  solves its
puzzle and appends a block Y1 to get a new copy L  Y  Y1 which
is broadcast If A receives L  Y  Y1 before receiving
L  X  X1 then A will set its chain to L  Y  Y1 and then
reject L  X  X1
httpskmchandygithubioCryptoBitCoinhtml

614

71124 350 PM

CryptoBitCoinhtml

You can construct a scenario with a sequence of collisions between

Distributed Algorithms
Contents
Index
agents appending blocks Xi and other agents appending blocks Yj
so that As chain switches back and forth between X and Y values



Long sequences of collisions are unlikely and the longer the
sequence the less the probability of continuing collisions
So how can an agent determine whether a block is in the chain And
so how can an agent find out if a transaction has been executed You
sell your used bicycle to somebody for coins but how do you know if
that transaction becomes part of the block chain when different
agents have different copies And so how do you know that you can
spend those coins that you should have received for your bicycle

Confidence that a Block is in the Chain
In this section we discuss the behavior of nondevious agents we will
show how the algorithm handles devious agents later Suppose an
agents copy of the block chain is X  X1  X2    XK  and
another agents copy is Y    where  represents arbitrary
values What is the likelihood that Y  X

Y can be different from X only if there are a sequence of K or more
collisions And the likelihood of a sequence of collisions decreases
with K  Likewise the likelihood that an agent never receives a block
chain containing X decreases with time and so decreases with K 
So if K is large then with very high probability X is part of every
agents block chain
Now suppose an agents copy of the block chain is

L  X  X1  X2    XK What is the likelihood that another
agents copy is L  Y    where L is an arbitrary sequence
By the same argument when if K is large then with very high
probability X is part of every block chain
For practical purposes many agents assume that if K  6 then
L  X is a prefix of most agents block chains See the Princeton
Bitcoin book
Suppose agent A gets N Bitcoins in transaction X If K  0 then
an agent cant be confident that A ever received these coins because
this transaction may not persist in the block chain As K increases
agents become more confident that the transaction is in the block
chain and that A did indeed receive these coins

httpskmchandygithubioCryptoBitCoinhtml

714

71124 350 PM

CryptoBitCoinhtml

Fig1

Distributed Algorithms

httpskmchandygithubioCryptoBitCoinhtml

Contents

Index



814

71124 350 PM

CryptoBitCoinhtml

Fig1 More Confidence in Older Blocks in the Chain

Distributed Algorithms

Contents

Index



What happens to Orphan Transactions
An agent may append a block Y to its chain and this
block may be dropped from the chains of all agents and
never reappear after some point We saw a scenario in
which this happens Such a block is an orphan because
no agent has a record of that transaction after some
time If an orphan block contains the transaction in which
you sold your bicycle in exchange for coins then will you
ever be able to spend your coins Yes you will get your
coins as we see next
Agents aggregate transactions that have not appeared in
the agents block chain into blocks and propose to
append these blocks to the chain A transaction that does
not appear in block chains will be agrregated eventually
by some agent and inserted into a block in the chian
Though the orphan block disappears the transactions in
the block do not

Incentives
Next looks look at challenge number 3 Why should an
agent create blocks of validated transactions
Because the agent gets paid Payment is from either a
block reward or transaction fees
Block rewards
An agent that creates a block gets a specified number of
Bitcoins for itself as a reward called a block reward The
Bitcoins in a block reward are created by making the
block these Bitcoins dont exist until the block is created
The process of making blocks and acquiring block
rewards is called mining Mining is the only way of
creating new Bitcoins
When Bitcoin started the reward for creating a block was
50 Bitcoins The reward halves after the creation of a
certain number 210000 of blocks The reward was
reduced to 25 in 2013 and to 125 in 2018 Block rewards
will vanish at some point in the future The total number
httpskmchandygithubioCryptoBitCoinhtml

914

71124 350 PM

CryptoBitCoinhtml

of Bitcoins that can ever be created has an upper bound

Distributed Algorithms
about 21 million

Contents

Index



Bitcoins can be lost An agent may lose the hash pointer
to the transaction that gave the agent ownership of the
coin or an agent may lose its private key
Even when block rewards vanish miners will continue to
mine provided that they get paid transaction fees A
transaction fee is a payment by payers and payees to
miners Transaction fees are voluntary A highfee for a
transaction is an incentive to miners to put this
transaction into a block quickly So its possible that
agents that offer no fee or low fees may have to wait
longer for their transactions to enter the block chain
Incentives are critical for Bitcoin Miners get paid to get
their blocks into the longterm consensus block chain
Miners have an incentive to police the block chain
because they dont get paid for appending erroneous
blocks If a miner appends an erroneous block to the
chain then other miners wont extend chains containing
the erroneous block and so the erroneous block will
become an orphan
Any agent can check whether its copy of the block chain
is valid however agents making ordinary transactions
dont need to do so because there are many miners each
of whom has an incentive to ensure that the block chain
is legitimate

Attacks
Next looks look at challenge number 4

Stealing coins
Can an agent steal a coin from an agent X by appending
a block to the chain where the block contains a
transaction in which X gives coins to Y 
No this cant happen thanks to cryptography A
transaction into which X puts coins is valid only if X
signs the transaction Y cannot forge Xs signature and

httpskmchandygithubioCryptoBitCoinhtml

1014

71124 350 PM

CryptoBitCoinhtml

so Y cannot create blocks that contain such fraudulent
Distributed Algorithms
Contents
Index
transactions



Double spend
Can an agent spend the same coin twice Can an agent
buy something without paying for it
Consider the following transaction using conventional
checks issued by banks A buyer gives a seller a check
for 100 000 for a house The house is put in escrow
When the check clears and the seller receives the
payment the buyer gets possession of the house The
legal process that includes notaries real estate agents
and banks helps ensure that the transaction concludes
correctly or is aborted correctly
Next lets look at a transaction in which a person buys a
video online by paying the seller Bitcoins The buyer and
seller know each other by their public keys and by their
online addresses The buyer broadcasts the transaction
in which the buyer gives the seller the payment in
Bitcoins The amount is specified as a pair transaction
id array index described in the section pay transactions
in the module introducing crypto currencies
A miner puts the transaction into a block X appends the
block to its copy L of the block chain and broadcasts the
extended block chain L  X When the seller gets a
copy of the block chain L  X the seller concludes that
it has received the payment from the buyer because the
transaction has been recorded in a block chain So the
seller gives the video to the buyer
The buyer cheats The buyer creates a transaction in
which the buyer transfers the same Bitcoins to the buyer
itself A miner creates a block Y that includes this
transaction A miner who has only received block chain L
and hasnt yet received chain L  X appends Y to L
to get a chain L  Y  and broacasts L  Y 
Now we have a situation in which one miner broadcasts a
legitimate block chain L  X and a different miner
broadcasts a legitimate block chain L  Y  Both chains
have the same length A miner with chain L  X does
httpskmchandygithubioCryptoBitCoinhtml

1114

71124 350 PM

CryptoBitCoinhtml

not know at this point that another minder has chain

Distributed Algorithms
Contents
Index
L  Y  So miners will extend both block chains Note
that the algorithm will not permit chains L  X  Y or
L  Y  X



Weve seen this situation before look at block collisions
described earlier in this module Both block chains will be
extended but eventually with very high probability one of
the blocks X or Y will drop out of chain
How should sellers protect themselves
What is the equivalent of the buyers check clearing in the
bank
A seller should give the item to the buyer only after the
transaction appears with high confidence in a block in the
chain  see Figure 1 The seller listens to block chains
broadcast by miners If the seller gets a block chain

L  X  L where L is itself a long block chain then
the seller has high confidence that the transaction is in
the permanent record
The seller waits to get block chains in which its
transaction appears in a block which is then followed by
m blocks for large m The larger the value of m the
greater the sellers confidence but the longer the buyer
has to wait to get paid length of the extension L A
value of m  6 gives adequate confidence in most
cases

Fraudulent miners
A miner gets paid for every block the miner creates so
why shouldnt the miner create fraudulent blocks and get
paid for them
The answer is the same as that for the doublespending
attack A miner may have created a block and appended
it to the chain however a suspicious agent and we hope
that all agents are suspicious will not accept the block
until many blocks have been appended to the chain after
it Other miners wont append their blocks to an invalid
one The invalid blocks will become permanent orphans

httpskmchandygithubioCryptoBitCoinhtml

1214

71124 350 PM

CryptoBitCoinhtml

and so the fraudulent miner wont be able to spend the

Distributed Algorithms

coins in these blocks

Contents

Index



Fifty One Percent Attacks
A 51 attack can be carried out by an agent that has
more mining power eg 51 or more than all other
agents combined The higher the proportion of mining
power of a single agent the greater the chances that
attacks by that agent will succeed You can see the
danger of a single agent having predominant mining
power by thinking about an agent with say 99 of the
total mining power This agent can mine so much faster
than others that it can manipulate the block chain in
many ways It can create doublespend transactions and
deny services to some transactions
A group of miners can collude to gain predominant
mining power Also miners can rent Cloudbased
systems for mining  as opposed to having to own huge
data centers An attacker can rent a large system for the
specific purpose and duration of an attack The public
may not know if and when such attacks are successful
because cryptocurrencies do not have an incentive to
publish such attacks

Denial of service
Can agents collude so that an agent Xs transactions
never get into blocks and so never get processed
An agents identity does not appear in a transaction only
a public key does An agent can create new public keys at
will So lets ask another question can agents collude so
that transactions with a specific public key do not get into
blocks
Only an agent that can solve puzzles in reasonable time
can make blocks These agents have significant
computational power One can concoct a situation where
many agents with significant computation power collude
to avoid transactions from a specific public key This
could have the effect of slowing processing of certain
transactions However such a situation isnt likely to arise
because agents have an incentive to create blocks and
httpskmchandygithubioCryptoBitCoinhtml

1314

71124 350 PM

CryptoBitCoinhtml

so they compete  rather than collude  with each other

Distributed Algorithms

Contents

Index

Colluding agents with massive computing power may
help to deny or slow service to a public key but not to



another agent because agents can create public keys at
will

Further Reading
There are many issues that we have not covered This
material only covers the basics from the point of view of
distributed algorithms

Review
1 What is a block chain
2 How does the algorithm deal with the situation in
which one agent receives a message to extend its
copy of the block chain with a block X while
another agent receives a message to extend its
copy of the block chain with a different block Y 
3 Could there be an infinite sequence of collisions Is
that likely
4 What is mining for cryptocurrency Suppose only a
small number say two organizations mined most
say 99 of Bitcoins Would that be a problem
5 Why is double spending unlikely to be successful

K Mani Chandy Emeritus Simon Ramo Professor
California Institute of Technology

httpskmchandygithubioCryptoBitCoinhtml

1414

71124 552 PM

Distributed Algorithms

DiffusingComputationsScenarioActiveIdlehtml

Contents

Index



A Scenario of Active  Idle
Agents

Fig 3 Scenario Initial Step

Scenario

httpskmchandygithubioDiffusingComputationsScenarioActiveIdlehtml

18

71124 552 PM

Scenario

Distributed Algorithms

DiffusingComputationsScenarioActiveIdlehtml

Contents

Index



Scenario

Scenario

Scenario

httpskmchandygithubioDiffusingComputationsScenarioActiveIdlehtml

28

71124 552 PM

Distributed Algorithms

DiffusingComputationsScenarioActiveIdlehtml

Contents

Index



Scenario

Scenario

Scenario

httpskmchandygithubioDiffusingComputationsScenarioActiveIdlehtml

38

71124 552 PM

Distributed Algorithms

DiffusingComputationsScenarioActiveIdlehtml

Contents

Index



Scenario

Scenario

Scenario

httpskmchandygithubioDiffusingComputationsScenarioActiveIdlehtml

48

71124 552 PM

Distributed Algorithms

DiffusingComputationsScenarioActiveIdlehtml

Contents

Index



Scenario

Scenario

Tree Structure

httpskmchandygithubioDiffusingComputationsScenarioActiveIdlehtml

58

71124 552 PM

Distributed Algorithms

DiffusingComputationsScenarioActiveIdlehtml

Contents

httpskmchandygithubioDiffusingComputationsScenarioActiveIdlehtml

Index



68

71124 552 PM

Distributed Algorithms

DiffusingComputationsScenarioActiveIdlehtml

Contents

httpskmchandygithubioDiffusingComputationsScenarioActiveIdlehtml

Index



78

71124 552 PM

Distributed Algorithms

DiffusingComputationsScenarioActiveIdlehtml

Contents

Index



K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDiffusingComputationsScenarioActiveIdlehtml

88

71124 604 PM

Distributed Algorithms

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

Contents

Index



Resource Management
Drinking Philosophers
This module describes algorithms for The
Distributed Drinking Philosophers Problem by
which distributed agents share indivisible resources
such as exclusive access to files

Key Ideas
1 This module describes algorithms by which distributed agents
share indivisible resources such as exclusive access to files in
a fair way
2 The module shows how to use a total ordering of priorities to
share resources fairly The dining philosophers algorithm given
in an earlier module uses a partial ordering
3 We show how time  readings from local clocks of agents  is
used to obtain priorities that are totally ordered
The description of the algorithm in this module is not as detailed as
that given for dining philosophers You can define a formal
specification and carry out a detailed proof for this algorithm in
almost exactly the same was as for dining philosophers

The Problem
A set of agents shares a set of indivisible resources Exclusive
access to a file is an example of an indivisible resource
The lifecycle of an agent is the same as in Dining Philosophers 1
executing outside the critical section 2 waiting to enter a critical
section and 3 executing in the critical section The problem is
identical to Dining Philosophers except for the transition to the critical
section
An agent executes outside the critical section without holding any
resources An agent may execute outside critical sections for ever or
httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

111

71124 604 PM

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

it may start waiting to enter a critical section When an agent starts

Distributed Algorithms

Contents

Index

waiting to enter a critical section it waits to get exclusive access to a
nonempty subset of the resources It continues waiting until it gets all



the resources for which it waits While it waits it does not change the
subset of resources for which it waits The agent continues to hold
these resources when it executes in the critical section An agent
remains in a critical section for only a finite number of steps and then
starts executing outside the critical section at which point it no longer
needs resources
For example an agent needs exclusive access to a set of files for it to
execute in its next critical section and it waits until it is given this
access While it is in the critical section it continues to have exclusive
access to these files When it is executing outside the critical section
it does not need access to these files Each time an agent starts to
wait it may wait for a different set of files

Fig1 Agent Lifecycle
The ideas in this module can be used to manage agents that require
read or write access to files Multiple agents can have read access to
a file concurrently While an agent has write access to a file no other
agent can have access to the file A homework problem deals with
readwrite access
Drinking Philosophers
The drinking philosophers name is another example of an attempt at
CS humor A philosopher is in one of three states tranquil thirsty or

drinking A philosopher may remain tranquil for ever or it may
become thirsty for one or more beverages It remains thirsty until it
gets all the beverages for which it waits Only when a thirsty
httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

211

71124 604 PM

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

philosopher gets all the beverages for which it waits does it start

Distributed Algorithms

Contents

Index

drinking It continues to drinking all these beverages until it becomes
tranquil again Philosophers drink for only finite time



A philosopher that enters the tranquil state remains in that state for
at least a constant  amount of time So a philosopher cant go from
drinking to thirsty instantaneously or in an arbitrarily small amount of
time

Fig1 Drinking Philosophers
A beverage can be held by at most one philosopher Imagine theres
only one bottle of each beverage in the system and philosophers
send bottles to each other One philosopher can drink vodka and cola
while another philosopher drinks gin and tonic However one agent
cannot drink vodka and cola while another drinks vodka and orange
juice

An Algorithm
There are many algorithms for this problem here we discuss one
Each beverage is an indivisible unique token A token is exchanged
between agents and a manager of the token We assume that each
token has its own manager  this assumption is merely for
convenience of exposition
Messages
1 request An agent sends a request for a beverage to a manager
A request is a pair agent_id request_priority the id of the
requestor and the priority of the request

httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

311

71124 604 PM

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

2 beverage A manager sends a beverage to a requesting agent

Distributed Algorithms

Contents

Index

and agents send beverages back to managers A beverage is
uniquely identified by its name



3 demand A manager sends a demand to an agent for the
beverage that the manager manages and that the agent holds
Agent Actions
1 When an agent becomes thirsty it sends requests to managers
for all the beverages that it needs to drink
2 If a thirsty agent gets a demand to return a beverage to a
manager then the agent returns the beverage and sends
another request for the beverage The priority of this new
request is the same as the priority of this agents last request
3 If a thirsty agent gets all the beverages that it needs to drink
then it starts drinking
4 When an agent finishes drinking it returns all the beverages that
it holds to the managers of the beverages
Manager Actions
A manager has local variable hr hp which is the id of the agent to
which the manager has most recently sent the beverage and the
priority of the request made by that agent hr is an acronym for
handling requestor and hp is an acronym for handling priority If the
manager holds the beverage then this variable is empty Null
A manager also maintains a priority queue of pending requests
ordered by priority
The actions of a manager are as follows
1 If a manager gets a request r p while it holds a beverage
then it sends the beverage to the requestor r and sets

hr hp  r p
2 If a manager gets a request r p while it does not hold the
beverage and hp  p then the manager inserts the request
r p into the priority queue of pending requests
3 If a manager gets a request r p while it does not hold the
beverage and hp  p then
1 the manager sends a demand to hr to return the
beverage if the manager has not already sent that
demand and
2 the manager inserts the request r p into its priority
queue of pending requests
httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

411

71124 604 PM

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

4 If a manager gets a beverage and it has no pending requests

Distributed Algorithms

Contents

Index

then the manager holds the beverage and sets the handling
requestor and priority to empty



5 If a manager gets a beverage and it has pending requests then
let r p be the request at the head of the priority queue ie
the request with the highest priority It sends the beverage to
requestor r removes r p from the queue of pending
requests and sets hr hp  r p

Example
The example shows a scenario The system has two agents Maya
and Liu both of whom are tranquil in the initial state There are three
beverages Tea coffee and milk Initially these beverages are with
their managers
The next diagram stage 1 shows the state after Maya gets thirsty for
tea and milk So she sends requests to the managers of tea and milk
The priority of this request is 2 We will discuss how priorities are
obtained later

Fig3 Stage 1
The next diagram stage 2 shows the situation after the managers of
tea and milk get requests from Maya and respond by sending the
beverages to Maya because there are no pending requests for these
beverages The beverages tea and milk are in the channel to Maya

httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

511

71124 604 PM

Distributed Algorithms

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

Contents

Index



Fig4 Stage 2
The stage 3 diagram shows a state after Liu becomes thirsty for
coffee and milk So she sends requests for coffee and milk to the
managers of these beverages The priority of the request is 5
Maya has received the milk beverage but tea is still in the channel So
Maya remains thirsty

Fig5 Stage 3
The stage 4 diagram shows a state in which the coffee manager
receives Lius request and sends coffee to Liu because there are no
pending requests for coffee When the milk manager gets Lius
request the manager puts the request on the priority queue of
pending requests At this point the queue has only Lius request The
milk manager demands milk back from Maya because her request
has priority 2 whereas Lius request has priority 5 Maya is still thirsty
because the tea hasnt arrived yet
httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

611

71124 604 PM

Distributed Algorithms

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

Contents

Index



Fig6 Stage 4
Next Maya receives the demand for milk and responds by sending
the milk back to the milk manager Maya also resends its original
request for milk with priority 2 to the milk manager Then Maya
receives tea Maya continues to be thirsty because she has only one
of the two beverages that she needs to drink Liu has coffee but she
remains thirsty because milk is in the channel from Maya to the milk
manager

Fig7 Stage 5
In stage 6 the milk manager has received Mayas request for milk
with priority 2 and received milk So the milk manager sends the milk
to respond to the highest priority request in the priority queue this
request is from Liu The milk manager puts Mayas request into the
queue of pending requests

httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

711

71124 604 PM

Distributed Algorithms

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

Contents

Index



Fig8 Stage 6
In stage 7 Liu has received both milk and coffee and so she is
drinking Maya is still thirsty holding tea while Mayas request for
milk is in the queue of pending requests for milk

Fig9 Stage 7

How Priorities Change
If priorities dont change then the agents with high priorities may
continue to go rapidly through the tranquil thirsty drinking cycle while
other agents remain thirsty for ever
One way to assign priorities is as follows Associated with each
request is a timestamp which is the time read from the requestors
local clock at the instant at which the request is made A requests
timestamp does not change after the request is created
httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

811

71124 604 PM

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

A requests priority is a pair timestamp requestors id with priorities

Distributed Algorithms

Contents

Index

compared lexicographically and lower values having higher priority
So requests made earlier have higher priority than requests made



later The requestors id is used to break ties
What are the requirements of agents local clocks that ensure that all
thirsty philosophers drink eventually
A Minimum Requirement on Clocks

An agents clock must tick forward between successive requests by
the agent If the agents clock remained stuck at the same value for
ever then the agent using that clock may get the highest priority for
ever and go through tranquil thirsty drinking cycles infinitely which
makes other agents remain tranquil for ever
Assume that each clock reading is an integer for example the
number of picoseconds since January 1 1900 NTP units are 232 of
a second The clock ticks forward between successive requests by
the same philosopher because the philosopher remains in tranquil
state for at least  units of time where  is a positive constant Treat
each agents clock tick as an event
Local clocks of agents may drift apart but lets assume that the
magnitude of the difference between clock readings of different
agents is bounded
Even if the philosopher makes a new request when its clock ticks
forward by one unit eventually the timestamp of a request from that
philosopher will exceed T for any value of T  This ensures that while
a philosopher is thirsty another philosopher cannot overtake it for
ever

Proof of Correctness
The proof of safety  multiple philosophers dont hold the same
beverage at the same time  is straightforward It follows because a
token is at exactly one agent or in exactly one channel
Lets prove that a thirsty philosopher v with a request with timestamp
T drinks eventually Let ti be the reading of philosopher is clock
Each agents clock reading eventually exceeds T
We observe that each agents clock ticks forward

i   ti    ti    1
httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

911

71124 604 PM

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

Therefore each is clock eventually reads a value greater than T 

Distributed Algorithms
using transitivity of 

Contents

Index



i   ti    ti  T 
From the previous formula and taking disjunction over all values of  

i 

true  ti  T 

Because clock readings never go back in time ti  T is stable and
therefore

i 

true  alwaysti  T 

Let Q be the predicate that all clocks read values that exceed T 

Q  i  ti  T 
From the above formula and because X  alwaysY  and

X  alwaysY  allows us to deduce X  alwaysY  Y 
true  alwaysQ
The number of pending requests with timestamps less than T
decreases
From the above formula

v thirsty  v drinking  Q  v thirsty  Q
Next we will prove that if v is thirsty and all clocks read values that
exceed T  then v will drink eventually

v thirsty  Q  v drinking
Let req be the number of pending requests with timestamps less
than T  We will prove

v thirsty  Q  req  k  v drinking  v thirsty  Q  req  k
This proof is straightforward The request with the lowest timestamp
gets all the resources it needs

v thirsty  Q  req  0  v drinking
The result follows using the rules for variant functions

Review
1 In the algorithm each manager of a resource maintains a
priority queue of requests for the resource Is the algorithm
httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

1011

71124 604 PM

DistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

correct if managers maintain firstcomefirstserved queues

Distributed Algorithms

Contents

Index

rather than priority queues
2 Show that the proposed variant function is correct show that it



does not increase while an agent remains thirsty and show that
it decreases eventually

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDistributedCollaborationDrinkingPhilosophersDrinkingPhilosophershtml

1111

71124 341 PM

Distributed Algorithms

PaxosStableMajorityhtml

Contents

Index



Paxos Consensus in Faulty
Systems
Part 1
Algorithms by which agents reach a consensus on a value are central
in many applications Paxos is an algorithm by which agents attempt
to reach a consensus in distributed systems in which agents may
halt be arbitrarily slow and messages may be duplicated lost and
delivered out of order In this page we describe and prove a
nondeterministic sequential representation of Paxos and describe
the distributed algorithm in the next page

Introduction
Paxos is a consensus algorithm for systems in which messages may
be lost multiple copies of a message may be delivered messages
may not be delivered in the order sent agents may be arbitrarily slow
and agents may stop From the FLP theorem there is no algorithm
that guarantees that consensus among agents will be reached in
such systems Paxos may not terminate We will discuss ways to
improve the likelihood of termination
Consider the problem of maintaining a ledger consisting of a
sequence of transfers of funds into and out of accounts Assume that
the ledger is implemented using copies at multiple agents The
copies may not be synchronized however there must exist a
consensus copy We call the sequence of operations on the ledger a

chain of operations and we call the the consensus value a consensus
chain
Suppose two clients simultaneously request extensions to a
consensus chain by transferring funds from an account x to two
different accounts Account x may not have funds to allow both
transfers and so the consensus chain can be extended by at most
one of the transfers Clearly the system must maintain a consensus
regarding the order of operations in the chain

httpskmchandygithubioPaxosStableMajorityhtml

18

71124 341 PM

PaxosStableMajorityhtml

Agents that propose extensions to consensus chains are called

Distributed Algorithms

Contents

Index

clients Copies of the chain are stored at agents called servers



Notation prefix
A prefix of a sequence S is an initial subsequence of S For example
A B is a prefix of A B C but A C is not a prefix of A B C
The empty sequence is a prefix of all sequences A sequence is a
prefix of itself We use the notation  for prefix as in A B  A B
C

Specification of Consensus
1 A consensus isnt changed
For all consensus chains c and d in a computation either c is a prefix
of d or d is a prefix of c

c  d  d  c
For example a consensus chain A B can be extended to form a
consensus chain A B C
A B and A C B cannot both be consensus chains in the same
computation

2 Every consensus chain is proposed by a client
For all consensus chains c in a computation There exists a client that
proposed c in the computation
This part of the specification merely says that consensus chains
cannot be arbitrary Later we define the specification in terms of
algorithm variables
Next we describe the agents  servers and clients  in the system

Servers
Each server q has a local variable qv which has two fields
1 qvs the chain stored at q and
2 qvt a sequence number that indicates when qv was last
written
A server q receives requests to read or write qv The only actions of
a server are to respond to requests from clients
httpskmchandygithubioPaxosStableMajorityhtml

28

71124 341 PM

Clients
Distributed Algorithms

PaxosStableMajorityhtml

Contents

Index



Each client receives a sequence of clock tick messages The intervals
between successive clock ticks are irrelevant for the correctness of
the algorithm but impact performance A client avoids waiting forever
for a reply from a server by only accepting replies that the client
receives before it receives its next clock tick message
A client repeatedly executes actions in which it reads and then writes
copies of chains stored at servers

Read
A client sends read requests to all servers Let R be the set of servers
from which the client receives replies before the client receives its
next clock tick If R has fewer than M elements where M is a given
constant then the action terminates without executing the write step
If R has M or more elements then a client proceeds to the write step

Write
A client p sends a request to all servers to write
pfqv for q in R
where f is a given function and the argument of the function is the
set of replies that p received
Write requests may get lost Let W be the set of servers that execute
write requests

Designing Paxos in Stages
We develop the algorithm in two stages

Paxos as a Nondeterministic Sequential Algorithm
First we represent Paxos as nondeterministic sequential algorithm P 
Exactly one client executes actions at a time in the sequential
program Failures of agents and channels are represented by
nondeterministic selection of servers that read and write values We
will prove that P satisfies specifications of consensus

Paxos as a Serializable Distributed Algorithm
In the second stage we develop a distributed algorithm Clients and
servers execute concurrently and so the action of one client may
interfere with the action of another A client p may read server values
httpskmchandygithubioPaxosStableMajorityhtml

38

71124 341 PM

PaxosStableMajorityhtml

and another client may modify these values before p writes these

Distributed Algorithms
values

Contents

Index



We will develop a serializable distributed algorithm for every
computation x there exists a computation y with the same steps as
x where exactly one client takes actions at a time in y We will show
that the proof of the sequential program is also a proof of the
distributed program

A Sequential Representation of Paxos
We develop Paxos in stages We begin by proving properties of the
following nondeterministic sequential program P  Nondeterminism in
the sequential program represents nondeterminism in both the
distributed program and in failures of agents and channels

Nondeterministic Sequential Program P
for n  1 to infinity
select a client p and subsets R W of servers
for q in W
qvs  pfqv for q in R
qvt  n

Many clients and servers execute concurrently in Paxos By contrast
exactly one client executes an action at a time in program P  We will
show that certain properties of P are also properties of Paxos
We prove properties of sequences of server state changes We now
restrict attention to iterations of P in which at least one server
changes state So hereafter we only consider iterations in which R
has at least M elements and W is nonempty

The Problem
The problem is to specify the following values so that the
specification for consensus is satisfied
1 M A client proceeds from the read step to the write step only if
it receives at least M replies to its read requests What should M
be

httpskmchandygithubioPaxosStableMajorityhtml

48

71124 341 PM

PaxosStableMajorityhtml

2 Consensus How is a consensus chain defined in terms of the

Distributed Algorithms

Contents

Index

server variable qv for all servers q
3 f A client executes a function f on the M or more replies that it



receives What is f

How Should You Solve The Problem
M Number of Replies
A client needs to receive at least M copies of chains to proceed to the
write step What is a reasonable value of M
Let N be the total number of servers We could set M  N and in this
case a client proceeds from the read step to the write step only if the
client receives chains from all servers This seems safe however a
client may never proceed to the write step because the client may not
receive a reply from a failed server The smaller the value of M the
greater the likelihood of the algorithm terminating sooner
Setting M  intN2  1 a majority is reasonable because any
two majorities have at least one element in common So if two
clients both proceed to the write step then both clients have received
replies from at least one common server

Consensus in terms of Server Variables
We define consensus as a value agreed upon by some number of
servers How many
We can define a consensus as a value agreed upon by all N servers
Here again the smaller the number of servers required the greater
the likelihood that a consensus will be reached Using the same
argument that we used for setting M to be a majority lets define
consensus as a value agreed upon by a majority

Consensus Majority of Servers Agree on a Consensus Value
s is a consensus chain in a computation of P exactly when there
exists a majority W of servers and an iteration number t where for
all q in W
qvs  s and qvt  t

httpskmchandygithubioPaxosStableMajorityhtml

58

71124 341 PM

PaxosStableMajorityhtml

So s is a consensus chain exactly when in iteration t for some

Distributed Algorithms

Contents

Index

t The set W of servers written in the iteration is a majority and s is
the chain assigned to qvs for all q in W



f Clients Write Requests
The argument of f is a list lst qv for q in R which is a list
of M or more elements
Case 1 All elements of lst are identical
If all elements of lst are identical then every element of lst is a
consensus chain Let c be any element of lst for example c 
lst0 The function returns the consensus chain c appended with
some value h
Case 2 Not all elements of lst are identical
If not all elements of lst are identical then let max_t be the element
of lst with the largest t value Return max_ts
The algorithm is given below

def flst
 if all elements of lst are identical
if alllst0  c for c in lst
c  lst0s
return cappendh
else
max_t  lst0
for c in lst
if ct  max_tt
return max_ts

max_t  c

Theorem The Algorithm Satisfies the
Specification
Proof
Part 2 of the specification follows directly from the algorithm
because the only assignments to qvs is pf Next we prove
part 1 We will show that if c is a consensus chain after an iteration
httpskmchandygithubioPaxosStableMajorityhtml

68

71124 341 PM

PaxosStableMajorityhtml

and d is a consensus chain after a later iteration then c is a prefix of

Distributed Algorithms
d

Contents

Index



Let s be a consensus at some point in a computation of P  Then
there exists t such that at the end of the nth iteration n  t there
exists a majority W of servers such that
For all q in W qvs  s and qvt  t
Because qvt does not decrease the following equation holds
Equation 1
For all n where n  t For all q in W qvt  t
Next we prove the following

Invariant
For all servers q if qvt  t then s is a prefix of qvs
This can be written as
For all servers q qvt  t  s  qvs

Proof of the Invariant
Base Case nth Iteration where n  t
The condition trivially holds for iteration n where n  t because
qvt  t in these iterations
Next consider the case where n  t If qv is modified in the
iteration then qvs  s If qv is not modified in the iteration then
qvt  t So the condition holds
Induction Step
Assume that the condition holds before iteration n for n  t and
show that it holds after the iteration
From property 1 and the induction hypothesis the following holds
before iteration n
For all q in W qvt  t  s  qvs
The argument lst of f is qv for q in R where R is a majority
Any two majorities have at least one element in common So there is
an element that is in both R and W Let this element be q Because
httpskmchandygithubioPaxosStableMajorityhtml

78

71124 341 PM

q is an element of W

Distributed Algorithms
Contents
qvt  t  s  qvs

PaxosStableMajorityhtml

Index



Let the value returned by function f be d We will show that c  d
Consider the two cases of lst
Case 1 All elements of lst are identical
Because qv is an element of lst every element of lst is identical
to qv So s is a prefix of the value d returned by the function
Case 2 Not all elements of lst are identical
If not all elements of lst are identical then the function returns
qvs where qv is the element with the highest iteration number
qvt There is an element q of lst where qvt  t So the
function returns qvs where qvt  t From the induction
hypothesis s is a prefix of the returned value d

Next
Next we develop Paxos a distributed consensus algorithm and prove
that Paxos satisfies the specifications for consensus by showing the
relationship between the distributed algorithm and the
nondeterministic sequential algorithm

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioPaxosStableMajorityhtml

88

71124 335 PM

Distributed Algorithms

TerminationDetection

Contents

Index



Termination Detection
A distributed computation has terminated when all agents are idle
and all channels are empty A termination detection algorithm is
executed by the operating system to determine whether a client
computation has terminated

Problem Definition
A computation terminates in states in which all channels are empty
and all agents are waiting to receive messages An agent is said to be
active while it is processing a message and idle while it is waiting to
process a message A terminated state is one in which all agents are
idle and all channels are empty
Let C s and C r be the numbers of messages sent and received
respectively on channel C  A computation is in a terminated state
exactly when
1 All agents are idle and
2 for all channels C  C s  C r 
The problem is to design an algorithm that detects whether the
computation is in a terminated state

How Should You Solve the Problem
Strategy
A strategy to solve detection problems is to start with the general
detection algorithm and then explore optimizations by using
properties of cuts Lets explore optimizations
The algorithm detects whether a channel is empty and it can do so
given the numbers of messages sent and received on the channel
without information about message contents What properties of
cuts come to mind to help us design an algorithm based on message
counts
We use Cut based on Counts of Messages Sent and Received which
is given again below
httpskmchandygithubioChannelSnapshotsTerminationDetectionhtml

13

71124 335 PM

TerminationDetection

There exists a cut past future exactly when the following two

Distributed Algorithms
conditions hold

Contents

Index



1 For all C  C s  C r 
where C s and C r are the numbers of messages sent and
received respectively on channel C  in past
2 If a step x of an agent is in past then steps at that agent
before x are also in past
The property suggests the following algorithm

A Termination Detection Algorithm
Agent Actions
When an agent changes state from active to idle the agent sends a
message to the observer This message contains C s for each output
channel and C r for each input channel of the agent
Observer Actions
The observer keeps only the latest message that it receives from
each agent For each channel C  let C s and C r be the latest value of

C s and C r  respectively that the observer has received
Initial Condition
All agents are idle C s and C r are the numbers of messages sent
and received respectively on channel C for all C 
Termination Detection

The observer detects computation has terminated if for all channels

C  C s  C r 

Proof of Correctness
We first prove that if the observer detects that the computation has
terminated then the computation has indeed terminated
Since the observer has detected termination for each channel C 
either C s  C r initially or the observer received messages
containing C s and C r such that C s  C r 
httpskmchandygithubioChannelSnapshotsTerminationDetectionhtml

23

71124 335 PM

TerminationDetection

Letpast future be a partition of the steps of the computation

Distributed Algorithms

Contents

Index

where past consists of steps at an agent before the agent sent the
messages to the observer containing C s and C r for channels C



incident on the agent If the agent sends no messages to the
observer then the agent has no steps in past
From the property Cut based on Counts of Messages Sent and
Received past future is a cut
From the definition of terminated state it follows that the state at this
cut is a terminated state Termination is a stable property  once
computation has terminated it remains terminated So if the state at
a cut of the computation is a terminated state then all succeeding
states are terminated states
Next we prove that if the computation terminates then the observer
detects termination The last message sent by each agent has counts
C s and C r of the numbers of messages sent and received
respectively for each of its output channels C  Because these are
the last messages sent when the algorithm terminates it follows that

C s  C r for all C 

Next
Next database deadlock detection

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioChannelSnapshotsTerminationDetectionhtml

33

71124 338 PM

Distributed Algorithms

PaxosConsensusImpossiblehtml

Contents

Index



Consensus
Central Ideas
1 Importance of consensus 2 Impossibility of consensus in
distributed systems with a faulty agent

Importance of Consensus
Algorithms by which groups of agents come to a consensus are
among the most fundamental problems in distributed computing
Why is consensus important There are many problems in which
messages are sent to groups of agents who collectively maintain a
common consensus state A bank may use a group of agents rather
than a single agent to maintain bank balances Multiple agents
reduce the possibility of systemwide failure due to the failure of a
single agent Managing replicated databases requires the replications
to come to a consensus on the sequence of transactions that is
applied to the database Cryptocurrency transactions also require
collections of agents to come to a consensus about sequences of
the transactions
In a control system with multiple and actuators the actuators have to
come to a consensus about the state of the environment so that they
can operate in concert A vehicle would crash if some actuators
caused the vehicle to accelerate while other actuators applied brakes
In some applications multiple agents have to elect a single leader
There are many problems in which a collection of agents have to
come to a consensus about something

Consensus Impossible with a faulty agent
Consensus is impossible with even a single faulty agent This was
proved in a paper published by Fischer Lynch and Patterson
You can get the idea of why consensus is not possible by considering
the following problem in which when message delays are finite but
arbitrarily long A collection of 2N  1 agents want to come to a
consensus about a color N of the agents pick blue and N1 pick red
httpskmchandygithubioPaxosConsensusImpossiblehtml

13

71124 338 PM

PaxosConsensusImpossiblehtml

One of the red agents is arbitrarily slow The 2N nonslow agents

Distributed Algorithms

Contents

Index

exchange messages among each other and each of these 2N agents
gets N votes for red and N votes for blue Agents decide to take a



majority vote and in the event of a tie pick blue

Fig1 Problem with a slow agent
How long should they wait for the slow agent
Consider an algorithm in which agent waits until its local clock shows
an elapsed time of T and then makes a decision based on the votes
that it has An agent Y gets N red and N blue votes when its clock
shows an elapsed time of T and agent Y decides that the consensus
is blue Another agent Z has a slower clock and gets a red vote from
the slow agent for a total of N1 red votes before Zs clock shows an
elapsed time of T So Z determines that the consensus is red The
algorithm fails because Y and Z have not come to a consensus
No algorithm is guaranteed to come to a consensus in finite time if
messages can be arbitrarily slow or if agents can be arbitrarily slow
Systems with synchronized clocks dont have this particular problem
Well look at consensus in such systems later

Best Effort Consensus
The theorem says that there is no algorithm that guarentees that
consensus can be reached in all scenarios however consensus can
be reached in most practical situations An idea to overcome the
counterexample given above is Agents keep trying repeatedly until
they reach consensus The theorem tells us that the agents may have
to keep trying for ever We expect however that in most practical
situations their attempts will succeed at some point

httpskmchandygithubioPaxosConsensusImpossiblehtml

23

71124 338 PM

PaxosConsensusImpossiblehtml

What does keep trying mean When does one trial end and the next

Distributed Algorithms

Contents

Index

one begin If agents use timeouts to end a trial then  because
clocks arent synchronized  the timeouts may complete at different



times Well see that we can use the idea of time even though clocks
arent synchronized Weve done that before with logical clocks The
Paxos algorithm shows how the idea of increasing values of
timestamps or ids are used for besteffort consensus

Central Ideas Review
Many applications of distributed systems require agents to come to a
consensus Agents cannot come to a consensus if an agent is faulty

Concepts Consensus  impossibility with faulty agents

Next
Next look at Paxos an important consensus algorithm that may not
terminate Later look at Byzantine consensus and consensus using
block chain

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioPaxosConsensusImpossiblehtml

33

71124 343 PM

Distributed Algorithms

SelfStabilizationSelfStabilizationhtml

Contents

Index



Self Stabilization
This module describes one example of a selfstabilization system  a system that recovers
automatically from transient errors
A self stabilizing system recovers automatically from transient errors
If a selfstabilizing system enters an unsafe state then the system will
correct itself and eventually enter a safe state
The literature on self stabilization is extensive Lets look at one
example of a selfstabilizing system to get an idea of its design

Self Stabilizing Token Passing
A ring of agents passes a single token around the ring An agent that
holds the token knows that no other agent has the token at that point
So the system can be used to implement mutual exclusion
Examples of errors are the disappearance of the single token and the
creation of additional tokens A self stabilizing algorithm ensures that
eventually the system gets back to a safe state ie one in which it
has exactly one token
Lets begin with a model in which each agent in the ring can read the
state of its predecessor in the ring Later we will modify the algorithm
to work with messagepassing

N agents indexed j are organized in a ring where agent
j  1 mod N can read the state of agent j Hereafter we will not
write mod N  it is to be understood
An agent is either idle or active The system is required to have
exactly one active process The active process can be thought of as
having the single token in the system The token is passed from
agent j to agent j  1 when agent j becomes idle and agent j  1
becomes active
For convenience in visualizing diagrams lets assume that the state
of an agent is a color Next we describe the basic algorithm that

httpskmchandygithubioSelfStabilizationSelfStabilizationhtml

16

71124 343 PM

SelfStabilizationSelfStabilizationhtml

assumes that errors do not occur later we will modify the algorithm

Distributed Algorithms

Contents

Index

to obtain a selfstabilizing algorithm that recover from errors



The Algorithm
The algorithm for agent 0 is different from that of the other agents
Agent 0 has the token exactly when its color is the same as that of its
predecessor Any other agent holds the token exactly when its color
is different from that of its predecessor
An agent j passes the token to agent j  1 when agent j changes its
color Agent 0 has the token when all the agents in the ring have the
same color
The diagram below illustrates an example with 4 agents where an
agents color is either red or blue The diagram shows how the token
is passed from each agent to its sucessor
In the figure on the top left all the agents are red so agent 0 has the
token When agent 0 changes its color we get the diagram at the top
center In this diagram agent 0 is blue and all the other agents are
red Agent 0 no longer has the token because its color is different
from that of its predecessor however agent 1 does have the token
because its color is different from that of its predecessor The
sequence of diagrams shows what happens when the agent holding
the token  which is the only active agent  changes its color

Fig1 The token is passed by an agent changing color

Faults
Lets look at the state of a system after a fault occurs The next set of
diagrams shows how errors  once they occur  can propagate for
httpskmchandygithubioSelfStabilizationSelfStabilizationhtml

26

71124 343 PM

SelfStabilizationSelfStabilizationhtml

ever These diagrams show a system with three tokens whereas an

Distributed Algorithms

Contents

Index

errorfree system should have exactly one The three agents holding
tokens are shown with large yellow numbers and the agent that does



not hold a token is shown with a smaller black number

Fig2 Errors can propagate forever
The figure on the top left of the above diagram shows agents 1 2 and
3 with tokens because their colors are different from those of their
predecessors The next diagram top right shows agents 1 and 3 with
tokens because their colors are different from those of their
predecessors and agent 0 with a token because its color is the same
as that of its predecessor The transition to the diagram on the top
right from the one on the top left occurs when agent 3 changes its
color
The sequence of state transitions gets the system to the figure on the
bottom left which is the same as that on the top left with the colors
reversed This cycle of state transitions can repeat forever with the
same system always having three tokens So this system is not self
stabilizing

A SelfStabilizing Algorithm
The solution add more colors
We will modify the design to have as many colors as there are agents
In our example we will have 4 colors because it has 4 agents The
algorithms for all agents other than agent 0 remains unchanged As
before agent 0 has the token when its color is the same as that of its
predecessor and agent 0 sends the token by changing agent 0s color
httpskmchandygithubioSelfStabilizationSelfStabilizationhtml

36

71124 343 PM

SelfStabilizationSelfStabilizationhtml

The difference in the selfstabilizing algorithm is the color to which

Distributed Algorithms
agent 0 transits

Contents

Index



Assume that the 4 colors are numbered 0 1 2 3 If agent 0s color is

k it makes a transition by changing its color to k mod N 
The diagram below gives an example of how agent 0s color changes
Its sequence of colors 0 1 2 3 are red blue green yellow
respectively The diagram on the top left shows a configuration in
which agent 0 holds a token because its color green  number 2 is
the same as that of its predecessor Agent 0 passes the token by
changing its color to 3 yellow as show on the diagram on the top
right
The diagram in the middle left shows agent 0 with a token It passes
the token by changing its color from 1 blue to 2 green as shown in
the diagram in the middle right

Fig3 Changes in color of agent 0

Proof
The proof has the following three ideas that we first describe
informally
1 In all states at least one agent holds a token
2 All trajectories from all states lead to a state in which agent 0
holds a token
3 A trajectory from a system state in which agent 0s color is
different from that of the other agents leads to a state in which
all agents have the same color in which case the system is in a
safe state
httpskmchandygithubioSelfStabilizationSelfStabilizationhtml

46

71124 343 PM

Part 1

Distributed Algorithms

SelfStabilizationSelfStabilizationhtml

Contents

Index



If all agents have the same color then agent 0 holds a token If there
is more than one color in the ring then there is at least one agent
other than agent 0 whose color is different from that of its
predecessors so that agent holds a token
Part 2
Agent 0 and agent n  1 will get the same color at some point
because agent 0s color will propagate all the way around the ring
unless it gets to agent n  1 sooner
Part 3
If agent 0s color is different from the colors of agents 1   n  1
then the only trajectory that leads to agents 0 and agent n  1
having the same color is for agent 0s color to propagate all the way
around the ring
The system always reaches a safe state
Let S be any state Let the C be the set of agent colors in state S  If
C has all N colors then the color of agent 0 is different from the
colors of the other agents and so the result follows from part 3
If C has fewer than N colors then the color of each agent remains a
color in C until agent 0 gets a color that is not in C  At this point
agent 0s color is different from that of the other agents and the result
follows

Review
1 In this algorithm does any agent detect that the system is in an
unsafe state Can we determine that the system is in an unsafe
state based solely on the state of any one agent and the state
of its predecessor Why
2 Will this algorithm work if the number of colors is arbitrarily
large and more than the number of agents Why
3 Will this algorithm work if the number of colors is less than the
number of agents Why

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioSelfStabilizationSelfStabilizationhtml

56

71124 343 PM

Distributed Algorithms

SelfStabilizationSelfStabilizationhtml

Contents

httpskmchandygithubioSelfStabilizationSelfStabilizationhtml

Index



66

71124 346 PM

Distributed Algorithms

ByzantineByzantineWrittenhtml

Contents

Index



Byzantine Consensus
Written Messages
This module introduces Byzantine consensus
algorithms in which agents reach consensus in a
sequence of synchronized rounds even though
some agents dont follow the protocol
In this module we study algorithms by which a collection of agents
reach a consensus among alternative values The Paxos algorithm is
an example of how agents reach consensus Agents cannot reach
consensus if message delays or agent operations are arbitrarily slow
Next we study a consensus algorithm in which message delays are
bounded and in which agents are guaranteed to come to a consensus
even though some agents do not follow the protocol
The algorithm operates in a sequence of steps called rounds All
messages sent in a round are delivered in the next round Agents
execute actions in each round after receiving messages sent in the
previous round these actions may include sending messages So the
Byzantine algorithm is synchronous

Byzantine Generals Problem Overview
A general has N army units each of which is led by a lieutenant
general herafter referred to merely as lieutenant We refer to the
general and the lieutenants collectively as agents An agent may be
either loyal or disloyal A loyal general gives the same command to all
lieutenants A loyal generals command is either attack or retreat A
disloyal general may give different commands to different lieutenants
and may give no commands to some The lieutenants receive
commands from the general and then communicate among
themselves to reach a consensus Loyal lieutenants follow an
algorithm while disloyal lieutenants may or may not
The figure below illustrates the difference between loyal and disloyal
generals
httpskmchandygithubioByzantineByzantineWrittenhtml

17

71124 346 PM

Distributed Algorithms

ByzantineByzantineWrittenhtml

Contents

Index



Fig1 Loyal and disloyal general behavior

Byzantine Generals Problem Specification
A loyal general sends attack messages to all lieutenants or sends
retreat messages to all lieutenants A disloyal general sends arbitrary
messages to lieutenants
1 Validity Loyal lieutenants must obey a loyal general If a loyal
general gives the command to attack then all loyal lieutenants
must attack Likewise if a loyal general gives the command to
retreat then all loyal lieutenants must retreat
2 Consensus Loyal lieutenants come to a consensus either all of
them attack or all of them retreat
The specification does not require that traitors be discovered For
example the algorithm doesnt have to determine whether the general
or a lieutenant is loyal or disloyal
If the only requirement is validity and consensus isnt required then
the solution is trivial all loyal lieutenants obey the general whether
the general is loyal or disloyal If the only requirement is consensus
then the solution is trivial all loyal lieutenants agree on a predefined
value say retreat regardless of the command issued by the general
The conjunction of both requirements makes the problem difficult

Oral and Written Messages
There are two versions of the problem
1 Written Messages In this version an agent may send copies of
messages that it receives to other agents but cannot modify
the messages Also an agent cannot forge signatures So an
httpskmchandygithubioByzantineByzantineWrittenhtml

27

71124 346 PM

ByzantineByzantineWrittenhtml

agent can receive a message M signed by lieutenant A only if

Distributed Algorithms
Contents
A sent M to some agent

Index



2 Oral Messages In this version an agent can modify messages
and forge signaturesSo an agent can receive a message M
signed by agent A even if A never sent M to any agent
The algorithm for written messages is simpler and requires fewer
messages

Algorithm with Written Messages
A reliable lieutenant who does not get a message from in round 0
treats the absence of the message as the same as receiving a retreat
message Likewise if a loyal lieutenant gets a message that is not an
attack or a retreat message then the lieutenant treats the message as
a retreat message We use retreat as a default We could just as well
have used attack as the default
Next we give an overview of the algorithm

Commit to Attack
At each round in the algorithm a loyal lieutenant has either
committed to attack or not A lieutenant that has not committed to
attack on a round may commit to attack on a later round If any loyal
lieutenant commits to attack in any round then it remains committed
to attack thereafter A loyal lieutenant retreats if it has not committed
to attack at the end of the last round

Messages
A message is an attack message from the general or a commitment
to attack by a lieutenant We call commitment messages attack
messages An attack message is identified by the agent general or
lieutenant that created the message

Evidence for Attack
A loyal lieutenant commits to attack on round r  1 for the first
time if the lieutenant has received an attack message from the
general and at least r  1 lieutenants When the lieutenant commits
to attack it sends copies of these messages and its own attack
message to all other lieutenants So in round r  1 each lieutenant
receives an attack messages from the general and at least r
lieutenants And so all loyal lieutenants commit to attack in this
round
httpskmchandygithubioByzantineByzantineWrittenhtml

37

71124 346 PM

The
Algorithm
Distributed
Algorithms

ByzantineByzantineWrittenhtml

Contents

Index



We will use the tactic that is helpful in analyzing distributed
algorithms that operate in rounds We will prove properties of a
sequential algorithm and then show the equivalence of the sequential
and distributed algorithms The sequential algorithm is given next
Local Variables
Associated with each lieutenant C are local variables Creceived
and Csent which are sets of agents general or lieutenants
Creceived is the set of agents from which C has received attack
messages or their copies C sends attack messages or copies
from agents in Csent The symbol g represents the general

Initialization Round 0
Asent   for all lieutenants A
1 If the general is loyal and sends attack messages then the set
of agents from which a lieutenant has received attack
messages is the singleton set consisting of the general So for
all lieutenants A
Areceived  g
2 If the general is loyal and sends retreat messages then for all
lieutenants A
Areceived  
3 If the general is disloyal then Areceived  g for some
lieutenants A and Areceived   for the others
The algorithm operates in a sequence of rounds with roundnumber r
stepping from 1 to t1 The rth iteration for loyal agent c consists
of the following two steps

Round r  0
Step 1
if Creceived  r AND
Ccommit  True

g in Creceived

Csent  Creceived UNION C
If Creceived has messages that show that 1 the number of
agents that have committed to attack on round r is at least r and 2
the general has sent an attack message then C commits to attack
and sends these messages as well as an additional message that C
has committed to attack
httpskmchandygithubioByzantineByzantineWrittenhtml

47

71124 346 PM

Step 2

Distributed Algorithms

ByzantineByzantineWrittenhtml

Contents

Index



Creceived  
UNION over all loyal agents B of Bsent
UNION
an arbitrary subset of disloyal agents
C receives the messages sent by loyal lieutenants and messages
sent by disloyal lieutenants A disloyal lieutenant A can send
messages to some lieutenants that A is committed to attack and not
send these messages to other lieutenants Lieutenant C receives
attack messages from an arbitrary subset of disloyal lieutenants
Lieutenant C does not know which agents are loyal and which are
disloyal Creceived is the set of all messages sent to C regardless
of whether the senders are loyal or disloyal

Proof of Correctness
Case 1 General is loyal and sends attack messages
In this case at the start round 1 Creceived  g So the ifclause in step 1 of round 1 is True and therefore all loyal lieutenants
commit to attack at the end of round 1

Case 2 General is loyal and sends retreat messages
A disloyal lieutenant cannot forge the generals signature and so it is
impossible for any lieutenant to have a copy of an attack message
from the general Therefore the ifclause of step 1 is never satisfied
and so no loyal lieutenant commits to attack in any step

Case 3 General is disloyal
Part 1
We first show that if any loyal lieutenant commits on round r then all
loyal lieutenants commit by the end of round r1
A loyal lieutenant C commits on round r exactly when the set
Creceived has at least r attack messages including one from the
general So in round r Csent has at least r1 attack messages
including one from the general Therefore the ifclause of step 1
evaluates to True in round r1 and so all loyal lieutenants commit by
the end of round r1

httpskmchandygithubioByzantineByzantineWrittenhtml

57

71124 346 PM

ByzantineByzantineWrittenhtml

Therefore if any loyal lieutenant commits by the end of round t1

Distributed Algorithms

Contents

Index

then all loyal lieutenants commit by the end of round t



Part 2
We next show that if no loyal lieutenant has committed by the end of
round t1 then no loyal lieutenant commits in round t
Csent   at the end of round t1 if no loyal lieutenant has
committed to attack Therefore in round t Creceived is an
arbitrary subset of disloyal lieutenants There are at most t1
disloyal lieutenants because there are at most t disloyal agents and
the general is disloyal So on round t the ifclause of step 1
evaluates to False
Part 3
From parts 1 and 2 by the end of round t either all loyal lieutenants
commit or no loyal lieutenant commits

Example
The figure below illustrates a situation in which a loyal lieutenant C
commits to attack on round 3 if it hasnt already committed to attack
on rounds 1 and 2 The figure shows C getting attack messages red
boxes signed by the general and lieutenants A and B on round 2 The
general and lieutenants A and B may be disloyal or loyal

Fig2 Example of a lieutenant committing to attack
Because C is loyal it follows the algorithm and C commits to attack
at the end of round 3 because C receives a signed attack message
from the general and signed attack messages from two different
httpskmchandygithubioByzantineByzantineWrittenhtml

67

71124 346 PM

ByzantineByzantineWrittenhtml

lieutenants So in round 3 C broadcasts copies of attack messages

Distributed Algorithms

Contents

Index

signed by the general and attack messages signed by A and B and
attack messages and also an attack message signed by C itself All



loyal lieutenants commit to attack in round 4 because they receive
attack messages signed by the general and 3 different lieutenants A
B C

Review
1 Assume that you are explaining the algorithm to someone who
hasnt taken a course on distributed computing How would you
explain to this person that even if the general and 999
lieutenants are disloyal and only 2 lieutenants are loyal the
loyal lieutenants reach a consensus after round 100
Remember the first round is round 0
2 Will the algorithm work if at most one lieutenant could modify
written messages and all the other lieutenants followed the
protocol ie these lieutenants could copy but not modify
messages

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioByzantineByzantineWrittenhtml

77

71124 349 PM

Distributed Algorithms

CryptoCryptoCurrencyIntroductionhtml

Contents

Index



Introduction to Cryptography
for Cryptocurrency
This module contains a review of elementary
cryptographic operations and introduces a simple
cryptocurrency managed by a trusted agent
The next module discusses the algorithm underlying Bitcoin the
Bitcoin algorithm doesnt require agents to be trusted This Princeton
University book is a superb description of Bitcoin

Review Cryptographic Hash
Function
A hash function H  maps input strings of arbitrary size to outputs of
fixed size

Collision Resistance
Input values x y of a hash function H are said to collide
when Hx  Hy A hash function H is said to be
collision resistant if the only known ways of finding
collisions using the hash are intractable

Lets look at the following problem Given H  find any colliding pair
x y
Consider a hash function H that outputs nbit numbers and whose
input is m bit strings As a specific example lets assume that m is a
large number and n  4 We can find a collision in the following way
Let D be an array of size 2n  16 Initially D contains null values
Repeat the following iteration until a collision is found Pick a random

httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

115

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

input x If DHx is null then set DHx  x else there is a

Distributed Algorithms
Contents
collision between Hx and x

Index



By the pigeonhole principle we will find a collision in at most

2n  1  17 iterations This bruteforce algorithm uses space 2n
and finds a collision in at most 2n  1 steps From the Birthday
Paradox a collision will be found with high probability in 2n2
iterations though the worsecase time is 2n  1 If n  256 then a
collision will be found with high probability in 2128 iterations however
executing 2128 steps is still intractable
For H to be collision resistant the output of H must be nbits for
large n For example n  256 in the SHA256 hash function

Commitment using Hashes
You bet that your soccer friend Megan cannot predict the winner of
the 2022 World Cup Megan puts the name of the predicted winner
W  in an envelope and gives it to a trusted third party After the World
Cup is over the third party reveals Megans prediction and at that
point you can find out whether Megans prediction was accurate
The trusted third party provides two services
1 Hiding You cant find out Megans prediction until the third party
reveals it
2 Binding Megan cant change her prediction after giving it to the
third party
Can we use a hash function instead of a trusted third party

Hiding
Lets try the following idea Megan commits to W in the following
way She announces a hash function H  and the hash y where

y  HW  You know H and y After the World Cup is over she
reveals her prediction W  At this point you can verify that
y  HW 
Does the hash function provide the services of the third party Can
you discover Megans prediction before she reveals it
Its easy There are only 32 teams playing Compute Hx where x
runs over each of the 32 teams One of those teams has to be W 
You can discover her prediction in at most 210 steps

httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

215

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

Lets try another algorithm Megan selects a secret value r which she

Distributed Algorithms

Contents

Index

keeps to herself Instead of giving you HW  she gives you y where
y  Hr  W  and where  indicates concatenation of strings



Can you discover W from H and y without knowing r
A bruteforce solution is to try every combination of r and W  If r is
obtained from a distribution that is spread out then finding W
without knowing r take so much time that it is practically impossible

Hiding Given H y where y  Hr  W  and r is a
secret discovering W is intractable

Binding
Does the hash function H and the secret r provide both services of
the trusted third party Is Megan bound to her prediction or can she
change her prediction after knowing the winner of the World Cup
Suppose Megan has values r and r such that Hr  Brazil  Hr 
Italy After the World Cup is over she can announce that her secret
is r if Brazil wins and announce that it is r if Italy wins

A hash function H is binding if finding pairs x y and

x y where y  y such that
Hx  y  Hx  y is intractable
Suppose you give Megan a hash function that is binding Then she
cannot find in reasonable time values rj to match country Cj such
that

Hr0  C0  Hr1  C1  Hr2  C2  
and so she cant wait for the winner Cj to be announced before
announcing her secret rj
In summary we can use a hash function that is hiding and binding to
play the role of a trusted third party in a commitment

Puzzle Friendly
httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

315

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

The concept of puzzle friendly is related to hiding Let r be a value

Distributed Algorithms

Contents

Index

picked from a spreadout distribution Let H map arbitrary length
strings to nbit strings Consider the following problem Given H  r



and an nbit value y compute any x such that Hr  x  y
In this problem as opposed to the hiding problem we are given r and
not x
The hash function H is said to be puzzle friendly exactly when any
algorithm to solve this problem is about as slow as a bruteforce
algorithm which checks Hr  x  y for random values of x The
number of steps taken by any algorithm that solves this problem is
not significantly lower than 2n
Now lets look at the following related problem Given H  r and a set
Y of nbit strings compute any x such that Hr  x  Y  If Y
consists of a single element y then this problem is the same as that
in the previous paragraph If Y is a set of all nbit strings then this
problem is trivial because any x solves the problem The probability
that a random value hashes to an element of Y is proportional to the
cardinality of Y  The cardinality of Y controls the expected time to
solve the puzzle

The hash function H is puzzle friendly when given H  r
and a set Y of nbit values the time required to compute
any x such that Hr  x  Y is not significantly lower
than 2nY  where Y  is the cardinality of Y 

A Cryptographic Hash Function
A cryptographic hash function is one that is collision
resistant hiding and puzzlefriendly

Hashing Inputs of Arbitrary Length
Let f be a function that operates on input strings of fixed length and
produces output strings of fixed length Let the input and output
strings of f have lengths M  N and M  respectively We look at
httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

415

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

functions where N  0 and since the output is smaller than the

Distributed Algorithms
Contents
input f is called a compression function

Index



We can use function f to define a function g whose inputs are strings
of arbitrary lengths and whose outputs are strings of length M 
Example code for g is given below where InitialValue is a given
constant string of length M 
def gy
output  InitialValue
 pad y so that its length is a multiple of N
if lenyN  0 y  y  0N  lenyN
 partition y into blocks of size N
blocks  yi iN for i in range0 leny N
 Apply function f to the concatenation of the
 previous output length M with each block
 length N to get the next output length M
for block in blocks output  foutputblock
return output

Hash Pointers
A hash pointer to an item D of data is a pair
ptr HD where ptr is a pointer that points to D and
H is a cryptographic hash function

Any data structure with pointers can be converted into a data
structure with hash pointers merely replace a pointer ptr to D by
ptr HD

TamperEvident Data
Structures
Single Block

httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

515

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

A simple example of a tamperevident structure is a single block of

Distributed Algorithms

Contents

Index

data D which is pointed to by a hash pointer consisting of a regular
pointer and a hash HD



Fig1 Hash Pointer points to a TamperEvident Block of
Data
Assume that a malicious agent cannot modify both the hash pointer
and the data that it points to If an agent changes D to D then the
tampering can be discovered because the hash pointer wont match
the data that it is pointing to HD  HD

TamperEvident Linked List
Lets look at linear linked list to which elements can be appended but
not deleted The ith element appended to the list points to the
i  1th element Lets replace the pointers in the list by hashed
pointers

httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

615

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

Fig2 Hash Pointer points to a TamperEvident List of

Distributed Algorithms
Data

Contents

Index



The jth element of the list j  0 consists of data Dj and a hash
pointer that points to the j  1th element of the list The hash
pointer in the jth element consists of a regular pointer ptrj which
points to the j  1th element of the list and a hashed value HAj
which is a cryptographic hash of the entire j  1th element
consisting of Dj1 ptrj1 and HAj1 The 0th element is called
the genesis element and has default values The list is accessed by a
hash pointer that points to the last element of the list let this pointer
be ptrn HAn
Assume that agents cannot modify ptrn HAn Then can any agent
determine whether the list has been tampered with
Suppose the agent modifies Dj ptrj or HAj for any j  n Any
agent can detect this tampering because the hash value HAj1 will
no longer match the jth element of the list If the malicious agent
also modifies HAj1 then hash value HAj2 will no longer match
the j  1th element
By induction on j any agent can detect tampering with the list
provided malicious agents do not also modify the hash pointer to the
last element of the last

TamperEvident Acyclic Graphs and Merkle Trees
The idea described in the previous paragraph to convert linear linked
lists can be used to convert directed acyclic graphs in which nodes
are connected by pointers into tamperevident graphs A specific
case of a directed acyclic graph is a rooted tree
A Merkle tree is a special case of a binary balanced tree in which data
items are stored only in the leaves Nodes that are not leaves contain
only hash pointers to nodes in the next level down To prove that an
element at the leaf is a member of the tree we need only the log2n
hash pointers on the path from the root to that leaf By contrast to
prove that an element is a member of a linear list we need to inspect

On elements on average

Keys and Signed Messages
You can create a random publickey privatekey pair by calling a
function on your computer With high probability nobody else has this
httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

715

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

specific pair of keys Each individuals private key is a secret held by

Distributed Algorithms

Contents

Index

that individual Public keys are accessible by everybody



Sending messages securely
Keys are used to send messages securely Kamala sends a secure
message to Joe by encrypting the message with Joes public key Joe
decrypts the message using Joes private key An agent cannot
decrypt the encrypted message without Joes private key
Signing messages
Suppose Kamala needs to send a signed message to Joe while
ensuring that nobody can forge her signature She encrypts the
message M with her private key to get an encrypted message M and
sends the pair M M securely to Joe ie she encrypts M M with
Joes public key and sends the resulting encrypted message to Joe
When Joe receives the message Joe decrypts it using his private key
to get M M Then Joe decrypts M using Kamalas public key to get
the decrypted message M If M  M then Joe knows that Kamala
sent M because only an agent with Kamalas private signature could
have sent that message

Cryptocurrency Managed by a
Trusted Agent
Lets start with a digital currency managed by a trusted agent that we
will call a bank Later we will look at a consensus algorithm  very
different from Paxos and Byzantine Generals  which will allow
cryptocurrencies without trusted agent

The bank maintains a tamperevident linear list L of
transactions that we call a tamperevident ledger Any
agent can get a copy of the ledger This tamperevident
ledger is the foundation of the currency

A transaction is one of two types create or pay In a pay transaction

payers give coins that they possess to payees An agent can be both
a payer and payee of the same transaction In a create transaction
the bank creates coins that it gives to agents  the payees of the
transaction the bank acts as the payer
httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

815

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

For this system to be trusted the bank must follow some protocol

Distributed Algorithms

Contents

Index

that determines how and when the bank creates coins We wont
discuss these protocols



A pay transaction is signed by all payers of the transaction A create
transaction is signed by the bank We discussed digital signatures
and keys earlier
Each element of the tamperevident ledger has
1 a unique id
2 the type of the transaction either create or pay
3 list of payers only for pay transactions  a list indicating the
agents who pay coins into the transaction and the amounts
that they put in
4 array of valuepayee pairs for both create and pay transactions
 an array of pairs value payee public key where
each pair in the array indicates that coins of the specified value
are given to the payee with the specified public key

Example of a create transaction
An example of a create transaction is
3146 create

21 7xxxx 32 8xxxx

The id of this transaction is 3146 the type of the transaction is
create and the array of valuepayee pairs is
21 7xxxx 32 8xxx
In this transaction the bank creates a coin of value 21 and gives it to
the agent with public key 7xxxx and the bank also creates a coin of
value 32 and gives it to the agent with public key 8xxxx
The pair
transaction id index into array of valuepayee pairs
uniquely identifies a value payee tuple
For example 3146 0  transaction id 3146 and array index 0 identifies valuepayee0 of transaction 3146 which is specified by the
2tuple 21 7xxxx So the transaction id and index 3146 0 tells
everybody that the agent with public key 7xxxx received 21 units of
coin in transaction 3146

httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

915

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

When this transaction is in a tamperevident ledger every agent from

Distributed Algorithms

Contents

Index

that point onwards knows that agent 7xxxx received 21 coins Any
modifications of this record can be detected



Likewise 3146 1  transaction id 3146 and array index 1 identifies valuepayee1 which is the 2tuple 32 8xxxx

Pay transaction
Coins are transferred from payers to payees in a pay transaction

Coins flowing into a pay transaction from
payers
The payers are identified by a list of 2tuples where each 2tuple is
transaction id index into array of valuepayee pairs
where transaction id is the id of the transaction in the tamperevident ledger As we said earlier this pair uniquely identifies an agent
and a value that this agent acquired in this transaction For example
the pair  transaction id index  such as 3146 0 identifies the 2tuple 21 7xxxx this 2tuple asserts that the agent with public key
7xxxx received 21 units of coin in transaction 3146 The entire
amount specified in the 2tuple 21 in our example is value that
flows into this pay transaction from the agent with public key 7xxxx
Suppose the payers in a pay transaction are identified by the list
3146 0 7359 3
and suppose pair 3 in transaction 7359 is 32 8xxxx Then the total
amount of coins flowing into this pay transaction is 21  32 and this
amount is disbursed to payees

httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

1015

71124 349 PM

Distributed Algorithms

CryptoCryptoCurrencyIntroductionhtml

Contents

Index



Fig3 Coins flowing into and out of a pay transaction

Coins flowing out of a pay transaction to
payees
The outflow of coins is specified by an array of valuepayee pairs
exactly as in a create transaction The transaction clears all coins the
total inflow from payers is equal to the total outflow to payees in a
transaction
The system may provide incentives such as payment of coins to
managers eg banks of cryptocurrencies In this case one of the
payees is the bank itself

Managing amounts spent in a transaction
A transactionid index pair  such as 3146 0 identifies a 2tuple
such as 21 7xxxx this 2tuple asserts that the agent with public
key 7xxxx received 21 units of coin in transaction 3146 The entire
amount specified in the 2tuple 21 in our example is value that
flows into the transaction What should this agent do if it wants to put
in more than 21 coins into the transaction Or less than 21 coins
To put in more value the bank identifies other transactionid index
pairs in which this agent received coins For example say that 4539
2 identifies a 2tuple 32 7xxxx and assume that the payers in this
transaction are specified by the pairs 3146 0 and 4539 2 The pair
3146 0 asserts that agent 7xxxx received 21 coins and the pair
4539 2 asserts that the same agent received 32 coins So the total
amount of coins flowing into this transaction from this agent 7xxxx
includes 21  32
httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

1115

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

To put in less value the agent acts as both payer and payee the net

Distributed Algorithms

Contents

Index

value that this agent pays out to other agents is the difference
between the amount that this agent puts in and takes out For



example if agent with public key 7xxxx wants to put in 19 coins into
this transaction its payer information can be given by the transactionid index pair 3146 0 which asserts that the agent received 21
coins and the same agent is a payee that withdraws 02 coins

Preventing Double Spending
How does the system prevent an agent from using the same coin
twice
For example the transaction id index pair 3146 0 identifies the 2tuple 21 7xxxx this tuple asserts that the agent with public key
7xxxx received 21 units of coin in transaction 3146 Why cant the
agent with public key 7xxxx use the 21 coins that it received to buy
items from Amazon and later use the same 21 coins to buy more
items from Walmart
The bank checks that the agent hasnt already spent the coin that it is
putting into a transaction
Before permitting the transaction that doublespends the 21 coins
with Walmart the bank inspects the tamperevident ledger for all
transactions after transaction 3146 and before the Walmart
transaction to ensure that the agent 7xxxx hasnt already spent the
21 coins that it got in transaction 3146 The transaction that spends
the coins at Amazon will show up in the ledger and so the transaction
with Walmart will not be allowed
Every agent that has the banks hash pointer to the end of the tamperevident ledger can inspect the ledger to check that doublespending
hasnt occurred
The bank signs a valid transaction and appends it to the tamperevident ledger All agents can see the banks signature and verify that
nobody not even the bank has tampered with the tamperevident
ledger

Example of a pay transaction
An example of the specification of a pay transaction is
9431 pay
3146 0 4731 2
httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

1215

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

07 7xxxx 46 9xxxx

Distributed Algorithms


Contents

Index



The id of this transaction is 9431 the type of the transaction is pay
the payers into the transaction are identified by the pairs of
transactionid index 3146 0 and 4731 2 and the payee array is
07 7xxxx 46 9xxxx

Transaction validity
The bank appends a transaction to L if and only if the transaction is
valid The bank checks for validity by carrying out the following steps
1 The bank verifies that the payers into the transaction signed the
transaction
2 The bank checks that the total value of coins paid out from the
transaction does not exceed the total value paid in to the
transaction If the value paid in exceeds the value paid out then
the bank takes the difference as a transaction fee More about
fees later
3 The bank verifies that the payers claims to have received coins
in previous transactions is genuine For example if the agent
with public key 7xxxx claims to have received coins worth 21
in the transaction with id 10 and payee array index 0 then the
bank verifies this claim by that transaction
4 The bank ensures that coins paid into the transaction havent
already been spent

Optimizations Blocks and Block Chain
Verifying large numbers of small transactions requires more
computation than verifying small numbers of blocks of many
transactions A block chain is a tamperevident ledger in which each
element of the ledger is a block consisting of many transactions A
block of transactions can be aggregated into a single large
transaction by aggregating all the payers and payees of the smaller
transactions
The amount of computation decreases as the number of transactions
in a block increases The time required to fill a block with transactions
is larger when the number of transactions to fill the block increases

Checking the Trusted Agent
httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

1315

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

Consider a system in which the trusted agent broadcasts its current

Distributed Algorithms

Contents

Index

copy of the tamperevident ledger to all agents Every agent can
inspect its copy of the tamperevident ledger to determine whether



the ledger has been tampered with So every agent can validate its
trust in the trusted agent however this validation suffers from a
crucial problem Agents may only have copies of old stale versions of
the ledger By the time that an agent receives a copy of the ledger the
trusted agent may have added more transactions to the ledger

Fig4 Old Copy is a Prefix of the Block Chain
An old copy of the ledger can differ from the current copy in only one
way the current copy may have transactions appended to the end of
the old copy So all agents can validate past behavior of the trusted
agent An agent cannot however treat its copy of the ledger as the
master copy because the agent may not have the transactions added
most recently to the ledger
In the next module we will see how the Bitcoin algorithm addresses
this problem

Advantages of this cryptocurrency
Any agent can get a copy of the tamperevident ledger and verify that
all transactions in the ledger are valid Any agent can verify that the
only way in which the ledger is modified is that elements are append
to its tail all that the agent needs to do is to check that the pointer to
the tail is modified only by appending elements Because the ledger is
tamperevident an agent can check that the ledger doesnt change
while the hash pointer to the end of the ledger doesnt change

httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

1415

71124 349 PM

CryptoCryptoCurrencyIntroductionhtml

The bank cant forge a transaction because all payers sign the

Distributed Algorithms

Contents

Index

transaction Agents can remain anonymous because an agents only
public information is the agents public key and an agent can create



multiple public keys Every agent can verify the correctness of every
transaction

Disadvantages of this cryptocurrency
Users may not trust the bank Transactions are not private because
the bank has a record of all transactions And the bank is a single
point of failure
Next well look at Bitcoins algorithms for implementing a
cryptocurrency without trusted agents

Review
1 What is collision resistance Why is it relevant to
cryptocurrencies
2 Consider the example of hiding in which Megan hides her
predictions for the winner of the World Cup Suppose you could
choose two different random number generators for creating
the secret r in one case the bits of r are uncorrelated and in
the other they are highly correlated Which generator would you
use and why
3 What is binding Why is it relevant to hiding information
4 What is puzzle friendly
5 What is a tamperevident data structure How would you
implement a tamperevident linear list A tamperevident tree
6 Describe the algorithm for cryptocurrency with a trusted agent
to someone who knows absolutely nothing about
cryptocurrency
7 How could the algorithm for cryptocurrency be used for a
collection of distributed agents to keep track of a sequence of
events other than buyingselling currency

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioCryptoCryptoCurrencyIntroductionhtml

1515

71124 542 PM

Distributed Algorithms

KnowledgeKnowledgehtml

Contents

Index



What Agents Know
This module gives a formal definition for the
frequently used informal phrase An agent knows
something about other agents and and channels

Key Ideas
We sometimes use anthropmorphic arguments in reasoning about
systems  we invest digital agents with human characteristics For
example a programmer may say an agent knows that another agent
is idle Endowing software with human capabilities can be dangerous
when terms are ambiguous
In this module we define a predicate agent x knows P  where P is a
predicate on states of a system In later modules we will use this
definition to discuss algorithms
This module presents theorems about what agents know The proofs
of these theorems follow from the definition of consistent cuts 

What an Agent Knows
Let x be an agent P a predicate on system states and Q a predicate
on states of x

P can be a global predicate ie a predicate on states of all agents
and channels Q is a local predicate of x because it is a predicate
only on the states of agent x and is independent of other agents and
only channels
Let init be the predicate that defines the initial condition of the
system
We define the predicate x knows P  as follows

x knows P is the weakest local predicate Q of x such
that
httpskmchandygithubioKnowledgeKnowledgehtml

19

71124 542 PM

Distributed Algorithms

KnowledgeKnowledgehtml

Contents

init  alwaysQ  P 

Index



x knows P holds in a local state sx of agent x exactly when P holds
in all states of all trajectories that start from an initial state when
the local state of agent x is sx

Explanation
For any predicate R

init  alwaysR
means that R holds in every state of every trajectory that starts in an
initial state So

init  alwaysQ  P 
means that in Q  P  holds in every state of every trajectory that
starts in an initial state So if local predicate Q of agent x holds in
any state of any trajectory that starts from an initial state then global
predicate P also holds in that state

Example
A system consisting of agents 0   N has two indivisible tokens
which are not created or destroyed
Agent 0 knows no other agent holds a token is a predicate on the
states of agent 0 this predicate holds for a local state s0 of agent 0 if
and only if no other agent holds a token when agent 0 is in state s0
So agent 0 knows P holds exactly when agent 0 holds both tokens
Example
This example deals with a system consisting of two agents x and y
and channels in both directions between the agents The system has
a single indivisible token that is not created or destroyed Let P be
the predicate y does not hold the token Agent x knows P when x
holds the token

 x knows P  is a predicate too and sometimes programmers refer
to this predicate as x does not know P 
Example

httpskmchandygithubioKnowledgeKnowledgehtml

29

71124 542 PM

KnowledgeKnowledgehtml

In the previous example let Q be the predicate y holds the token In

Distributed Algorithms
Contents
Index
what local states of agent x does x know that y holds the token



There are no local states of agent x in which x knows that y holds
the token Even when x does not hold the token x does not know
that y holds the token because the token could be in a channel
When x does not hold the token x does not know that y holds the
token and x does not know that y does not hold the token
NOTx knows Q AND NOTx knows NOT Q
is a predicate which holds in the state which x does not hold the
token

Notation
x knows P at a point T  in a timeline means that at point T agent x
is in a state where the predicate x knows P  holds

Theorem Knowledge and Consistent Cuts
Let P be a predicate on the states of a system

If x knows P at a point T in xs timeline then P holds in every
consistent cut through that point
Proof
The states corresponding to all consistent cuts that pass through the
same point on xs timeline have the same common value for xs local
state

Example



Fig 2 Agent A knows P in all consistent cuts that cross
point T
The top figure in both diagrams above show a time T at which agent
A knows that P holds This implies that P holds in all consistent cuts
httpskmchandygithubioKnowledgeKnowledgehtml

39

71124 542 PM

KnowledgeKnowledgehtml

through point T The lower figures in the diagrams show consistent

Distributed Algorithms

Contents

Index

cuts which passes point T on As timeline the theorem says that P
holds for the state at these cuts too



Theorem A Silent Agent retains Knowledge
An agent that sends no information between a point T
and a later point T  retains all the knowledge it has at T
at T 

Let x be an agent in a system and let P be a predicate on a
subsystem that does not include x Let T and T  be points on xs
timeline with T  T  If x knows P at point T and x sends no
messages in the interval T  T  then x knows P at T 
Proof
Let c be any consistent cut through point T  on xs timeline We will
prove that P holds for the state at cut c
Let c be the cut that is identical to c except that it passes through
point T on xs timeline c is consistent because there are no outgoing
edges from xs timeline between cuts c and c
Because x knows P at T  P holds at c Since c and c are identical
except for the intersection with xs timeline it follows that P holds c

Example



Fig 3 Illustration of Proof of Silent Agents

Consequence of the Theorem
An agent doesnt lose knowledge by getting information from other
agents
httpskmchandygithubioKnowledgeKnowledgehtml

49

71124 542 PM

KnowledgeKnowledgehtml

An agent can only lose knowledge by sending information to other

Distributed Algorithms

Contents

Index

agents This seems counterintuitive well look at the reasoning
underlying this in a later theorem



Theorem Agents who dont listen remain
Ignorant
An agent that receives no information between a point T
and a later point T  learns no new knowledge between T
and T 

Let x be an agent in a system and let P be a predicate on a
subsystem that does not include x Let T and T  be points on xs
timeline with T  T  If x knows P at point T  and x received no
messages in the interval T  T  then x knows P at T 
The proof has exactly the same structure as the proof of the previous
theorem

Consequence of the Theorem
x didnt learn anything in the interval T  T  everything x knows at
the later point T  is knowledge it already had at the earlier point T 
The only way for an agent to gain knowledge is to receive messages
An agent cannot learn about other agents by only sending messages
or making internal state transitions

Theorem Knowledge implies Control
Let x and y be agents in a system and let P be a predicate on the
states of y Let T and T  be instants in a trajectory with T  T  If x
knows P at T  and P holds at T  then there is a path in the
timeline diagram from point T on xs timeline to point T  on ys
timeline
Proof If there is no path from point T on xs timeline to point T  on y
s timeline then there exists a consistent cut which crosses xs
timeline at T and crosses ys timeline at T 

Example
httpskmchandygithubioKnowledgeKnowledgehtml

59

71124 542 PM

KnowledgeKnowledgehtml

In the figure below agent A at point T knows that agent C holds no

Distributed Algorithms
Contents
Index
tokens At a later point T  agent C holds a token What must happen
between points T and T 





Fig 4 What must happen between T and T
There must be a path in the timeline diagram from point T on agent

As timeline to point T  on agent C s timeline This path is
represented by edges that show time elapsing on a timeline and
message edges between timelines



Fig 5 There must be a path from A at T to C at T

Consequence of the Theorem
Suppose you and your friend communicate only by means of
messages that are delayed by arbitrary finite amounts Consider a
situation where your friend knows that you are in the library at 9 pm
Then from our definition of knowledge because agents only know
truth you must be in the library at 9 pm Moreover you cant leave the
library until you receive a message from your friend this message
may go through intermediate agents
In one of the exercises well look at knowledge when agents have
clocks that may drift from each other but are not more than a some
constant M units apart If your friend knows that you will be in the
library till her watch reads 900 pm and your watches may drift apart
by a minute then you can leave the library at 901 pm Clocks are
useful even if they arent perfect More about clocks later

httpskmchandygithubioKnowledgeKnowledgehtml

69

71124 542 PM

KnowledgeKnowledgehtml

Theorem
Communication
Distributed Algorithms
Contentsto learn
Index about
Change



This theorem is similar to the knowledge is control theorem
Let x and y be agents in a system and let P be a predicate on the
states of y Let T and T  be instants in a trajectory with T  T  If

P holds at T and x knows P at T  then there is a path in the
timeline diagram from point T on ys timeline to point T  on xs
timeline

Example
In the figure below agent C holds a token at point T  At a later point

T  agent A knows that agent C holds no tokens What must happen
between points T and T 



Fig 6 What must happen between T and T
There must be a path in the timeline diagram from point T on agent

C s timeline to point T  on agent As timeline This path is
represented by edges that show time elapsing on a timeline and
message edges between timelines



Fig 7 There must be a path from C at T to A at T

What Agents Know about Channel States
Next lets look at systems in which messages are acknowledged For
a pair of agents x y let ms and mr be the number of messages that
httpskmchandygithubioKnowledgeKnowledgehtml

79

71124 542 PM

KnowledgeKnowledgehtml

x has sent to y and the number of messages that y has received
Distributed Algorithms
Contents
Index
from x respectively Let as and ar be the number of
acknowledgements that y has sent to x and the number of
acknowledgements that x has received from y respectively The



following is an invariant

ms  mr  as  ar
The number of messages in the channel from x to y is ms  mr
Because ms and ar are variables of agent x agent x knows an
upper bound ms  ar on the number of messages in channel

x y So x knows that the channel is empty when ms  ar

What an agent cannot know
An agent cannot know that there are exactly n messages in a
channel for n  0 You can prove this result using the concept of
consistent cuts Intuitively the agent cannot know whether a
message is in the channel or has been received

Chains of Knowledge
Let x y z be agents of a system and P be a predicate on states of
the system Then the following are all predicates

z knows P
y knows that z knows P
x knows that y knows that z knows P
The theorems given earlier apply to any predicate For example if x
knows that y knows that z knows P at a point t in a trajectory and

P holds at a later point t then there must be path in the timeline
diagram from point t on xs timeline to point t on zs timeline

Concurrent Systems with Shared Variables
The theorems and proofs given in this module apply to systems with
shared variables and indeed any system with trajectories that are
representable by timeline diagrams and with consistent cuts

Summary
Many people working on distributed systems use the phrase an
agent knows This module gives a definition of the concept that is
consistent with intuitive definitions of knowledge The central idea in
this module is the relationship between what agents know and
consistent cuts of timelines We presented several theorems about
httpskmchandygithubioKnowledgeKnowledgehtml

89

71124 542 PM

KnowledgeKnowledgehtml

agent knowledge which are intuitive when applied to human agents

Distributed Algorithms

Contents

Index

The proofs are straightforward and are all based on consistent cuts
of timelines



Review
1 Is the following true Why
z knows P  and z knows Q  z knows P  Q
2 Is the following true Why
z knows P  or z knows Q  z knows P  Q
3 Suppose you and your friend communicate only using
messages sent in channels just as agents do in our model of
distributed systems When you know that your friend is wearing
a cap does that mean that a your friend is wearing a cap and
b your friend cant take the cap off until the friend hears from
you

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioKnowledgeKnowledgehtml

99

71124 548 PM

Distributed Algorithms

DiffusingComputationsDiffusingComputationshtml

Contents

Index



Diffusing Computations
This module describes diffusing computation
algorithms by which an agent can learn about the
structure of the network in which the agent
operates
This module describes diffusing computations An agent can use
diffusing computations to learn about the structure of the network in
which the agent operates For example an agent can use diffusing
computations to determine the number of agents in the network or to
determine if the system is deadlocked
Data Structures in Distributed Algorithms

The module shows how data structures play critical roles in
distributed algorithms just as they do in sequential algorithms The
algorithm maintains the invariants that define the data structure  in
this case a tree  even though the structure is modified concurrently
by multiple agents
Nondeterministic Iteration in Sequential and Distributed Algorithms

This module shows how nondeterministic iteration is used in exactly
the same way for reasoning about sequential and distributed
algorithms Whether the algorithm operates across multiple agents
and channels or is a sequential program is immaterial to reasoning
about its correctness

The Problem
In this module we deal with systems in which an agent is either idle or
active An idle agent remains idle until it receives a message at which
point it becomes active An idle agent does not send messages An
active agent may send messages An active agent may become idle
at any time
Initially the system has a single active agent This agent is called the

initiator Initially all channels are empty The computation terminates
exactly when all agents are idle and all channels are empty
httpskmchandygithubioDiffusingComputationsDiffusingComputationshtml

15

71124 548 PM

DiffusingComputationsDiffusingComputationshtml

The computation may never terminate Our first problem is to design

Distributed Algorithms

Contents

Index

an algorithm that enables the initiator to determine that the
computation has terminated if it terminates Later we will extend this



algorithm to enable the initiator to learn about the network
In this system for every channel from an agent x to an agent y there
is a channel from y to x For any pair x y of agents there exists at
most one channel from x to y and at most one channel from y to x
An agent y sends an ack acknowledgment along channel y x
after receiving a message along channel x y An ack is different
from a message so acks arent acked
Initially all channels are empty there are no messages or acks in
transit along channels Let x num_unacked be the number of xs
unacknowledge messages ie the number of messages that x has
sent minus the number of acks that x has received We can prove the
invariant that there are no messages in any of xs outgoing channels
when x num_unacked  0

A Rooted Tree
For an agent to become active there must be a chain of messages
from the initiator to the agent A data structure with paths between
the initiator and active agents is a tree rooted at the initiator and
which spans active agents For each agent x let x parent be either
null or an agent which is xs parent in the tree Agent x is not on the
tree exactly when x parent  null
We will prove the following invariants

Invariants
1 The tree is rooted at the initiator ie if x parent  null then
the initiator is an ancestor of x
2 An agent is off the tree exactly when the agent is idle and the
agent has no unacknowledged messages

x parent  null



x idle  x num_unacked  0

3 If xs parent is not null then xs parent has at least one
unacknowledged message

x parent  null



x parent num_unacked  0

httpskmchandygithubioDiffusingComputationsDiffusingComputationshtml

25

71124 548 PM

DiffusingComputationsDiffusingComputationshtml

From invariant 3 it follows that an agent has no children if it has no

Distributed Algorithms

Contents

Index

unacknowledged messages So from invariant 1 if the initiator has
no unacknowledged messages then all agents apart from the



initiator are idle and have no messages in outgoing channels
Therefore computation has terminated when

initiator idle  initiator num_unacked  0
So the initiator detects that the computation has terminated when
the initiator is idle and no unacknowledged messages Next we give
an algorithm that maintains the above invariants

Program for an agent
Next we propose a program for an agent x other than the initiator

Program
0 initially
xparent  null
xidle  True
xnum_unacked  0
1 When x sends a message
xnum_unacked  xnum_unacked  1
2 When x receives a message from y
xidle  False
if xparent  null
xparent  y
else
send ack to y
3 When x receives an ack
xnum_unacked  xnum_unacked  1
if xnum_unacked  0 and xidle
send ack to xparent
xparent  null
4 When x becomes idle
xidle  True
if xnum_unacked  0
send ack to xparent
xparent  null
httpskmchandygithubioDiffusingComputationsDiffusingComputationshtml

35

71124 548 PM

The Initiator

Distributed Algorithms

DiffusingComputationsDiffusingComputationshtml

Contents

Index



The program for the initiator is the same except that initially the
initiator is active Also to keep the exposition uniform for the initiator
and the other agents we assume that the initiator has a parent which
is not one of the agents of the network We call the initiators parent

external This agent plays no role other than to keep the proofs
identical for the invariant and other agents
initiatorparent  external
initiatoridle  False
initiatornum_unacked  0
externalnum_unacked  1

Proof of Correctness
Safety
The proof that the invariants are satisfied is carried out by showing
that they hold initially and then verifying that each of the four
commands maintains the invariants The verification step is
straightforward if a bit laborious
Progress
If all agents are idle and there are no messages in channels then the
underlying computation has terminated We will prove that if the
underlying computation does terminate then the detection algorithm
terminates as well ie the tree vanishes and at that point the initiator
detects that the computation has terminated After the underlying
computation terminates the only action that executes is action 3
receiving an ack
A variant function is the following graph A vertex x is in the graph
exactly when x parent is not null or there is an ack in transit along
the channel from x to its parent Define a partial order  between
graphs as G  G when G is a subgraph of G This graph is a tree
because the only pending acks are from a vertex to its parent rule 3
Next we prove that every execution of an action while the variant
function is not the empty graph reduces the variant function When all
acks are delivered to y it sends an ack to its parent So while the tree
is not empty there is an ack in some channel When y receives an ack
from x the edge x y is deleted from the tree Therefore every
execution of action 3 reduces the variant function
httpskmchandygithubioDiffusingComputationsDiffusingComputationshtml

45

71124 548 PM

Review
Distributed Algorithms

DiffusingComputationsDiffusingComputationshtml

Contents

Index



1 Show that when an idle agent becomes active the agent is
added to the rooted tree if it is not already part of it
2 The variant function used to prove progress in this module is a
graph Every action execution of a guarded command with a
true guard must reduce the variant function What does
reducing the graph mean
3 This module says that if the underlying computation has
terminated and the tree hasnt vanished then there exists some
channel that has an ack in it Why is that true

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDiffusingComputationsDiffusingComputationshtml

55

71124 1257 PM

Distributed Algorithms

DistributedSystemModelsBasicsFAQhtml

Contents

Index



Basics FAQ
Why use such a simplistic model
The model is indeed simplistic however it is adequate for describing
and reasoning about many of the algorithms described in the first
part of this course We introduce other models later We use the
simplest model adequate for the problem at hand
We point out the models weaknesses and we introduce other models
as needed to deal with different problems
Can an agent refuse to receive a message
In this model an agent cannot refuse to receive a message If a
channel is not empty then a message from the channel can be
delivered to the agent independent of the state of the agent
Suppose you want to design an algorithm in which an agent X refuses
to receive messages from an agent Z until it first receives a message
from an agent Y How would you use this model
In our model agent X has to receive the message from Z in every
state of X
Agent X can copy the message from Z into a local queue  a local
variable of X  and process the message only after receiving the
message from Y
Can a full channel block a sender from sending more messages
In the model a sender is never blocked from sending a message
How could this model be used to analyze a system in which a
channel has a maximum size and when a channel is full it cannot
accept messages
Our model assumes that channels have unlimited capacity We can
represent a situation in which channels have limited capacity in the
following way An agent has a local output queue into which the
agent puts messages when the channel is full Messages from this

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSBasicsFAQhtml

14

71124 1257 PM

DistributedSystemModelsBasicsFAQhtml

output queue are sent on the channel when the channel stops being

Distributed Algorithms
full

Contents

Index



Can you represent systems in which agents are created and deleted
in the model
The model doesnt have features that allow agents to be created and
deleted
You may want to implement a system in which agents are created
and deleted infinitely often In this case the network of agents
changes over time in an arbitrary fashion The model doesnt
represent such systems
A work around for the case in which agents are created or deleted a
finite number of times is as follows The network of agents in the
model is made large enough to include agents that have not been
created as yet and also include agents that have been deleted An
agent that has not been created is represented by an agent that is
idle ie one that doesnt receive messages An agent this is deleted
is represented in the same way
Can an agent process background jobs that are interrupted when
messages arrive
No there are no interruptions in the model After an agent is initiated
it does nothing but execute receives or wait to execute receives
When an agent is executing a receive it is not interrupted by the
arrival of another message
How do you represent channels that are not first in first out
We use queues to represent states of first in first out channels and
we use other data structures  such as multisets  to represent
states of other types of channels
Later we describe algorithms with different types of channels For
example the state of a channel in which messages may overtake
each other is a multiset or bag A message is sent on a channel by
adding the message to the multiset A nonempty multiset may deliver
any message in the mutliset to the receiving agent
Lossy channels and channels in which messages have priorities are
also modeled by defining channel states appropriately
Can the model represent sequential composition of distributed
computations
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSBasicsFAQhtml

24

71124 1257 PM

Yes

Distributed Algorithms

DistributedSystemModelsBasicsFAQhtml

Contents

Index



There are problems in which we would like to start a distributed
computation P wait for P to finish and then start another distributed
computation Q We want a barrier between P and Q
A barrier can be implemented in several ways An agent say a

coordinator agent sends messages to all agents to start P The
coordinator then detects termination of P we discuss termination
detection algorithms later After detecting termination of P the
coordinator sends messages to all agents to start Q
Can the model represent agents that make state transitions without
receiving messages
No the model does not represent agents that make state transitions
without receiving messages The effect of a state transition without
receiving a message can be simulated by an agent sending itself a
message and carrying out the transition when it receives a message
from itself
Some books on distributed systems allow agents to make internal
state transitions  these are transitions without receiving messages
For example an agent that is computing using a set of files may
transition to a state in which it no longer needs those files this
transition occurs without the agent receiving a message Can the
model represent such internal state transitions
Internal state transitions are represented by transitions in which an
agent receives a message from itself We represent an internal state
change by having the agent send a message to itself the agent
makes a state change when it receives the message
For example an agent that is computing using a set of files sends a
message finished using files to itself and when the message
arrives the agent changes state to one in which it no longer using the
files
Representing internal state changes in this way is an artifice
however the artifice allows us to use a simple model in which a state
change occurs only when a message is delivered
Local clocks can be synchronized using NTP and other protocols
Why do you assume that clocks arent synchronized

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSBasicsFAQhtml

34

71124 1257 PM

DistributedSystemModelsBasicsFAQhtml

Local clocks can indeed be synchronized very accurately however

Distributed Algorithms

Contents

we do not assume that they are perfect

Index



We use agents local clocks for evaluating algorithm performance but
not for proving correctness because even a small drift can cause race
conditions
Consider an algorithm in which one agent carries out a computation
starting at 1pm and another agent carries out a computation starting
at 2pm When we prove the correctness of our algorithms we allow
for the unlikely possibility that that the agent starting its computation
at 2pm does so before the agent that starts a 1pm For evaluating
performance however we assume that the agent that starts a 1pm
usually does so before the agent that starts at 2pm

Next
The next three webpages continue the description of a model of
distributed systems and point out its strengths and limitations The
next page introduces Timelines and Dataflow

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSBasicsFAQhtml

44

71124 340 PM

Distributed Algorithms

PaxosReadWriteLossyChannelshtml

Contents

Index



Serializable Computations in
Faulty Systems
In this webpage we develop algorithms for systems in which agents
may halt or be arbitrarily slow the same message may be delivered
multiple times messages may be delivered out of order and
messages may be lost A transaction consists of two steps a client
reads and the writes shared variables This page shows how a proxy
for time can be used to develop algorithms in which computations
can be serialized each agent starts and completes a transaction
before executing steps of another transaction

Overview
In this webpage we develop algorithms for systems in which agents
may halt or be arbitrarily slow the same message may be delivered
multiple times messages may be delivered out of order and
messages may be lost
A system consists of a set of agents called clients and a set of
agents called servers There is a channel from each server to each
client and from each client to each server
Clients execute transactions in which they send requests to servers
to read and then write variables managed by servers We describe an
algorithm in which computations are serializable which allows us to
treat the sequences of steps at each agent as though exactly one
transaction is executed at a time

Servers
Each server q has a variable qv Clients send requests to q to read
or write qv The only actions of a server are to respond to requests
from clients
A server q replies to a read request from a client p by sending p a
copy of qv A write request includes the value v to be written A
server q assigns v to qv when q receives a write request containing
value v

httpskmchandygithubioPaxosReadWriteLossyChannelshtml

110

71124 340 PM

Clients
Distributed Algorithms

PaxosReadWriteLossyChannelshtml

Contents

Index



Each client receives a sequence of clock tick messages The intervals
between successive clock ticks are irrelevant for the correctness of
the algorithm The intervals do however impact performance There
are many ways of generating clock tick messages and we postpone
discussion of them
A read request and a reply to the request may get lost or be delayed
for an arbitrary time A client avoids waiting forever for a reply by only
accepting replies that the client receives before it receives its next
clock tick message Replies that arrive after the next clock tick are
treated as lost
A transaction consists of a read step and a write step

Read Step of a Transaction
A client p sends read requests to all servers Some requests may be
lost A server that receives a read request from p sends a reply to p
Some replies may be lost Let R be the set of servers from which p
receives replies before p receives its next clock tick
If R has M or more elements where M is a given constant then p
proceeds to the write step If R has fewer than M elements then the
transaction terminates without executing the write step

Write Step of a Transaction
The list of replies that p gets before p receives its next clock tick is
qv for q in R
Client p sends a request to all servers to write pfqv for q in
R where pf is a function of p
Write requests may get lost Let W be the set of servers that receive
write requests
A transaction consists of the step in which a client p broadcasts read
requests to all servers the steps in which servers receive read
requests and send replies the steps in which p receives replies the
step in which p sends write requests and the steps in which servers
receive and execute write requests
Changes to server variables in a transaction are specified by the
following statement in which pf is a function executed by p
httpskmchandygithubioPaxosReadWriteLossyChannelshtml

210

71124 340 PM

Distributed Algorithms
Transaction

PaxosReadWriteLossyChannelshtml

Contents

Index



if lenR  M
for q in W qv  pfqv for q in R

Transactions are tailored to a specific application by specifying M and
pf The selections of R and W are nondeterministic and they can be
arbitrary sets of servers
Transactions executed concurrently by multiple clients can interfere
with each other as illustrated by the following example

Example
Let x be the amount of funds in an account and assume that x has
110 Consider a computation in which clients p and p both execute
identical transactions concurrently In a transaction a client reads x
and if x has at least 100 then the client transfers 100 out of x to an
account y
Consider a computation in which both clients p and p read x and
verify that x has at least 100 and then both clients transfer 100 out
of x and set the amount in x to 10 The computation transfers 200
out of x but debits x by only 100
This situation does not occur if only one client executes a transaction
at a time If p executes its transaction first then when p completes
the transaction it sets the amount in x to 10 If p executes its
transaction next then p finds that x has only 10 and so p does not
transfer 100 from x

Serializable Computations
A system executes multiple transactions concurrently A computation
x is serializable exactly when there exists a sequence of transactions

Zi i  0 such that in x For all agents v for all i
all steps of v in Zi occur before any step of v in Zi1
It is possible that in a serializable computation x an agent u takes a
step in Zj before a different agent v takes a step in Zi where j  i
Transactions and Serializability in Databases

httpskmchandygithubioPaxosReadWriteLossyChannelshtml

310

71124 340 PM

PaxosReadWriteLossyChannelshtml

There is an extensive literature on transactions and serializability

Distributed Algorithms

Contents

Index

Also see transaction processing systems and online transaction
processing In this webpage we provide a narrow definition of



transactions and serializability that is adequate for describing
algorithms such as Paxos

The Problem Guarantee Serializability
The problem is to develop a distributed algorithm with multiple
clients and servers in which computations are serializable and in
which the system may be faulty

How Should You Solve The Problem
What method comes to mind to partition the sequence of steps at an
agent into intervals where the agent completes all steps of exactly
one transaction in each interval
Logical time partitions computations into a past and a future Lets
use a mechanism similar to logical time As with logical time each
step e in a computation is assigned a value te called the epoch of
e For any step e steps with epochs less than equal to or greater
than te are in the past current and future respectively We specify
epochs such that the steps in current consists of all the steps of

exactly one transaction

Epochs and Logical Times
Recall that the logical time of a step e is a value te assigned to
each step e in a computation such that for all edges e e of the
dataflow graph te  te The epoch of a step e in a computation
is defined as a value te assigned to each step e in the computation
such that for all edges e e of the dataflow graph te  te

Rules for Assigning Epochs to Steps
The following rules ensure that the assignment te to each step e in
a computation satisfies the specification for epochs For all steps

e e of a computation
1 for all steps e and e at the same agent if e occurs after e then

te  te and
2 if e is a step in which a message is sent and e is a step in
which that message is received then te  te
Observation
httpskmchandygithubioPaxosReadWriteLossyChannelshtml

410

71124 340 PM

PaxosReadWriteLossyChannelshtml

If e and e are steps at the same agent and te  te then e

Distributed Algorithms
occurs after e

Contents

Index



Theorem A Sufficent Condition for Serializability
A sufficient conditions for a computation to be serializable is
There exists epochs for all steps of a computation such that
1 each transaction has a unique epoch and
2 all steps in a transaction have the epoch of the transaction

If a computation x satisfies this condition then let the epochs of
transactions in x be T0 T1 T2  where Ti  Ti1 and let Zi be
the transaction with epoch Ti Then in x for all i for all agents v
All steps of v in Zi occur before any step of v in Zi1

Proof
Assume that the sufficient condition is satisfied for epochs of steps
in a computation Let e and e be steps in transactions with epoch T
and T  respectively and let T  T  Let e and e be steps at the
same agent v From the observation regarding epochs e occurs
before e Therefore all steps of a transaction with epoch Ti occur
before any step of a transaction with epoch Ti1

An Algorithm Based on the Sufficent Condition
Next we describe an algorithm based on this idea Lets consider the
two issues posed by the condition for serializability 1 How can the
algorithm assign a unique epoch to each transaction 2 How can
the algorithm assign epochs to steps so that all steps in a transaction
have the epoch of the transaction

Uniqueness of a Transactions Epoch
A client p initiates a new transaction when p gets a clock tick
message To ensure that the epoch of the transaction is unique an
epoch t is a pair n p_id where n is a number and p_id is the id
of client p Transactions initiated by different clients have different
epochs because their client ids are different A client sets the epoch
of a new transaction that it initiates to be greater than epochs of all
previous transactions that it initiated So different transactions
httpskmchandygithubioPaxosReadWriteLossyChannelshtml

510

71124 340 PM

PaxosReadWriteLossyChannelshtml

initiated by the same client have different epochs Therefore each

Distributed Algorithms
epoch is unique

Contents

Index



Client ids are totally ordered and so epochs are also totally ordered
For brevity we refer to an epoch by a single value t rather than a pair
n p_id

All Steps in a Transaction have the Transactions Epoch
We associate a field t with each agent  client or server  where t is
the epoch of the step of the transaction that the agent is executing
Likewise we associate a field mt with each message m between
clients and servers where mt is the epoch of the step in which the
message is sent
A message sent in a step of a transaction is received in a step of the
same transaction So for a message m between clients and servers
mt is also the epoch of the step in which the message is received
We design the algorithm so that all steps of a transaction all
messages sent in steps of the transaction and all messages received
in steps of the transaction have the epoch of the transaction
Next we give the algorithm for clients and then for servers

Algorithm for a Client
When a client p gets a clock tick message it executes
pt  pt  pos
where pos returns a positive value and then p initiates a new
transaction with epoch pt Client p continues executing the
transaction with epoch pt until p gets its next clock tick message at
which point it increases pt and starts a new transaction
In the algorithm all steps of p all requests sent by p to clients and all
replies received by p from clients have epoch pt

 Initialization
pt  0
start
def receivemessage sender
if isinstancemessage ClockTick
 Received clock tick
httpskmchandygithubioPaxosReadWriteLossyChannelshtml

610

71124 340 PM

PaxosReadWriteLossyChannelshtml

pt  pt  pos

Distributed Algorithms

Contents

Index

 Start new transaction with epoch pt
 pcopy stores values in replies



pcopy  
 Broadcast read request with epoch pt
for q in Q

sendReadRequestpt q

else
 received a reply to a read request
if messaget  pt
pcopysender  messagev
 send write requests if M replies received
if lenpcopy  M
 Broadcast write request value v epoch t
v t  pf pt
for q in Q sendWriteRequestv t q

Algorithm for a Server
A server waits to get requests from clients
When a server q receives a request r from the transaction that the
server is currently processing ie rt  qt then the server
responds to the request
When a server q receives a request r from a transaction with a
smaller epoch than the transaction that the server is currently
processing ie rt  qt then the server does not respond to the
request The request has the same effect as a request that is lost
What should server q do when it receives a request r from a
transaction with a larger epoch than the servers epoch ie rt 
qt
In this case the server increases its epoch to the epoch of the
request and then responds to the request The request the step in
which the server responds to the request and the reply to a read
request have the same epoch

 initialization
qv qt  init 0
start
httpskmchandygithubioPaxosReadWriteLossyChannelshtml

710

71124 340 PM

PaxosReadWriteLossyChannelshtml

def receiverequest client

Distributed Algorithms

if requestt  qt
qt  requestt

Contents

Index



if isinstancerequest ReadRequest
sendReplyqv qt client
else
 message is a WriteRequest
qv  requestv

Correctness
Next we prove that all computations are serializable in a system
specified by these algorithms for clients and servers
Epoch of a step in a computation of the algorithm
The epoch of a step taken by a client p or server q is the value of pt
or qt respectively upon completion of the step

Theorem
The assignment of epochs to steps satisfies the condition for
epochs ie For all steps e e of a computation
1 if e and e are steps at the same agent and e occurs after e
then te  te and
2 if e is a step in which a message is sent and e is a step in
which that message is received then te  te
Proof
From the algorithms for server p and client q it follows that pt and
qt do not decrease in a computation Therefore the first condition is
satisfied
Also from the algorithm the epoch for step in which a request or
reply is received is equal to the epoch in which the message is sent
So the second condition is also satisfied Therefore the assignment
of epochs to steps of a computation satisfy the specification of
epochs

Theorem
The sufficient condition for serializability is satisfied 1 each
transaction has a unique epoch and 2 all steps in a transaction
httpskmchandygithubioPaxosReadWriteLossyChannelshtml

810

71124 340 PM

PaxosReadWriteLossyChannelshtml

have the epoch of the transaction

Distributed Algorithms

Contents

Index



Proof
We have shown that each transaction initiated by a client p has a
unique epoch pt
All steps at p have epoch pt Requests sent by p have epoch pt
When a client q gets a request with epoch pt the client sets its own
epoch to pt and sends a reply with the same epoch So all steps in
a transaction have the epoch of the transaction Therefore the
algorithm satisfies the sufficient condition for serializability

Corollary
The algorithm satisfies specifications for serializability
Proof
Follows because the algorithm satisfies the sufficient condition for
serializability
Therefore if the epochs of transactions in a computation x are
T0 T1 T2  where Ti  Ti1 then in x for all i for all agents v
All steps of v in the transaction with epoch Ti occur before any step
of v in the transaction with epoch Ti1

Equivalence of Distributed and Sequential
Algorithms
Let the sequence of increasing epochs in a computation x of the
distributed algorithm be T1 T2 T3  and let pi
Ri Wi be the values of p R W in the transaction with epoch
Ti
The sequence of values of agent variables in computation x of the
distributed algorithm is the same as in the following nondeterministic
sequential program by selecting p R W on the ith iteration to be
pi Ri Wi respectively and by selecting delta on the ith iteration so that Ti  Ti1  delta
Equivalent nondeterministic sequential algorithm

t  0
while True
httpskmchandygithubioPaxosReadWriteLossyChannelshtml

910

71124 340 PM

PaxosReadWriteLossyChannelshtml

select positive delta select client p

Distributed Algorithms
t  t  delta

Contents

Index



 p executes transaction with epoch t
pt  t
pcopy  
 Read step
select R
for q in R pcopyq  qv
 Write step
if lenpcopy  M
select W
for q in W qv  pf

We will prove properties of the sequential algorithm and show that
these properties also hold for the distributed algorithm

Next
Next we develop Paxos a distributed consensus algorithm We prove
that Paxos satisfies the specifications for consensus by showing that
Paxos is serializable We prove properties of a nondeterministic
sequential algorithm and show that properties of the sequential
algorithm also hold for Paxos

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioPaxosReadWriteLossyChannelshtml

1010

71124 544 PM

Distributed Algorithms

KnowledgeKnowledgeExamplehtml

Contents

Index



Example
A system has two agents x and y with a channel in each direction
between them The system has two tokens in the initial state If an
agent has a token then it sends it to the other agent
The figure below illustrates how a token may move between the
agents The figure has three diagrams A token is shown as a red
disc In all three diagrams one token is at agent x In the top diagram
one token is on the channel to agent y in the middle diagram one
token is at y and in the lower diagram one token is on the channel to
agent x



When x holds one token it knows y does not hold both
tokens
Using our definition of knowledge when x is in a state in which x
holds exactly one token x knows that y does not hold both tokens
Example
In the above system let P be the predicate y holds exactly one
token
The predicate x knows P  is universally False There is no state in
which x knows that y holds exactly one token because tokens may
be in channels

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology
httpskmchandygithubioKnowledgeKnowledgeExamplehtml

12

71124 544 PM

Distributed Algorithms

KnowledgeKnowledgeExamplehtml

Contents

httpskmchandygithubioKnowledgeKnowledgeExamplehtml

Index



22

71124 702 PM

Distributed Algorithms

DistributedSystemModelsModelshtml

Contents

Index



Timelines and Dataflow
A timeline shows how the state of a system changes over time A

dataflow graph dataflow for short is an abstraction of a timeline
this abstraction has no concept of time other than an ordering of
before and after We discuss the advantages and disadvantages of
using a timefree model

Timelines
Timelines are used to describe the interactions of nations animal
species and ideas over time Here timelines describe the
interactions of agents over time
While an agent executes a receive the agents state changes
over time and the agent may send messages at different points in
time The evolution of the state of a system over time is depicted by a
timeline diagram in which the horizontal axis is the time axis or taxis
Figure 1 shows states of a system with two agents u and v Each
horizontal line shows the state of an agent at each point in time The
lower horizontal line shows the states of agent v and the upper
horizontal line shows the states of agent u

Fig1 Example Timeline
Representation of execution of a receive

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSModelhtml

16

71124 702 PM

DistributedSystemModelsModelshtml

An execution of a receive is represented by a rectangle and the

Distributed Algorithms

Contents

Index

length of the rectangle represents the time to execute the receive For
example rectangles 1 and 4 represent receives executed by agent u



while rectangles 2 and 3 represent receives executed by v The state
of the agent changes as the receive is executed and is specified at
each point in the rectangle
Horizontal edges between successive executions of receives on the
timeline of an agent are labeled with the state of the agent at those
points For example the state of agent v between its second and
third receives is v2
Representation of a message
Each message is represented by a line which is labeled with the
message The line starts from the point on the senders timeline at
the time that the message is sent The line ends at the point on the
receivers timeline at the time that the receiver starts executing the
receive which receives the message For example messages
m2 and m3 are sent by u while it is executing its first receive
Representation of an instant in time
An instant at time T is represented by a vertical line T units to the
right of the origin The state of an agent at time T is the state where
the vertical line at T intersects the horizontal line representing the
agents state The state of a channel at T is shown by the labels of the
channels message lines that intersect the vertical line at T
In figure 1 time T is represented by the dotted red line At T agent u is
executing its first receive and v is executing its second channel v
u contains a single message m4 and channel u v is empty
The initial state of the timeline is given by the initial states of agents
and channels and is shown by the labels of the edges representing
agent states and messages from the point at time 0  the point at
which execution starts
A system may have many timelines
The hardware on which a distributed algorithm executes may be
unspecified The operating system executing a distributed algorithm
may interrupt an agent executing a receive and restart it later
Some agents may execute on slower processors than others The
communication mechanism may get congested causing message
delays to change We can determine properties of the timelines of a
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSModelhtml

26

71124 702 PM

DistributedSystemModelsModelshtml

distributed algorithm only if we have specifications of the operating

Distributed Algorithms

Contents

Index

system and hardware on which the algorithm executes and we often
dont have the information



The passage of time
The passage of time as determined by an agents local clock may
play a role in the behavior of a system For example a receive
function of an agent may have a sleep statement eg
timesleept in Python The system behavior may depend on
the fact that one agent sleeps for 1 second while another agent
sleeps for 10 seconds Local clocks are not perfectly synchronized
however a system designer may know that clocks are usually
accurate and may use clocks in designing the system
Next we describe a model that ignores time and makes no
assumptions about how far local clocks may drift from each other
and from true time Later we discuss the advantages and
disadvantages of using our weak model

Events
The top diagram of figure 2 depicts an execution of receive as time
progresses and the lower diagram ignores time and restricts
attention to the states of the agent before and after execution of the
receive

Fig2 Representation of receive with and without time
An execution of a receive by an agent u is specified by an event at
u An event in which an agent u executes receivemsg v is a 4tuple
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSModelhtml

36

71124 702 PM

DistributedSystemModelsModelshtml

1 us state before it executes the receive

Distributed Algorithms

Contents

Index

2 the message msg received and the sender v of the message
3 us state after it completes execution of the receive and



4 for each output channel of u the sequence of messages sent
and the receivers of the messages
The first two elements of the tuple are called the inputs to the event
and the last two elements are the outputs of the event An event does
not specify the duration of a receive or the state of an agent while it
executes a receive or when messages are sent during execution of a
receive
An agents receive function can be specified by the set of events at
that agent We say that an agent executes event e to mean that the
agent executes a receive that is specified by e An agent changes
state by executing a sequence of events where the agents state after
the ith event is its state before the i  1th for all i

Dataflow
A dataflow graph is an abstraction of a timeline diagram An
execution of a receive is represented by a vertex in the dataflow
graph whereas it is represented by an evolution of the agents state in
a timeline The lower diagram of figure 3 is the dataflow abstraction
of the timeline shown in the upper diagram

Fig3 Example Dataflow Graph

Vertices in Dataflow
A dataflow graph of a system is a labeled directed acyclic graph
Each vertex represents the execution of an event at an agent The
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSModelhtml

46

71124 702 PM

DistributedSystemModelsModelshtml

inputs and outputs of each vertex in a dataflow graph are specified by

Distributed Algorithms

Contents

the event that the vertex represents

Index



For example vertex 1 in the graph represents execution of an event at
agent u specified by the 4tuple 1 the state before the event is u1
2 a single message is received in the event and the message is m1
from v 3 the state after the event is u2 4 a single message m3 is
sent in the event and this message is sent to v

Edges in Dataflow
The edges are in the same as in a timeline and are as follows
1 There is an edge from an event at an agent to the next event at
that agent this edge is labeled with the state of the agent
between the events and is called an agent edge
2 There is an edge from an event in which a message is sent to
the edge at which the message is received this edge is labeled
with the message and is called a message edge

Initial and Final States
A dataflow graph starts in an initial state of the system A dataflow
graph may be finite or infinite A dataflow graph has an initial vertex
labeled O for each agent The output edges from an initial vertex at
an agent u specify us initial state and the states of us output
channels
The graph representing a finite execution of a system has a vertex
labeled N for each agent representing the final state This vertex is
called the final vertex of the agent The input edges to a final vertex at
an agent u specify us final state and the final states of us input
channels The initial and final vertices do not represent events
A finite dataflow graph represents an execution of the system from
the initial state to the final state of the graph

Events and Steps
An agent can execute multiple receives specified by the same event
An event is a 4tuple that specifies a state transition of an agent
Each execution of an event by an agent is called a step taken by the
agent to distinguish an execution of an event from the event itself
Each vertex in a dataflow is a step taken by an agent

Time in Dataflow Before and After
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSModelhtml

56

71124 702 PM

DistributedSystemModelsModelshtml

The only concept of time in a dataflow is that some steps occur

Distributed Algorithms

Contents

Index

before other steps A message is sent before it is received
Equivalently a message is received after it is sent Later steps at an



agent occur after earlier steps at the agent before and after are
partial orders on steps in a dataflow
A step v occurs before a step v in a dataflow exactly when there is a
path from v to v For example steps 0 1 and 2 occur before step 3
Likewise steps 4 and N occur after step 3 Step 1 is neither before nor
after step 2

Advantages and Disadvantages of the
Dataflow Model
Disadvantages
The obvious disadvantage of dataflow is that ignores time which can
play a role in ensuring that a system behaves correctly Moreover a
model that doesnt deal with time cannot deal with specifications that
include time Also time plays a critical role in system performance
Advantages
Analyzing simpler models is easier than analyzing complex ones A
single dataflow represents all timelines with the same flow structure
and arbitrary timing so a property of the dataflow is also a property
of all timelines that the dataflow represents We will prove properties
of all dataflows of a system and these properties also hold for all
timelines
We use the simplest model adequate for the task at hand

Next
Computations shows how a while loop of a sequential program can
be used to analyze distributed algorithms
Frequenty Asked Questions

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSModelhtml

66

71124 331 PM

Distributed Algorithms

ChannelSnapshotsChannelSnapshotsFAQhtml

Contents

Index



Global Snapshots FAQ
Which agent starts a global snapshot algorithm

Any one or more agents starts the algorithm The initiators are not
specified The choice of initiators is usually evident from the
application of the algorithm For example an agent that has been
waiting a long time for a message may initiate a snapshot algorithm
to determine if the agent is in a deadlocked cycle of agents
Can the algorithm be used to detect the states of a subset of agents
and channels or does the algorithm necessarily have to obtain a
snapshot that encompasses all agents
The algorithm can be modified to record states of subset S of agents
and their incident channels Modify the algorithm in the obvious way
An agent does not send markers to agents that are not in S 
The subset of agent and channel states that are recorded are part of
a global state Some algorithms only need states of subsets of
agents
Can the algorithm be used to take repeated snapshots
Yes
Each initiation of the algorithm by an agent x at local time t is
identified by the pair x t Every local snapshot and every marker is
identified in this way So different executions of the global snapshot
algorithm can be disambiguated in this way
Next logical clocks

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioChannelSnapshotsChannelSnapshotsFAQhtml

11

71124 546 PM

KnowledgeKnowledgeSelfTesthtml

Distributed Algorithms

Contents

Index



Self Test
Problem 1
Do Agents only know Truth
True or False

x knows P



P

Problem 2



Fig 1 Agent A knows P at point T
The figure is a timeline diagram for agents A B Message lines are
colored red T is a time represented as a vertical line
Let P be a predicate on the states of agent B If at time T agent A
knows P then P must hold at all points between what point and T
1 between point U and T but not necessarily before U
2 between point V and T but not necessarily before V
3 between point W and T but not necessarily before W

Problem 3

httpskmchandygithubioKnowledgeKnowledgeSelfTesthtml

14

71124 546 PM

Distributed Algorithms

KnowledgeKnowledgeSelfTesthtml

Contents

Index





Fig 2 Agent A knows P at point T
The figure is a timeline diagram for agents A B Message lines are
colored red T is a time represented as a vertical line
Let P be a predicate on the states of agent B If at time T agent A
knows P then P must hold at all points between T and what point
1 between point T and point 1 but not necessarily before 1
2 between point T and point 2 but not necessarily before 2
3 between point T and point 3 but not necessarily before 3
4 between point T and point 4 but not necessarily before 4
5 between point T and point 5 but not necessarily before 5

Problem 4
Let P be a predicate on the states of an agent y and let x be a
different agent in the system Let T and T  be points on a timeline
with T  T 
Part a
True or False If x knows P  holds at T and x knows P holds
at T  then x must have received a message between T and T 
Part b
True or False If x knows P  holds at T and x knows P holds
at T  then x must have sent a message between T and T 

Answers
Problem 1
True
Follows from definition of x knows P 
httpskmchandygithubioKnowledgeKnowledgeSelfTesthtml

24

71124 546 PM

Problem 2

Distributed Algorithms

KnowledgeKnowledgeSelfTesthtml

Contents

Index



P must hold at all points between point V and T but not necessarily
before V 
Follows directly from the theorem on communication to learn about
change
Example
Consider this example The system has a single indivisible token P is
the predicate Agent B does not hold a token Agent B holds the
token before point V and sends the token to A at V  Agent A knows
P when it receives the token But P does not hold before V 
Anthropomorphic Argument
Proofs in which we assume digital agents have human capabilities
can be faulty They give insight but its best to use definitions
Agent A gets no message with information after the message sent
by B at point V  So agent A does not learn anything after that point
If there is a transition from P to P after point V then there is no
way for A to find out about this transition

Problem 3
P must hold between T and point 4 on Bs timeline
Follows directly from the theorem knowledge implies control
Anthropomorphic Argument
Proofs in which we assume digital agents have human capabilities
can be faulty They give insight but its best to use definitions
Agent B can change P only after getting permission from agent A
This permission may be communicated through intermediate agents
The earliest point that B gets a message is at point 4

Problem 4
Part a
True

httpskmchandygithubioKnowledgeKnowledgeSelfTesthtml

34

71124 546 PM

KnowledgeKnowledgeSelfTesthtml

Because x knows P  holds at T there is some state of the

Distributed Algorithms
Contents
Index
system where P holds for the local state s of agent y while the
state of agent x is its state at point T 



Because x knows P holds at T  the state of y cannot be s at point
T  So there is a transition from s to a different state s at some point
between T and T  If x doesnt get a message after y transits from s
to s then the cut through point T  on xs timeline and point T on ys
timeline is a consistent cut So x knows P  holds at T  as well
Part b
False
Example P is the predicate y does not hold a token And x gets a
token from y between points T and T  So x knows P  holds at
T and x knows P at T  and x sends no messages

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioKnowledgeKnowledgeSelfTesthtml

44

71124 553 PM

Distributed Algorithms

DiffusingComputationsApplicationsDiffusingComputationhtml

Contents

Index



Applications of Diffusing
Computation
This module describes diffusing computation
algorithms by which an agent learns properties of
the network in which the agent is situated
Diffusing computations are used by an agent to learn properties of
the network in which the agent is embedded We will first look at
cases in which the network is static and then study an algorithm in
which an agent learns properties of the network while the network is
changing
In this problem agents are in a static network If there is an edge
from an agent x to an agent y in the network then there is an edge in
the reverse direction

Acquiring Graph Information
Associated with each agent x is some constant value x v where

x v is arbitrary For example x v could be the coordinates of agent
x in 3D space or agent xs lists of assets and liabilities or the files
for which it has exclusive locks
An agent called the initiator starts a computation by which it learns
the values of all the agents in the network When the the computation
terminates the initiator will have a set initiator values where the
elements of the set are pairs x x v with one element for each
agent in the system
We first give the program and then prove its correctness The
program is a simple version of a diffusing computation The
simplification comes from the facts that
1 Each agent becomes active only when it receives its first

message It doesnt change its activeidle state when it
receives subsequent messages So each agent changes from
idle to active exactly once
httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationhtml

17

71124 553 PM

DiffusingComputationsApplicationsDiffusingComputationhtml

2 After an agent sets its parent to a nonnull value it does not

Distributed Algorithms

Contents

Index

change its parents thereafter So the tree grows and once an
edge of the tree is created that edge is never changed



3 For each channel c exactly one message and exactly one ack
traverses the channel in the algorithm
By contrast in a general diffusing computation an agent may become
active multiple times because each time an idle agent receives a
message it becomes active In the general case edges of the tree are
created and may be later deleted
Associated with each agent x is a local boolean variable
x received_all_acks which is True exactly when agent x has
received acks for all the messages that it has sent
Each ack has a field called values which is a set The elements of this
set are pairs x x v where x is an agent

Simpler Version
Initially x parent  null for all agents x other than the initiator
The initiator starts the computation by executing the following
program
initiatorvalues  initiator initiatorv
send a message to each neighbor of the initiator
Next we give the program for an agent x other than the initiator

1 if xparent  null and x receives a message from y
xparent  y
 xparent does not change from now onwards
xvalues  x xv
send a message to each neighbor of x other than xparent
2 if xparent  null and x receives a message from y
send ackvalues   to y
3 if x receives an ack
 set xvalues to the union of xvalues and ackvalues
xvalues  unionxvalues ackvalues
if xreceived_all_acks
send ackvaluesxvalues to xparent
httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationhtml

27

71124 553 PM

DiffusingComputationsApplicationsDiffusingComputationhtml

Proof
outline
Distributed
Algorithms

Contents

Index



The steps of the proof are as follows
1 An agent x changes x parent exactly once from null to a
nonnull value The initiator is the ancestor of all agents x for
which x parent is not null The tree propagates to span all
agents reachable from the initiator
2 For each agent x its value x x v is propagated exactly once
to its parent This value is then propagated along edges of the
tree through ancestors of x to the initiator

Examples
The algorithm can be optimized for problems in which the initiator
has to discover different kinds of information about graphs For
example if agents have colors and the initiator has to discover the
numbers of agents of each color then values can be counts of agents
of each color and counts can be summed instead of taking unions of
sets

Example
Next we look at an example of an algorithm in which an agent
acquires a specific kind of graph information An agent has a color
either red or blue and the color does not change The initiator has to
discover whether there exists at least one red agent in the network
An optimization is that if the diffusing computation reaches a red
agent then the red agent does not diffuse the computation even
further We give the optimized algorithm program 2 below Its proof
of correctness is similar to the proof of program given above

Program 2 Detecting a red agent
1 if xparent  null and

x receives a message from y

xparent  y
if xcolor  red
send ackcolorred to y
else
send a message to all neighbors of x other than y
2 if xparent  null and x receives a message from y
send ackcolorxcolor to y

httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationhtml

37

71124 553 PM

DiffusingComputationsApplicationsDiffusingComputationhtml

3 if x receives an ack A and x has not sent an ack to xparent

Distributed Algorithms

Contents

Index

if Acolor  red
send ackcolorred to xparent



elif xreceived_all_acks
send ackcolorblue to xparent
If the initiator receives at least one red ack then the network has a red
agent If the initiator receives only blue acks then the network has no
red agent

Termination Detection Revisited
We described the problem of detecting that a computation has
terminated in the module on global snapshot applications We also
described an algorithm to solve that problem in the module Now we
give another algorithm to solve the same problem This algorithm
combines diffusing computation and the snapshot algorithm and is a
small modification of program 2

Problem Specification
For convenience the problem definition from the earlier module is
repeated here
An agent is either idle or active An idle agent remains idle until it
receives a message An idle agent does not send messages An
active agent may send messages An active agent may become idle
at any point An idle agent becomes active when it receives a
message Initially all agents are active and all channels are empty
A terminated state of the system is one in which all agents are idle
and all channels are empty terminated is stable a system in a
terminated state remains terminated thereafter A system may or
may not enter a terminated state Our task is to develop an algorithm
that detects that a system has entered a terminated state

Algorithm
In analogy with program 2 lets give colors to agents Lets specify
that an agent that is idle throughout the snapshot algorithm is
colored blue An agent that is active at any point during the snapshot
algorithm is colored red The initiator has to discover whether any
agent is red
The differences between termination detection and the problem of
detecting a red agent are that 1 agent colors may change during
httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationhtml

47

71124 553 PM

DiffusingComputationsApplicationsDiffusingComputationhtml

termination detection and 2 termination detection has to detect

Distributed Algorithms

Contents

Index

properties of channels  namely whether channels are empty  in
addition to detecting properties of agents A surprising result is that



program 2 with the addition of a statement to deal with channels can
be used for termination detection
In the modified algorithm the initiator takes its local snapshot when it
initiates the algorithm All other agents take their local snapshot
when they set their parents to nonnull values
The statement that we add is
4 if xparent  null and x receives a message
if x has not sent an ack to xparent
send ackcolorred to xparent

Proof outline
Consider the following modification to the snapshot algorithm
replace the ack and message of program 2 by markers of the
snapshot algorithm The resulting program is identical to the
snapshot algorithm with two differences
1 An ack in program 2 may be sent later than a marker is sent in a
snapshot algorithm In the snapshot algorithm when an agent
receives a marker for the first time it sends markers
immediately In the modified algorithm however an agent may
not immediately send an ack when it receives a command This
is because of the elif clause in statement 3 an agent sends an
ack only after receiving acks for all the messages that it sent
2 The snapshot algorithm takes snapshots of channels as well as
agents The modified algorithm doesnt mention channels
Next we address these two differences
Late arrivals of markers dont matter for the purposes of detecting
termination If computation has terminated then agents will be idle
when markers arrive regardless of when they arrive Likewise the
algorithm records channel states as empty regardless of when
markers arrive
If x receives no messages after it takes its local snapshot and before
receiving markers on all its incoming channels then all its incoming
channels are empty Statement 4 identifies the computation as not
terminated when x receives a message

httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationhtml

57

71124 553 PM

DiffusingComputationsApplicationsDiffusingComputationhtml

Index
CommunicationContents
Deadlock
Detection
Distributed Algorithms



Communication deadlock is identical to termination detection with
one difference An idle agent in termination detection becomes active
if it receives a message from any agent By contrast in the
communication deadlock problem an idle agent becomes active only
if receives a message from a set of agents for which it is waiting An
earlier module on deadlock detection developed algorithms to detect
deadlock when an idle agent became active only if it received
messages or resources from all the agents for which it is waiting In
the communicationdeadlock case an idle agent became active if it
receives messages from any of the agents for which it is waiting

Problem Specification
An agent is either active or waiting Associated with each waiting
agent x is a nonempty set x waits of agents x becomes active if it
receives a message from any agent in x waits and x remains
waiting if it receives a message from an agent that is not in x waits
A waiting agent does not send messages Active agents may send
messages

The Algorithm
The algorithm for communication deadlock detection is the same as
that for termination detection except that the network is restricted to
agents that are waiting The network has a channel between a pair of
agents if either agent in the pair is waiting for the other

Review
1 Modify the algorithm to count the number of red agents to
count agents of all colors Assume that colors of agents dont
change
2 Now consider the case where each agent is either red or blue A
blue agent can become red A red agent does not change its
color Develop an algorithm to obtain a lower bound on the
number of red agents and an upper bound on the number of
blue agents The algorithm should get good bounds Obviously
0 is a lower bound and N the number of agents is an upper
bound

httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationhtml

67

71124 553 PM

DiffusingComputationsApplicationsDiffusingComputationhtml

K Mani Chandy Emeritus Simon Ramo Professor California Institute

Distributed Algorithms
of Technology

Contents

Index

httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationhtml



77

71124 705 PM

Distributed Algorithms

DistributedSystemModelsBasicsFAQhtml

Contents

Index



Timelines and Dataflow FAQ
Dataflow doesnt have the concept of time Does that mean that we
cannot use time in our algorithms
You can use the local clock of an agent in its receive function
Indeed it can be helpful to do so For example you can have a sleep
statement in a receive
Properties of all dataflows of a system are properties of all timelines
of the system Dataflow doesnt make any assumptions about time
and so it works for all possible evaluations over time
You may be able to determine more properties of a system by making
assumptions about local clocks however properties that you prove
without making assumptions are properties that hold for any
assumptions that you make
Does dataflow assume that events are instantaneous
Dataflow makes no assumptions about the duration of an event The
only states of an agent that appear in dataflow are the states You
can however think of a vertex in a dataflow as an event in which a
receive is executed in an infitisimally small time
Local clocks can be synchronized using NTP and other protocols
Why do you assume that clocks arent synchronized
Local clocks can indeed be synchronized very accurately however
we do not assume that they are perfect
We use agents local clocks for evaluating algorithm performance but
not for proving correctness because even a small drift can cause race
conditions
Consider an algorithm in which one agent carries out a computation
starting at 1pm and another agent carries out a computation starting
at 2pm When we prove the correctness of our algorithms we allow
for the unlikely possibility that that the agent starting its computation
at 2pm does so before the agent that starts a 1pm For evaluating
performance however we assume that the agent that starts a 1pm
usually does so before the agent that starts at 2pm
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSModelFAQhtml

12

71124 705 PM

Next
Distributed Algorithms

DistributedSystemModelsBasicsFAQhtml

Contents

Index



Computations shows how a while loop of a sequential program can
be used to analyze distributed algorithms

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSModelFAQhtml

22

71124 332 PM

ChannelSnapshotsLogicalClocksNewhtml

Distributed Algorithms

Contents

Index



Logical Clocks
A logical clock algorithm assigns a value called the logical time to
each step in a computation so that all sequences of steps in
ascending logical time are computations

The Problem
Design an algorithm that assigns a value called the logical time to
each step in a computation so that all sequences of steps in
ascending logical time are computations
This definition is different from that given in the paper that introduces
the concept

How Should You Solve the Problem
Strategy
A strategy for assigning attributes to steps in computations is to find
a property of computations that can help
We use the following property A computation is a sequence of steps
in which for all edges e e in the dataflow graph corresponding to
the computation

e occurs before e in the sequence
This property suggests the following algorithm to assign logical time
te to step e

The Logical Time Property
For all edges e e of the dataflow graph te  te

Example Logical Times of Steps
Figure 1 shows the dataflow graph of a computation with agents

A B C and an step sequence 0 1 2    The numbers inside
the vertices are the step ids which show the position of the step in
httpskmchandygithubioChannelSnapshotsLogicalClockshtml

13

71124 332 PM

ChannelSnapshotsLogicalClocksNewhtml

the computation The red numbers outside the steps are logical times

Distributed Algorithms
assigned to steps

Contents

Index



Logical times are arbitrary provided every edge is directed from a
lower to a higer logical time

Fig 1 Logical Times of Steps Edges Directed from
Lower to Higher Logical Times
Verify that every edge in figure 1 is from an step with a lower logical
time to an step with a higher logical time

Steps in Increasing Order of Logical Time
All sequences of steps in increasing order of logical time are
computations
This result follows from the fact that all topological sorts of dataflow
graphs are computations and sequences of of steps in increasing
logical time are topological sorts
For example a sequence of steps in increasing logical time in figure 1
is 1 2 4 3 5 6 7 8 9 and this sequence is a computation

A Logical Clock Algorithm
The following algorithm is suggested by the logical time property Let

te be the logical time assigned to step e A message sent in an
step e is assigned a timestamp te

Let e be the step immediately preceding an step e at an agent and
let the timestamp of the message received in e be T 
httpskmchandygithubioChannelSnapshotsLogicalClockshtml

23

71124 332 PM

ChannelSnapshotsLogicalClocksNewhtml

Set te to be any value greater than maxte T

Distributed Algorithms

Contents

Index



The correctness of the algorithm is self evident

Next
Logical clocks are used to record global snapshots as described
here

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioChannelSnapshotsLogicalClockshtml

33

71124 554 PM

Distributed Algorithms

DiffusingComputationsApplicationsDiffusingComputationExamplehtml

Contents

Index



Examples Combining
Algorithms
These examples show how to compose or combine algorithms

Snapshot Termination Detection
This algorithm combines the global snapshot algorithm and diffusing
computations to get an algorithm that is initiated by a single agent

which detects when the snapshot algorithm has terminated
Single initiator of snapshot
An earlier module gave the rules for the global snapshot algorithm
These rules allow multiple agents to start recording their states either
independently or when they receive markers from other agents who
have recorded their own states Now lets design an algorithm in
which a single agent called the initiator is the only agent that records
its state independently and all other agents record their states only
when they receive markers
Initiator detects termination of snapshot
A global snapshot is complete when all agents have recorded their
own states and the states of all incoming channels The rules for the
snapshot algorithm dont specify how an agent detects that the
global snapshot is complete Now lets look at an algorithm by which
the initiator detects that the snapshot algorithm is over In this
algorithm the initiator does not get the local snapshots of all the
agents the initiator merely detects that the states of all agents and
channels have been recorded

Problem Specification
A system is as specified in diffusing computations There is a
channel from agent x to agent y if and only there is a channel from y
to x All agents are reachable by a sequence of channels from an
agent called the initiator

httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationExamplehtml

12

71124 554 PM

DiffusingComputationsApplicationsDiffusingComputationExamplehtml

Modify the global snapshot algorithm so that it is started by a single

Distributed Algorithms

Contents

Index

agent which detects that the algorithm has terminated



Solution Combine Algorithms
The solution is a diffusing computation algorithm which takes global
snapshots
A message in the diffusing computation is a marker in the snapshot
algorithm When a message ie marker is received by an idle agent
the agent becomes active sends messages ie markers specified
by the snapshot algorithm and becomes idle
The diffusing computation terminates when all agents are idle and all
channels are empty So the computation terminates when each agent
has completed its step of the snapshot algorithm and when all
markers have been received This implies that at termination the
states of all agents and channels have finished being recorded

Initiator Acquires the Global
Snapshot
In the algorithm given above the initiator detects that the global
snapshot is complete  ie each agent has finished recording its
state and the states of its incoming channels The algorithm does not
show how the local information of each agent is sent to the initiator
An algorithm to send agent information to the initiator operates in
two phases
1 Execute a diffusing computation in which the initiator detects
that a global snapshot is complete
2 Initiate the algorithm to acquire graph information The
information that is acquired from each agent is its recorded
state and the recorded states of its incoming channels

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationExamplehtml

22

71124 706 PM

Distributed Algorithms

DistributedSystemModelsModelshtml

Contents

Index



Computations
A computation is a sequential representation of the execution of a
distributed system We use techniques for proving sequential
programs to prove properties of computations and thus prove
properties of distributed systems

A Sequential Programming Representation
A timeline is representation of an execution of a distributed system a
dataflow is an abstraction of a timeline Next we look at a sequential
programming abstraction of a distributed system
Consider a sequential program consisting of an initialization not
shown and the following while loop
while there exists a nonempty channel in the system
select a nonempty channel u v
let the head of channel u v be msg
v executes receivemsg u
Execution of the while loop terminates in a state in which all channels
are empty If there are multiple nonempty channels in an iteration
then any nonempty channel is selected We discuss fairness in
selection later in the course Each iteration of the while loop executes
a single event Another representation of the loop is
while there exists an event that can be executed
execute any executable event

Each iteration of the while loop causes a state transition by changing
the state of one agent and the states of channels incident on that
agent Next we define computations and relate the sequential
program to computations

Computations
A computation is a sequence of one or more states S0 S1 S2 
where the initial state S0 of the sequence is an initial state of the
system and where there exists an event at an agent of the system
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSComputationshtml

15

71124 706 PM

DistributedSystemModelsModelshtml

that causes a transition from each state in the sequence to the next

Distributed Algorithms

Contents

A computation may be finite or infinite

Index



A computation can also be specified by an initial state S0 and a
sequence of events e0 e1    where execution of the ith event ei
causes a transition from the ith to the i  1th state of the
computation
A step of the computation is an execution of a single event in this
sequence The same event  specified by the 4tuple that defines a
state transition  can occur multiple times in a computation So
different steps may be executions of the same event

Relationship between Computations and a While
Loop
Let S0 be the state before execution of the while loop and let Si be
the state upon completion of the ith iteration of the loop for i  0
while there exists an event that can be executed
execute any executable event

The sequence of states S0 S1    is a computation The while
loop may not terminate and a computation may be infinite
The advantage of using a while loop to generate the states of a
computation is that we can use familiar techniques for reasoning
about while loops to reason about distributed algorithms
Reasoning about While Loops Loop Invariants and Loop Variants
A loop invariant is an assertion about the state of the program that
holds before and after each iteration of the loop We use invariants to
prove that all states in an execution of a distributed system have
some property such as all states are safe
We prove that some desired property holds at some point in the
execution of a while loop by using loop variants also called variant
functions or metrics Methods for proving progress properties are
given later

Relationship between Computations and
Dataflow
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSComputationshtml

25

71124 706 PM

DistributedSystemModelsModelshtml

Associated with each computation is a dataflow that has the same

Distributed Algorithms

Contents

Index

steps as the computation A computation is a sequence of steps
whereas a dataflow is a partial ordering on steps A computation has



exactly one dataflow associated with it A dataflow may have multiple
computations associated with it
We adopt the following convention in diagrams of of computations
We depict a computation by a dataflow graph with earlier steps in the
computation appearing to the left of later steps in the computation
Figure 4 shows computations 1 2 3 4 and 2 1 3 4 Both
computations have the same dataflow

Fig4 Example Different Computations with the same
Dataflow
Topological Sorts of Directed Acyclic Graphs
A topological sort of a directed acyclic graph is a sequence of
vertices of the graph where every edge e e in the graph e appears
before e in the sequence
For example 0 1 2 3 4 N and 0 2 1 3 4 N are topological
sorts of the graph shown in figure 4 0 1 3 2 4 N is not a
topological sort because the graph has an edge 2 3 and 3 appears
before 2 in the sequence For similar reasons 0 1 2 4 3 N is not
a topological sort

Theorem
All topological sorts of a dataflow graph are computations

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSComputationshtml

35

71124 706 PM

DistributedSystemModelsModelshtml

The initial state is the state after the initial step step 0 at each

Distributed Algorithms
agent

Contents

Index



Proof
Let z be a topological sort of a dataflow graph G We will prove by
induction on n that zn the sequence consisting of the first n
elements of z is a computation The base case is n  0 Let the
n  1th element of z be vertex v Let this vertex represent a step at
an agent a in which a receives a message m on a channel c and the
state of a before the step is s
Because z is a topological sort
1 zn consists of vertices with paths to v So the state of agent a
before v in G is s
2 The step in which message m is sent is in zn and all messages
received by a on channel c prior to m are also in zn So after zn
the state of c has m at its head
Therefore there is a step in which a receives a message m on a
channel c and the state of a before the step is s

Alternate Version of the Theorem
A computation is a sequence of steps of a dataflow graph in which
for all edges e e in the graph

e occurs before e in the sequence

Next
This page describes the model of distributed systems that we use to
design most of the algorithms in this course You may wonder how a
model as simple as a sequential while loop that ignores critical
features of time evolution of system state can be useful This course
give examples of algorithms designed using this and other models
The next webpage discusses the concepts of past and future in
computations and dataflow
Frequenty Asked Questions

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSComputationshtml

45

71124 706 PM

Distributed Algorithms

DistributedSystemModelsModelshtml

Contents

Index

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSComputationshtml



55

71124 334 PM

Distributed Algorithms

ChannelSnapshotsLogicalClocksSnapshotshtml

Contents

Index



Logical Clocks and Global
Snapshots
The state at which all agents are at the same logical time t is a global
snapshot The state when local physical clocks of all agents are at
the same time t may not be a global snapshot Combining physical
and logical clocks results in clocks that tick forward and where the
state when all local clocks are at the same time is a global snapshot
Examples of algorithms that use such clocks are given later

Problem Global Snapshots at Logical
Times
Design an algorithm that computes global snapshots using logical
clocks

How Should You Solve the Problem
Strategy
Use properties of logical times and computations
Sequences of steps in increasing logical time are computations
Therefore the sequence of steps with logical time at most t is a
computation for all t This suggests the following definition of the
state at logical time t

State at Logical Time t
The state of an agent A at logical time t is its state after steps with
logical time t or less and before steps with logical time greater than t
The state of a channel at logical time t is the sequence of messages
sent along the channel in steps with logical time at most t but not
received in these steps

Example State at Logical Time t
Figure 1 illustrates the state at logical time 65 of the computation
shown in figure 1 The curved purple line represents the cut The cut
httpskmchandygithubioChannelSnapshotsLogicalClocksSnapshotshtml

14

71124 334 PM

ChannelSnapshotsLogicalClocksSnapshotshtml

separates the past of the cut from its future Past steps are colored

Distributed Algorithms

Contents

Index

black while future steps are colored green The states of agents and
channels at logical time t  65 are given by the labels of the edges



that cut the purple line

Fig 1 Cut at Logical Time 65 Past is Set of Steps with
Logical Time at most 65
The point at which the purple line cuts the timeline for agent A can
be thought of as the point in As computation at which the logical
time is exactly 65 This cut is on the edge from the step at A with
logical time at most 65 to the step with logical time greater than 65
In this example the cut is on the edge from step 3 to step 5
The message edge from step 3 to step 7 represents a message sent
along the channel from A to B in the past that is received in the
future In this example the state of the channel A B is the
sequence consisting of a single message which is the label of this
edge

Global Snapshot Algorithm to Record the State at a
Logical Time
An algorithm to record the state at logical time t follows directly from
the definition of the state at logical time t
1 Each agent takes its local snapshot  ie records its state after a step with logical time at most t and before a step with
logical time greater than t
2 An agent records the state of an input channel as the sequence
of messages with timestamps atmost t that the agent receives
when its logical clock exceeds t
httpskmchandygithubioChannelSnapshotsLogicalClocksSnapshotshtml

24

71124 334 PM

ChannelSnapshotsLogicalClocksSnapshotshtml

The purple line in figure 2 represents the global snapshot at logical

Distributed Algorithms
time 65

Contents

Index



Using Imperfect Clocks in Distributed
Algorithms
Intuition
We will design some algorithms using logical time to play the role of
real time Figure 3 shows the computation in figure 2 with the
horizontal axis representing real time The position of a step with
logical time t is at a distance of t units from the origin

Fig 3 Computation with Logical Time as Real Time
Think of logical time as continuous just as real time is continuous In
this example points at logical times 65 and 66 at agent A refer to
the same edge It helps intuition however to think of the point at
logical time 66 as a location to the right of the point at logical time

65 on the same edge Imagine that logical time 66 is 01 time units
to the right of logical time 65
The cut at logical time 65 is represented by the vertical line at time
65 The left of the line is the past at logical time 65 and the right
side of the line is the future at that time
Physical and Logical Clocks
Operating systems maintain clocks Some have atomic clocks or
other highfidelity clocks that use Precision or Network Time
Protocols PTP NTP With highfidelity clocks a message sent when
the senders clock is at t will almost always be received when the
receivers clock is later than t So physical clocks almost always obey
the logical clock requirement
httpskmchandygithubioChannelSnapshotsLogicalClocksSnapshotshtml

34

71124 334 PM

ChannelSnapshotsLogicalClocksSnapshotshtml

We cannot rule out the possibility that a message sent when the

Distributed Algorithms
Contents
Index
senders clock is at t is received when the receivers clock is earlier
than t or equal to t We can use physical clocks but correct them so



that messages are received only after they are sent where the times
are determined by corrected physical clocks
Such clocks have the following properties that we use in designing
algorithms
1 Clocks tick forward forever For all t there is a point in an
infinite computation at which clocks of all agents exceed t
2 Sequences of steps in ascending order of time are
computations

Next
The next few pages describe applications of global snapshots We
begin with Termination Detection

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioChannelSnapshotsLogicalClocksSnapshotshtml

44

71124 556 PM

Distributed Algorithms

DiffusingComputationsDiffusingComputationsSelfTesthtml

Contents

Index



Diffusing Computations Self
Test
Question 1
In this module we differentiate between acks and messages An ack
travels along channels exactly like a message does however we use
acks only to acknowledge messages So acks are not themselves
acknowledged
Part a
When agent x gets a message from agent y then which of the
following is True
1 At that point agent y is on the tree ie y parent  null
2 At that point agent y is not on the tree ie y parent  null
Part b
When agent x gets a message from agent y then what action does x
take if x parent  null
Part c
When agent x gets a message from agent y then what action does x
take if x parent  null
Part d
If xnum_unacked  0 then which of the following is True
1 There are no messages in xs outgoing channels
2 x has no descendants
3 There are no acks in xs incoming channels
Part e
True or False
If x parent  y then x has received more messages from y than x
has sent acks to y
httpskmchandygithubioDiffusingComputationsDiffusingComputationsSelfTesthtml

13

71124 556 PM

Part f

Distributed Algorithms

DiffusingComputationsDiffusingComputationsSelfTesthtml

Contents

Index



True or False
If x parent  y and w is different from x and y then x has
received more messages from w than x has sent acks to w

Answers
Question 1
Part a
When agent x gets a message from agent y then which of the
following is True
1 At that point agent y is on the tree ie y parent  null
2 At that point agent y is not on the tree ie y parent  null
Part a Answer
At that point agent y is on the tree ie y parent  null
This is because if there is a message in an outgoing channel from y
then y is on the tree
Part b
When agent x gets a message from agent y then what action does x
take if x parent  null
Part b Answer
Agent x sets x parent  y and does not immediately send an ack
to y for that message
Part c
When agent x gets a message from agent y then what action does x
take if x parent  null
Part c Answer
Agent x sends an ack to y and leaves x parent unchanged
Part d
If xnum_unacked  0 then which of the following is True
httpskmchandygithubioDiffusingComputationsDiffusingComputationsSelfTesthtml

23

71124 556 PM

DiffusingComputationsDiffusingComputationsSelfTesthtml

1 There are no messages in xs outgoing channels
Distributed Algorithms
Contents
Index
2 x has no descendants
3 There are no acks in xs incoming channels



Part d Answer
All are True
Part e
True or False
If x parent  y then x has received more messages from y than x
has sent acks to y
Part e Answer
True

x has received one more message than it has acknowledged
Part f
True or False
If x parent  y and w is different from x and y then x has
received more messages from w than x has sent acks to w
Part f Answer
False

x immediately acknowledges messages from agents other than its
predecessors

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDiffusingComputationsDiffusingComputationsSelfTesthtml

33

71124 709 PM

Distributed Algorithms

DistributedSystemModelsTimelineshtml

Contents

Index



Past Future and Cuts in Dataflow
This page introduces the concept of a cut of a dataflow graph and
relates a cut to the only notions of time  past and future  in
dataflow A cut separates past from future Cuts of dataflow are
central to understanding detection algorithms such as deadlock
detection and for global snapshot algorithms that determine states
of distributed systems

Cuts of a Dataflow Graph
The only concept of time in dataflow is that of before and after Recall
that a vertex v is before a vertex w in the dataflow graph exactly
when there is a path from v to w And w is after v exactly when v is
before w

A cut of a dataflow graph is a partition of the set of vertices of the
graph into subsets past and future such that all steps before past
steps are past steps

The cut requirement can also be specified as all steps after future
steps are future steps or equivalently as There is no past step
after a future step
A cut of a dataflow graph is an instance of the general cut of a graph
and more specifically a cut of a flow network where the source is an
initial vertex and the sink is a final vertex

The State at a Cut
The state of the system at a cut past future is specified by
the labels of edges from past to future
Example
The top diagram of figure 1 shows a cut in which vertices in past are
colored red and vertices in future are green The curved black line is
the boundary separating past from future

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSTimelineshtml

14

71124 709 PM

Distributed Algorithms

DistributedSystemModelsTimelineshtml

Contents

Index



Fig1 Example  A Cut of a Dataflow Graph
In figure 1 all edges to past steps are from past steps and all edges
from future steps are to future steps
The state S after completion of past steps and before initiation of
future steps is given by the labels of edges from past to future
These are the edges that cross the boundary line separating past
from future
S is the final state of the subdataflow of past steps S is also the
initial state of the subdataflow of future steps
See the lower diagram in figure 1 S is shown as final vertices which
are labeled N of past dataflow and S is shown as as initial vertices
which are labeled 0 of future dataflow

Cuts of Computations
Associated with a computation is exactly one dataflow graph
consisting of the steps of the computation We define a cut of a
computation as a cut of the dataflow of the computation

Properties of Cuts
The proofs of these properties are straigtforward and are given here

Dataflows of Past steps before Future steps
Given a cut past future of a dataflow graph There exists a
dataflow consisting only of past steps and there exists exists a
dataflow consisting only of future steps

Computations of Past before Future
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSTimelineshtml

24

71124 709 PM

DistributedSystemModelsTimelineshtml

Let computation X start in state Sinit and end in state Sfini Let S 

Distributed Algorithms

Contents

Index

be the state at a cut past future of X There exists a
computation Y that starts in Sinit visits S  and ends in Sfini



All steps in past are executed before all steps in future in Y 

Cut based on Message is Received only after it is Sent
There exists a cut past future exactly when the following two
conditions hold
1 Every message received in past is sent in past
2 If a step x of an agent is in past then steps at that agent
before x are also in past

Cut based on Counts of Messages Sent and Received
A version of this property that uses only counts of messages is used
in termination detection and is as follows
There exists a cut past future exactly when the following two
conditions hold
1 For all C  Cs  Cr
where Cs and Cr are the numbers of messages sent and
received respectively on channel C  in past
2 If a step x of an agent is in past then steps at that agent
before x are also in past

Computations through Increasing Cuts
Let Si be the state at a cut pasti  futurei for i  0 1 
where
For all i pasti  pasti1
There exists a computation that visits states Si in increasing order of
i

Next
The properties of cuts in dataflow and the concepts of before  after
past  future are central for algorithms by which agents record the
states of distributed systems discussed in the next chapter

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSTimelineshtml

34

71124 709 PM

DistributedSystemModelsTimelineshtml

K Mani Chandy Emeritus Simon Ramo Professor California Institute

Distributed Algorithms
of Technology

Contents

Index

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSTimelineshtml



44

71124 558 PM

Distributed Algorithms

DiffusingComputationsApplicationsDiffusingComputationSelfTesthtml

Contents

Index



Applications of Diffusing
Computations Self Test
This problem is to apply the algorithm in which the initiator takes a
global snapshot and then acquires the global snapshot
The Problem
The system has a set of indivisible indestructible tokens Tokens are
not created So the number of tokens in the system is a constant
Agents may hold tokens and agents may send tokens So at any
point tokens may be at agents or in transit in channels
Design an algorithm by which the initiator detects the number of
tokens in the system

Solution
Use the algorithm in which the initiator takes a global snapshot and
then acquires the global snapshot The state of an agent is the
number of tokens it holds The state of a channel is the number of
tokens in transit along the channel The local information x v that
agent x sends to the initiator is the total number of tokens in agent x
and in incoming channels of agent x
We dont need to prove the correctness of this algorithm because it is
a special case of the algorithm in which the initiator takes and then
acquires a global snapshot

Optimization
The algorithm in which the initiator takes a global snapshot and then
acquires the global snapshot can be optimized by merging the two
phases Instead of first waiting for the initiator to determine that the
global snapshot is complete and only then initiating the algorithm to
acquire all the local information the two phases can operate
concurrently The algorithm with the merged phases is
straightforward and is not given here

httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationSelfTesthtml

12

71124 558 PM

DiffusingComputationsApplicationsDiffusingComputationSelfTesthtml

K Mani Chandy Emeritus Simon Ramo Professor California Institute

Distributed Algorithms
of Technology

Contents

Index

httpskmchandygithubioDiffusingComputationsApplicationsDiffusingComputationSelfTesthtml



22

71124 111 PM

Distributed Algorithms

DistributedSystemModelsTimelinesProofshtml

Contents

Index



Past Future and Cuts in Dataflow
Proofs
Properties of Cuts of Dataflow
Dataflows of past events and future events
Theorem
Given a cut past future there exists exists a dataflow
consisting only of past events and there exists exists a dataflow
consisting only of future events
Proof
For a dataflow graph G with initial state Sinit and final state Sfini
and a state S  at a cut past future we will prove that
1 There exists a dataflow graph H of past events with initial
state Sinit and final state S 
2 There exists a dataflow graph H  of future events with initial
state S and final state Sfini
Every vertex of H  apart from final vertices is a vertex in G Every
edge of H  apart from edges to final vertices is an edge in G Since
every vertex in G represents an event so does every vertex in H 
The proof for the second part is similar Figure 1 illustrates the idea
underlying the proof

Computation in which Past precedes Future
Theorem
Given a dataflow graph and a cut past future of the graph
there exists a computation that starts at the initial state of the
dataflow executes the events in past and then executes events in
future
Proof

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSTimelinesProofshtml

13

71124 111 PM

DistributedSystemModelsTimelinesProofshtml

Every topological sort of a dataflow graph is a computation There

Distributed Algorithms

Contents

Index

exists at least one topological sort of a directed acyclic graph From
the previous theorem there is at least one computation consisting of



past events and there is at least one computation consisting of
future events
The final state of computations of past events is the initial state of
computations of future events

Initial Subsequences of Steps by Agents
For the remainder of this page we assume that agents are indexed i
for 0  i  N  We restrict attention to a cut past future
specified by a vector n where past consists of the first nk steps of
agent k Cuts specified by a vector in this way are used in taking
global snapshots
Theorem
There exists a cut past future specified by a vector n where
past consists of the first nk steps of agent k exactly when
Every message received in past is sent in past
Proof
If the ith step of agent k is in past then all steps of agent k before
its ith step are also in past So if all messages received in past are
sent in past then all paths in the dataflow to past are from past

Numbers of Messages Sent and Received
For a channel c let csent and crcvd be the numbers of messages sent
and received along the channel at each point in a computation
Theorem
There exists a cut past future specified by a vector n where
past consists of the first nk steps of agent k exactly when
For all channels c csent  crcvd

Next
The properties of cuts in dataflow and the concepts of beforeafter
pastfuture are central for algorithms by which agents record the
states of distributed systems discussed in the next chapter

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSTimelinesProofshtml

23

71124 111 PM

DistributedSystemModelsTimelinesProofshtml

K Mani Chandy Emeritus Simon Ramo Professor California Institute

Distributed Algorithms
of Technology

Contents

Index

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSTimelinesProofshtml



33

71124 336 PM

Distributed Algorithms

kmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

Contents

Index



Detecting Database Deadlocks
A database deadlock occurs when each agent in a cycle remains
waiting forever for a resource held and required by the next agent in
the cycle A database deadlock detection algorithm is executed by
the operating system to determine whether there exists a cycle of
deadlocked agents

The Problem
The problem described here is a simplification of the database
deadlock problem The simplification focuses on the essentials of the
problem
Agents in a system share a set of indivisible resources An example
of such a resource is exclusive access to a file
A deadlock arises when there is a cycle of agents

x0 x1   xn1 x0 where for all i
1 agent xi holds a resource ri and
2 agent xi requires resources ri and ri1 to continue executing
Operations on indices of agents are taken mod n and n  1

Example
In the example a resource is identified by its color A system has one
red one blue and one green resource Agents x y and z are
deadlocked in the following state
1 Agent x requires the red and blue resources to continue
executing x is holding the red resource and is waiting to
acquire the blue resource
2 Agent y requires the blue and green resources to continue
executing y  is holding the blue resource and is waiting to
acquire the green resource
3 Agent z requires the green and red resources to continue
executing z holds the green resource and is waiting to acquire
the red resource

httpskmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

15

71124 336 PM

Distributed Algorithms

kmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

Contents

Index



Fig2  An Example of a Deadlock

How Should You Solve the Problem
Strategy
A strategy to solve detection problems is to start with the general
detection algorithm and then explore optimizations by using
properties of cuts
In the general detection algorithm an observer gets global snapshots
and determines if there is a cycle of waiting agents in the snapshot
Algorithms for determining cycles are found here
Next lets explore optimizations  see Detection without Observers
Distributed Algorithms on Local Snapshots The optimized algorithm
has two phases 1 First a global snapshot algorithm is executed 2
After the global snapshot algorithm terminates a distributed
detection algorithm is executed on the local snapshots recorded by
the global snapshots
The two phases can be merged for some problems including this
one

A Distributed Algorithm to Detect a Cycle of Waiting
Agents
Multiple detection algorithms and global snapshot algorithms may
execute concurrently These algorithms are disambiguated by tagging
each algorithm with the initiator and a sequence id Next we describe
a single detection algorithm which is executed after a single global
snapshot algorithm terminates
httpskmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

25

71124 336 PM

kmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

Local Constants

Distributed Algorithms

Contents

Index



In the detection algorithm each agent v has the following local
constants
1 vwaits is the set of resources that v has to acquire from
other agents to start execution
2 vholds is the set of resources that v holds and must
continue to hold to start execution
Example
In the example of the figure
xwaits  blue xholds  red
ywaits  green yholds  blue
zwaits  red yholds  green
vwaits and vholds are constant for all v in the detection
algorithm because these values are specified in the global snapshot
Messages
The algorithm to detect waiting cycles is similar to the global
snapshot algorithm Instead of the marker message used in global
snapshots a message in the detection identifies the set of resources
for which the sender of the message is waiting
Each message m sent by an agent v has a field mwaits where
mwaits  vwaits
Initiating the Algorithm
A waiting agent u initiates the algorithm by sending a message m on
each of its output channels where mwaits  uwaits
Action by an Agent other than the Initiator
When an agent v receives a message m
1 If v has already sent messages then v takes no action
2 If v has not sent messages and if there is a resource common
to mwaits and vholds then v sends a message m on each
of its output channels where mwaits  vwaits
Cycle Detection

httpskmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

35

71124 336 PM

kmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

If the initiator u receives a message m where there is a resource

Distributed Algorithms

Contents

Index

common to mwaits and uholds then u detects a cycle of waiting
agents



Proof of Correctness
The proof outline is as follows An agent v sends messages only if
there is a path of waiting processes from u to v So u detects a cycle
of waiting processes only if there exists a cycle of waiting processes
If there exists a cycle of waiting processes from u to u then
messages are sent along one such cycle and so u detects a cycle
The algorithm terminates because it sends at most one message on
each channel

Example
This example shows steps in the case of the cycle of waiting
processes shown in figure 2 The algorithm is initiated by agent x by
broadcasting a message m where mwaits  xwaits 
blue
When y receives a message m where mwaits  blue there is a
resource in both mwaits and yholds and so y broadcasts
message m where mwaits  ywaits  green
When z receives a message m where mwaits  blue z takes
no action because there is no resource in both mwaits and
zholds
When z receives a message m where mwaits  green z
broadcasts message m where mwaits  zwaits  red
When the initiator x receives a message m where mwaits 
red x detects a deadlock because there is a resource common to
mwaits and xholds

Combining Cycle Detection and Snapshot Algorithms
We can use a a marker in the snapshot algorithm as a message in
cycle detection Modify a marker m to have the field mwaits used in
cycle detection Then the snapshot algorithm is the same as the cycle
detection algorithm except that the snapshot algorithm records
states of channels which are not used in cycle detection
Write the algorithm for the combined algorithm as an exercise
httpskmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

45

71124 336 PM

Distributed Algorithms

kmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

Contents

Index

K Mani Chandy Emeritus Simon Ramo Professor California Institute



of Technology

httpskmchandygithubioChannelSnapshotsDatabaseDeadlockDetectionhtml

55

71124 711 PM

Distributed Algorithms

DistributedSystemModelsTimelinesFAQhtml

Contents

Index



Timelines FAQ
Which agent starts a global snapshot algorithm
The algorithm is started by any one or more agents The agents that
start the algorithm isnt specified
The agent that should initiate a snapshot algorithm is usually self
evident from the application of the algorithm For example an agent
that has been waiting for a long time for a message may obtain a
global snapshot to determine if the agent is in a deadlock
Can the snapshot algorithm be used to record the states and
channels of a subset of agents or does the algorithm have to span all
agents and channels
The snapshot algorithm can be used to record the states of a
connected subset of agents An agent doesnt propagate markers to
agents outside the set of interest The recorded states of the subset
of agents and channels forms a part of a global snapshot Some
algorithms only used snapshots of subsets of agents
Is every message received in past is sent in past equivalent to
every message sent in future is received in future
Yes
Note that a message may be received in the final state

Next
Chapter on Snapshots and Clocks Global Snapshots
Properties of Dataflow

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSTimelinesFAQhtml

11

7724 1103 AM

Distributed Algorithms

DistributedSystemModelsBasicshtml

Contents

Index



Basics
This page describes a simple model and notation for distributed
algorithms The model is adequate for describing a collection of
algorithms Other models are introduced later

Models of Distributed Systems
Distributed systems are complex A banking information system
supports actions in ATM machines branch offices and fraud analysis
centers An earthquake monitoring system has thousands of sensors
and agents carrying out complex calculations
A model of a distributed system is an abstraction that ignores some
features Different models are used to design algorithms in different
settings for example a model of a system in which messages may
be corrupted is different from one in which messages are
incorruptible
We begin with a simple model and notation Examples of some
distributed algorithms are given in Python using a simulator and
using software libraries such as a Python implementation of the
Advanced Message Queuing Protocol AMQP

A Simple Model A Network of Agents and
Channels
A distributed system consists of a set of agents and a set of
channels A channel is directed from one agent to one agent A
channel from an agent P to an agent Q is called an output of P and an
input of Q The ordered pair P Q represents the channel from P to
Q An agent can send messages on its output channels and receive
messages on its input channels
A system is represented by a directed graph in which vertices
represent agents and edges represent channels The graph is called a
network of agents
Figure 1 shows a network of 4 agents pos neg sum and result
The network has 3 edges pos sum neg sum and sum
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSBasicshtml

14

7724 1103 AM

result

Distributed Algorithms

DistributedSystemModelsBasicshtml

Contents

Index



Fig1 Agent Network of the Example
A distributed system is initiated with sets of agents and channels that
remain unchanged Agents and channels are not created or deleted
during a computation

Message Communication Channels
The state of a channel is a queue consisting of the sequence of
messages in the channel  these are the messages that have been
sent on the channel and that have not been received
An agent sends a message by appending the message to the tail
rear of the queue A message from a nonempty queue is delivered
to an agent by removing the message from the head front of the
queue and calling the receive function of the agent
Messages are not lost or modified in channels Every message sent is
received Message delays are arbitrary but finite
A system has the following property For all n the nth message
received on a channel is the nth message sent on the channel and
the nth message is received on a channel only after the nth
message is sent on the channel

Agents
An agent is an object that sends and receives messages An agent is
a sequential program that has two parts 1 a part that initializes
variables and output channels of the agent and 2 a function
receivemessage sender
called a callback function in message queuing libraries
Delivering a message in a channel to an agent

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSBasicshtml

24

7724 1103 AM

DistributedSystemModelsBasicshtml

If an agent has a nonempty input channel then the receive function

Distributed Algorithms

Contents

Index

of the agent is called where message is the message at the head of
the channel and sender is the agent that sent the message The



message at the channel head is removed and processed by the
agent
A receive function must not be recursive an agent cannot receive a
new message while it is executing a receive on a previous message
Every execution of receive must terminate
An agent may have many nonempty input channels but the agent
processes only one message at a time An agent is not interrupted
while it is executing a receive Messages that arrive while an agent
is executing a receive remain in channels
Sending a message on a channel by an agent
An agent sends a message by executing
sendmessage receiver
The first parameter of send is the message that is sent and the
second paramenter is the agent to which the message is sent
Execution of this statement places the message in the output
channel directed from the sender to the receiver Statements that
send messages appear in the receive function of the agent An
agent sends messages in response to messages that it receives See
examples

The State of a System
The state of a system is given by the states of its agents and
channels We represent a system state as a tuple with an element of
the tuple for each agent and each channel
The state of an agent is given by the values of its variables including
its program counter An agents state changes while it executes its
receive function An agents state remains unchanged while it is
idle waiting to execute a receive
The state of a channel is the sequence of messages sent on the
channel that have not as yet been delivered and the channel state
changes when a message is sent on the channel or a message in the
channel is delivered

Example of an Agent
httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSBasicshtml

34

7724 1103 AM

DistributedSystemModelsBasicshtml

This is an example of an agent sum_pos_neg that receives

Distributed Algorithms

Contents

Index

messages from agents pos and neg and sends messages to agent
results See an example of an implementation in Python



The statements before the receive function specify the initial
values of variables and output channels of the agent The initial state
of an output channel is an empty queue unless it is assigned a
different value In this example the initial state is sum  0 and the
agents output channels are empty initially
 Initialization
sum  0
 Callback function
def receivemessage sender
if sender  pos
sum  sum  message
else
sum  sum  message
sendsum results
If the agent receives a message from agent pos then the agent
increments sum by the contents of the message and sends the
resulting value of sum to the agent results The agent takes similar
actions when it receives a message from neg except that it
decrements sum

Next
The next three webpages continue the description of a model of
distributed systems and point out its strengths and limitations The
next page introduces Timelines and Dataflow
Frequenty Asked Questions

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology

httpskmchandygithubioDISTRIBUTED_SYSTEM_MODELSBasicshtml

44

71124 326 PM

Distributed Algorithms

ChannelSnapshotsChannelSnapshotshtml

Contents

Index



A Global Snapshot Algorithm
A global snapshot algorithm records a state of the system that can
occur during a computation The state obtained by the algorithm is
called a global snapshot Systems are monitored by taking repeated
global snapshots When a transient error is detected a rollback and
recovery algorithm restarts the computation from the most recent
snapshot instead of starting it from the initial state

Global Snapshot
A global snapshot algorithm records a state of the system that
occurs during a computation of the system A state obtained by the
algorithm is called a global snapshot
A state of the system is a tuple with an element of the tuple for each
agent and each channel A system state is also called a global state
to distinguish it from states of agents and states of channels
An algorithm to record the state of a system is not instantaneous
because the algorithm records the states of multiple agents and
channels The algorithm starts at some point and terminates at a
later point A global snapshot is a state that occurs in a computation
from the state in which the algorithm starts to the state in which the
algorithm ends
The global snapshot algorithm is an example of an algorithm that is
executed by a distributed operating system OS on behalf of a client
Next we describe features of the OS that are relevant to the snapshot
algorithm

A Distributed Operating System
Each client agent has an OS agent that supervises it OS agents use
the same processors and channels as clients do OS agents can
record but not modify states of their clients OS agents can send and
receive OS messages that are not seen by clients
Figure 1 is a representation of two OS agents that manage their client
agents Messages sent by a client are recorded by the OS and passed
through to destination clients The OS sends messages on the same


17

71124 326 PM

ChannelSnapshotsChannelSnapshotshtml

channels as clients but the OS traps these messages so that the

Distributed Algorithms
client does not see them

Contents

Index



Fig1 OS and Clients use the same Channels
Execution of an OS agent on a processor may delay a clients steps
on the same processor and thus change the order in which the
clients steps are executed The OS may change a clients
computation  the order of steps  but the OS must not change the

clients dataflow
One way to record a global snapshot is for the OS to stop a client
computation then take a global snapshot and then restart the client
computation Our goal is to design an algorithm that does not stop
the client
Hereafter when we refer to an agent we mean an OS agent Likewise
by messages we mean those that are sent and received by the OS
Next lets develop OS agents and OS messages to record a global
snapshot

The Problem
Let Sinit and Sfini be the states in which the algorithm starts and
finishes respectively Design an algorithm that records a state S 
such that there exists a computation that starts at Sinit then visits

S  and then visits Sfini

How Should You Solve the Problem
Strategy
A general strategy for designing algorithms dealing with intermediate
states is to find a helpful property of cuts What property helps to
determine S 



27

71124 326 PM

ChannelSnapshotsChannelSnapshotshtml

The property Computations of Past before Future given below tells

Distributed
Algorithms
Contents
us that S  can be the state at any cut

Index



Computations of Past before Future
Let computation X start in state Sinit and end in state Sfini Let S 
be the state at a cut past future of X There exists a
computation Y that starts in Sinit visits S  and ends in Sfini
Using this strategy our tasks reduce to 1 identifying a cut and 2
recording the state S  at the cut

Identifying a Cut
Each agent has to record its own state because an agents state is
not accessible to other agents The state of an agent that it records is
called a local snapshot
Define past as the set of steps at each agent before the agent takes
its local snapshot and define future as the set of steps at each
agent after the agent takes its local snapshot So if a step x at an
agent is in past then all steps at that agent before x are also in
past
Lets use the following property of past future and cuts
The partition past future is a cut exactly when every message
received in past is sent in past
Therefore past future is a cut exactly when

Global Snapshot Rule
Each message received before the receiver takes its local snapshot is
sent before the sender takes its local snapshot

Design an algorithm yourself before reading further and compare
your algorithm with the one given below

The Global Snapshot Algorithm
A special OS message called a marker is used to distinguish presnapshot from postsnapshot messages Messages sent on a
channel before a marker is sent on the channel are messages sent



37

71124 326 PM

ChannelSnapshotsChannelSnapshotshtml

in the past  ie before the sender takes its local snapshot  and

Distributed Algorithms

Contents

Index

messages sent after the marker are sent in the future



The algorithm
1 The algorithm begins by one or more agents taking their local
snapshots
2 When an agent takes its local snapshot it sends a marker on
each of its outgoing channels
3 When an agent receives a marker the agent takes its local
snapshot if it has not already done so
4 The snapshot of a channel is the sequence of messages
received on the channel after the receiver takes its snapshot
and before the receiver receives a marker on the channel

Proof of correctness
From rule 3 each message received by an agent r on a channel c
before r takes its local snapshot is a message received by r before r
receives a marker on channel c
Because channels are first in first out each message received by r on
c before r receives a marker on c is sent on c before a marker is sent
on c
From rule 2 each message sent on c before a marker is sent on c is
sent before the sender takes its local snapshot
From the three paragraphs above it follows that the global snapshot
rule holds for the algorithm
Proof about States of Channels
The messages in a channel at the cut are the messages sent in past
and received in future These are messages sent before the sender
takes its snapshot and received after the receiver takes its snapshot
So the state of a channel is the sequence of messages received
along the channel after the receiver takes its snapshot and before the
receiver receives a marker along the channel
Note If an agent takes its local snapshot when it receives a marker
along a channel then the snapshot of the channel is the empty
sequence of messages

Termination of the Algorithm



47

71124 326 PM

ChannelSnapshotsChannelSnapshotshtml

After any agent v initiates the algorithm all agents that are reachable

Distributed Algorithms
Contents
Index
from v will receive a marker and take their local snapshots If every



agent is reachable from an initiator then all agents take local
snapshots
Each agent takes its local snapshot at most once So a marker is
sent on a channel at most once The computation terminates when
all markers are received

Collecting Local Snapshots to form Global Snapshots
One way to collect local snapshots is to have an OS agent act as an
observer Each agent sends its local snapshots to the observer which
puts the local snapshots together to form the global snapshots
Successive snapshots are disambiguated by using sequence
numbers or timestamps
Some algorithms carry out distributed computations on local
snapshots without using an observer to collect local snapshots
Later we give examples of such algorithms

Applications of Global Snapshots
System Monitoring
Systems can be monitored by taking global snapshots repeatedly Let
S0 S1 S2   be the sequence of states recorded by the system
From the property Computations through Increasing Cuts there exists
a computation that visits each state Si in order of increasing i The
system monitor checks the sequence of snapshots to determine if
some action is required

Rollback and Recover
Let S  be the most recent snapshot recorded by a system monitor
From the property Computations of Past before Future there exists
a computation that starts at the initial state and later visits S  So if
an error is detected in a computation then the computation can be
restarted from S  rather than rolling all the way back to the initial
state

Detecting Stable Predicates
A stable predicate is a predicate with the following property If the
predicate holds at any point in any computation then it continues to
hold forever thereafter in that computation Equivalently if a stable


57

71124 326 PM

ChannelSnapshotsChannelSnapshotshtml

predicate holds in a state s then it holds in all states reachable from s

Distributed Algorithms


Contents

Index



Examples of stable predicates are The computation has terminated
and The computation is deadlocked If a computation has
terminated at some point then it remains terminated Likewise if a
computation has deadlocked then it remains deadlocked

Specification of Detection Algorithms
An algorithm to detect a stable property P has the following
specification
1 If P holds when the algorithm is initiated then the algorithm
detects that P holds
2 If the algorithm detects that P holds then P holds when the
algorithm terminates

General Detection Algorithms
A general solution is for the operating system to monitor a client
computation by taking repeated snapshots of the computation The
OS checks whether a specified stable property holds in each
snapshot From the property Computations of Past before Future
this general solution satisfies the specification of detection
algorithms
Detection with Observers
The OS uses an agent the observer to collect local snapshots and
form a global snapshot The observer inspects the global snapshot to
determine if the property holds in the snapshot The OS can also use
multiple observers each of which collects local information from
subnetworks the OS then carries out a distributed algorithm on its
collection of observers
The OS can also execute a distributed algorithm on local snapshots
without having observers collect local information as described next
Detection without Observers Distributed Algorithms on Local
Snapshots
Distributed algorithms on local snapshots operate in two phases In
the first phase a global snapshot algorithm is executed The local
snapshot of each agent and its incoming channels are stored locally
at the agent without sending the information to observers



67

71124 326 PM

ChannelSnapshotsChannelSnapshotshtml

In the second phase a distributed algorithm is executed to determine

Distributed Algorithms

Contents

Index

if the local information stored at agents satisfies a specified global
property such as computation has deadlocked The algorithm in the



second phase operates on unchanging data These algorithms are
often distributed graph algorithms
The two phases can be executed concurrently in many applications

Next
A code skeleton of the algorithm and examples of the global
snapshot algorithm are provided here Next logical clocks

K Mani Chandy Emeritus Simon Ramo Professor California Institute
of Technology



77
